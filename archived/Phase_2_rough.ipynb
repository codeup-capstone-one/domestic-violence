{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan:\n",
    "\n",
    "### Phase 2 will utilize the subset of women that were identified as abused in the study and compound extra features that were gleaned in a follow-up survey of these identified women.  These features will be narrowed and modeled to identify risk of being reassaulted.  This work will investigate appropriately on a compounded dataframe of our original features in addition to the new features from the follow-up survey.\n",
    "\n",
    "### Hypothesis: From domain knowledge of this field, we predict that there will likely be significant identifiers of abuse that can be fed into a machine-learned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# basic environment and custom scripts\n",
    "import os\n",
    "import time\n",
    "\n",
    "# import pipeline scripts\n",
    "import acquire\n",
    "import prepare\n",
    "import explore\n",
    "import model\n",
    "\n",
    "# numpy and pandas for dataframe building and manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# matplotlib and seaborn for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# import preprocessing for scaling and splitting\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# xgboost for potential feature selection\n",
    "import xgboost as xgb\n",
    "\n",
    "# sklearn machine learning\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# classification reports\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Dimensionality\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#  balanced bagging classifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "# to explode the DataFrames and avoid truncation\n",
    "# pd.set_option('display.max_rows', 1000)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACQUISITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilize acquire script to get primary dataframe for analysis\n",
    "dfa, dfb = acquire.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will push forward and prepare dfa as we did in Phase 1.  Details and checks may be examined in the Phase 1 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create recidivism column\n",
    "dfa['RECID'] = dfa.CASEID.apply(prepare.get_repeat_case)\n",
    "# use prepare function to rename features \n",
    "dfa = prepare.rename_columns_all(dfa)\n",
    "# use prepare function to re-encode data\n",
    "prepare.replace_nonvals_all(dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASEID</th>\n",
       "      <th>M5FIRED</th>\n",
       "      <th>M11HIGH</th>\n",
       "      <th>M35SAFE</th>\n",
       "      <th>M41ILLGL</th>\n",
       "      <th>M42DAGRR</th>\n",
       "      <th>M13TALKR</th>\n",
       "      <th>M32OTHER</th>\n",
       "      <th>M27HOW</th>\n",
       "      <th>M30ARRES</th>\n",
       "      <th>...</th>\n",
       "      <th>FORCEDR</th>\n",
       "      <th>MISCARR</th>\n",
       "      <th>RESTRAIN</th>\n",
       "      <th>CHOKED</th>\n",
       "      <th>NDRUNK</th>\n",
       "      <th>RDRUNK</th>\n",
       "      <th>BOTHDRUN</th>\n",
       "      <th>NDRUGS</th>\n",
       "      <th>RDRUGS</th>\n",
       "      <th>BOTHDRUG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108395</td>\n",
       "      <td>9999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108397</td>\n",
       "      <td>9999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108399</td>\n",
       "      <td>9999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108443</td>\n",
       "      <td>9999</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108444</td>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>99999</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CASEID  M5FIRED  M11HIGH  M35SAFE  M41ILLGL  M42DAGRR  M13TALKR  M32OTHER  \\\n",
       "0  108395     9999        2        1         2         0         1        99   \n",
       "1  108397     9999        2        1         2         0         1        99   \n",
       "2  108399     9999        2        1         2         0         1        99   \n",
       "3  108443     9999        2        1         2         0         1        13   \n",
       "4  108444     9999        1        1         2         0         1        99   \n",
       "\n",
       "   M27HOW  M30ARRES    ...     FORCEDR  MISCARR  RESTRAIN  CHOKED  NDRUNK  \\\n",
       "0   99999         3    ...           0        0         0       0       0   \n",
       "1   99999         3    ...           0        0         0       1       2   \n",
       "2   99999         3    ...           0        0         1       1       0   \n",
       "3   99999         3    ...           0        0         0       1       1   \n",
       "4   99999         3    ...           0        0         0       0       3   \n",
       "\n",
       "   RDRUNK  BOTHDRUN  NDRUGS  RDRUGS  BOTHDRUG  \n",
       "0       0         0       0       0         0  \n",
       "1       0         0       0       0         0  \n",
       "2       0         0       0       0         0  \n",
       "3       0         0       0       0         0  \n",
       "4       0         0       0       0         0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#peek at dfb\n",
    "dfb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [sum_nulls, nulls_by_percent]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# formally check that there are no nulls in dataframe b\n",
    "prepare.get_nulls_by_column(dfb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no nulls!\n"
     ]
    }
   ],
   "source": [
    "# check no 2\n",
    "if not prepare.get_nulls_by_row(dfb):\n",
    "    print('no nulls!')\n",
    "else:\n",
    "    prepare.get_nulls_by_row(dfb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEAD\n",
      "   CASEID  M5FIRED  M11HIGH  M35SAFE  M41ILLGL  M42DAGRR  M13TALKR  M32OTHER  \\\n",
      "0  108395     9999        2        1         2         0         1        99   \n",
      "1  108397     9999        2        1         2         0         1        99   \n",
      "2  108399     9999        2        1         2         0         1        99   \n",
      "3  108443     9999        2        1         2         0         1        13   \n",
      "4  108444     9999        1        1         2         0         1        99   \n",
      "\n",
      "   M27HOW  M30ARRES    ...     FORCEDR  MISCARR  RESTRAIN  CHOKED  NDRUNK  \\\n",
      "0   99999         3    ...           0        0         0       0       0   \n",
      "1   99999         3    ...           0        0         0       1       2   \n",
      "2   99999         3    ...           0        0         1       1       0   \n",
      "3   99999         3    ...           0        0         0       1       1   \n",
      "4   99999         3    ...           0        0         0       0       3   \n",
      "\n",
      "   RDRUNK  BOTHDRUN  NDRUGS  RDRUGS  BOTHDRUG  \n",
      "0       0         0       0       0         0  \n",
      "1       0         0       0       0         0  \n",
      "2       0         0       0       0         0  \n",
      "3       0         0       0       0         0  \n",
      "4       0         0       0       0         0  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "\n",
      "TAIL\n",
      "     CASEID  M5FIRED  M11HIGH  M35SAFE  M41ILLGL  M42DAGRR  M13TALKR  \\\n",
      "492  808678     9999        2        1         2         0         2   \n",
      "493  808695     9999        1        1         2         1         1   \n",
      "494  808696     9999        1        1         2         1         1   \n",
      "495  908001      999      999      999       999       999       999   \n",
      "496  908003      999      999      999       999       999       999   \n",
      "\n",
      "     M32OTHER  M27HOW  M30ARRES    ...     FORCEDR  MISCARR  RESTRAIN  CHOKED  \\\n",
      "492        99   99999         2    ...           0        0         0       0   \n",
      "493        16   99999         1    ...           4        0         1      99   \n",
      "494        18   99999         3    ...           0        0         0      99   \n",
      "495        99    9999       999    ...         999      999       999     999   \n",
      "496        99    9999       999    ...         999      999       999     999   \n",
      "\n",
      "     NDRUNK  RDRUNK  BOTHDRUN  NDRUGS  RDRUGS  BOTHDRUG  \n",
      "492       0       0         0       0       0         0  \n",
      "493       0       0         0      28       0         0  \n",
      "494       0       0         0       0       0         0  \n",
      "495     999     999       999     999     999       999  \n",
      "496     999     999       999     999     999       999  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "\n",
      "SHAPE: (497, 29)\n",
      "\n",
      "DESCRIPTION\n",
      "              CASEID      M5FIRED     M11HIGH     M35SAFE    M41ILLGL  \\\n",
      "count     497.000000   497.000000  497.000000  497.000000  497.000000   \n",
      "mean   387964.422535  8936.913481   15.392354   19.267606   19.881288   \n",
      "std    197319.742270  3077.792007  114.044050  133.185850  133.102374   \n",
      "min    108395.000000     1.000000    1.000000    1.000000    1.000000   \n",
      "25%    308037.000000  9999.000000    2.000000    1.000000    2.000000   \n",
      "50%    308498.000000  9999.000000    2.000000    1.000000    2.000000   \n",
      "75%    508541.000000  9999.000000    2.000000    1.000000    2.000000   \n",
      "max    908003.000000  9999.000000  999.000000  999.000000  999.000000   \n",
      "\n",
      "         M42DAGRR    M13TALKR    M32OTHER        M27HOW    M30ARRES  \\\n",
      "count  497.000000  497.000000  497.000000    497.000000  497.000000   \n",
      "mean    16.581489   11.321932   67.959759  86853.790744   14.199195   \n",
      "std    125.784706   99.668892   38.969415  33366.834308  108.979479   \n",
      "min      0.000000    1.000000   11.000000     11.000000    0.000000   \n",
      "25%      0.000000    1.000000   19.000000  99999.000000    1.000000   \n",
      "50%      1.000000    1.000000   99.000000  99999.000000    3.000000   \n",
      "75%      1.000000    2.000000   99.000000  99999.000000    3.000000   \n",
      "max    999.000000  999.000000   99.000000  99999.000000  999.000000   \n",
      "\n",
      "          ...         FORCEDR     MISCARR    RESTRAIN      CHOKED      NDRUNK  \\\n",
      "count     ...      497.000000  497.000000  497.000000  497.000000  497.000000   \n",
      "mean      ...        8.519115    8.064386    8.261569   32.092555   12.044266   \n",
      "std       ...       89.313737   89.349057   89.341769   96.890920   89.940740   \n",
      "min       ...        0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%       ...        0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%       ...        0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%       ...        0.000000    0.000000    0.000000    6.000000    2.000000   \n",
      "max       ...      999.000000  999.000000  999.000000  999.000000  999.000000   \n",
      "\n",
      "          RDRUNK    BOTHDRUN      NDRUGS      RDRUGS    BOTHDRUG  \n",
      "count  497.00000  497.000000  497.000000  497.000000  497.000000  \n",
      "mean     8.60161    8.456740   10.219316    8.764588    8.525151  \n",
      "std     89.33316   89.334517   89.678223   89.351827   89.342535  \n",
      "min      0.00000    0.000000    0.000000    0.000000    0.000000  \n",
      "25%      0.00000    0.000000    0.000000    0.000000    0.000000  \n",
      "50%      0.00000    0.000000    0.000000    0.000000    0.000000  \n",
      "75%      0.00000    0.000000    1.000000    0.000000    0.000000  \n",
      "max    999.00000  999.000000  999.000000  999.000000  999.000000  \n",
      "\n",
      "[8 rows x 29 columns]\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 497 entries, 0 to 496\n",
      "Data columns (total 29 columns):\n",
      "CASEID      497 non-null int64\n",
      "M5FIRED     497 non-null int64\n",
      "M11HIGH     497 non-null int64\n",
      "M35SAFE     497 non-null int64\n",
      "M41ILLGL    497 non-null int64\n",
      "M42DAGRR    497 non-null int64\n",
      "M13TALKR    497 non-null int64\n",
      "M32OTHER    497 non-null int64\n",
      "M27HOW      497 non-null int64\n",
      "M30ARRES    497 non-null int64\n",
      "M31HOW      497 non-null int64\n",
      "M38ORDER    497 non-null int64\n",
      "SEVERER     497 non-null int64\n",
      "TOTINCR     497 non-null int64\n",
      "THREATR     497 non-null int64\n",
      "SLAPR       497 non-null int64\n",
      "PUNCHR      497 non-null int64\n",
      "BEATR       497 non-null int64\n",
      "UWEAPON     497 non-null int64\n",
      "FORCEDR     497 non-null int64\n",
      "MISCARR     497 non-null int64\n",
      "RESTRAIN    497 non-null int64\n",
      "CHOKED      497 non-null int64\n",
      "NDRUNK      497 non-null int64\n",
      "RDRUNK      497 non-null int64\n",
      "BOTHDRUN    497 non-null int64\n",
      "NDRUGS      497 non-null int64\n",
      "RDRUGS      497 non-null int64\n",
      "BOTHDRUG    497 non-null int64\n",
      "dtypes: int64(29)\n",
      "memory usage: 112.7 KB\n",
      "INFORMATION\n",
      "CASEID\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "M5FIRED\n",
      "1        10\n",
      "2        41\n",
      "9999    444\n",
      "999       2\n",
      "Name: M5FIRED, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "M11HIGH\n",
      "1      101\n",
      "2      389\n",
      "888      2\n",
      "999      5\n",
      "Name: M11HIGH, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "M35SAFE\n",
      "1      391\n",
      "2       97\n",
      "999      9\n",
      "Name: M35SAFE, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "M41ILLGL\n",
      "1       86\n",
      "2      402\n",
      "999      9\n",
      "Name: M41ILLGL, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "M42DAGRR\n",
      "0      240\n",
      "1      249\n",
      "999      8\n",
      "Name: M42DAGRR, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "M13TALKR\n",
      "1      352\n",
      "2      140\n",
      "999      5\n",
      "Name: M13TALKR, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "M32OTHER\n",
      "(10.911000000000001, 19.8]    125\n",
      "(19.8, 28.6]                   20\n",
      "(28.6, 37.4]                   17\n",
      "(37.4, 46.2]                   36\n",
      "(46.2, 55.0]                    0\n",
      "(55.0, 63.8]                    0\n",
      "(63.8, 72.6]                    0\n",
      "(72.6, 81.4]                    0\n",
      "(81.4, 90.2]                    0\n",
      "(90.2, 99.0]                  299\n",
      "Name: M32OTHER, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "M27HOW\n",
      "11         7\n",
      "21         7\n",
      "22         6\n",
      "23         3\n",
      "24         2\n",
      "31         9\n",
      "32         5\n",
      "33         7\n",
      "41         2\n",
      "7777      11\n",
      "99999    430\n",
      "9999       8\n",
      "Name: M27HOW, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "M30ARRES\n",
      "0       70\n",
      "1       83\n",
      "2       34\n",
      "3      304\n",
      "999      6\n",
      "Name: M30ARRES, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "M31HOW\n",
      "1       30\n",
      "2        7\n",
      "3        8\n",
      "4       26\n",
      "5        6\n",
      "6        8\n",
      "7        3\n",
      "8        7\n",
      "9        4\n",
      "10       3\n",
      "11       2\n",
      "12       5\n",
      "13       7\n",
      "777    363\n",
      "999     18\n",
      "Name: M31HOW, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "M38ORDER\n",
      "1        24\n",
      "2        39\n",
      "3       427\n",
      "9999      1\n",
      "999       6\n",
      "Name: M38ORDER, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "SEVERER\n",
      "1    255\n",
      "2    238\n",
      "9      4\n",
      "Name: SEVERER, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "TOTINCR\n",
      "1      143\n",
      "2      167\n",
      "3       74\n",
      "4      109\n",
      "999      4\n",
      "Name: TOTINCR, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "THREATR\n",
      "0      388\n",
      "1       45\n",
      "2       19\n",
      "3       19\n",
      "4       22\n",
      "999      4\n",
      "Name: THREATR, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "SLAPR\n",
      "0      215\n",
      "1      123\n",
      "2       79\n",
      "3       40\n",
      "4       36\n",
      "999      4\n",
      "Name: SLAPR, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "PUNCHR\n",
      "0      255\n",
      "1      116\n",
      "2       74\n",
      "3       28\n",
      "4       20\n",
      "999      4\n",
      "Name: PUNCHR, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "BEATR\n",
      "0      316\n",
      "1      116\n",
      "2       45\n",
      "3       11\n",
      "4        5\n",
      "999      4\n",
      "Name: BEATR, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "UWEAPON\n",
      "0      432\n",
      "1       49\n",
      "2        9\n",
      "3        2\n",
      "8        1\n",
      "999      4\n",
      "Name: UWEAPON, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "FORCEDR\n",
      "0      374\n",
      "1       57\n",
      "2       25\n",
      "3       17\n",
      "4       20\n",
      "999      4\n",
      "Name: FORCEDR, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "MISCARR\n",
      "0      481\n",
      "1       12\n",
      "999      4\n",
      "Name: MISCARR, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "RESTRAIN\n",
      "0      436\n",
      "1       49\n",
      "2        2\n",
      "3        3\n",
      "8        1\n",
      "17       1\n",
      "23       1\n",
      "999      4\n",
      "Name: RESTRAIN, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "CHOKED\n",
      "0      314\n",
      "1       49\n",
      "2        8\n",
      "3        1\n",
      "6        1\n",
      "99     120\n",
      "999      4\n",
      "Name: CHOKED, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "NDRUNK\n",
      "(-1.0, 99.9]      492\n",
      "(99.9, 199.8]       1\n",
      "(199.8, 299.7]      0\n",
      "(299.7, 399.6]      0\n",
      "(399.6, 499.5]      0\n",
      "(499.5, 599.4]      0\n",
      "(599.4, 699.3]      0\n",
      "(699.3, 799.2]      0\n",
      "(799.2, 899.1]      0\n",
      "(899.1, 999.0]      4\n",
      "Name: NDRUNK, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "RDRUNK\n",
      "0      413\n",
      "1       37\n",
      "2       14\n",
      "3        8\n",
      "4        5\n",
      "5        6\n",
      "6        2\n",
      "7        2\n",
      "9        1\n",
      "12       1\n",
      "17       1\n",
      "22       1\n",
      "23       1\n",
      "31       1\n",
      "999      4\n",
      "Name: RDRUNK, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "BOTHDRUN\n",
      "0      431\n",
      "1       30\n",
      "2        9\n",
      "3        8\n",
      "4        2\n",
      "5        6\n",
      "7        2\n",
      "9        1\n",
      "12       1\n",
      "17       1\n",
      "22       1\n",
      "23       1\n",
      "999      4\n",
      "Name: BOTHDRUN, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "NDRUGS\n",
      "(-1.0, 99.9]      492\n",
      "(99.9, 199.8]       1\n",
      "(199.8, 299.7]      0\n",
      "(299.7, 399.6]      0\n",
      "(399.6, 499.5]      0\n",
      "(499.5, 599.4]      0\n",
      "(599.4, 699.3]      0\n",
      "(699.3, 799.2]      0\n",
      "(799.2, 899.1]      0\n",
      "(899.1, 999.0]      4\n",
      "Name: NDRUGS, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "RDRUGS\n",
      "(-1.0, 99.9]      493\n",
      "(99.9, 199.8]       0\n",
      "(199.8, 299.7]      0\n",
      "(299.7, 399.6]      0\n",
      "(399.6, 499.5]      0\n",
      "(499.5, 599.4]      0\n",
      "(599.4, 699.3]      0\n",
      "(699.3, 799.2]      0\n",
      "(799.2, 899.1]      0\n",
      "(899.1, 999.0]      4\n",
      "Name: RDRUGS, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n",
      "BOTHDRUG\n",
      "0      450\n",
      "1       12\n",
      "2        7\n",
      "3        7\n",
      "4        4\n",
      "5        2\n",
      "7        2\n",
      "9        1\n",
      "10       1\n",
      "12       1\n",
      "15       1\n",
      "17       1\n",
      "21       1\n",
      "22       1\n",
      "23       1\n",
      "25       1\n",
      "999      4\n",
      "Name: BOTHDRUG, dtype: int64\n",
      "\n",
      "-------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prepare.summarize_data(dfb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see the cases where reassault happened. There are 350 cases out of the original 705 (before the padding implemented in Phase 1). There were 497 cases of domestic violence (cases where the surveyed was identified as abused)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new dataframe out of subset of dfa where we only look at the victims of abuse\n",
    "dfa_abused = dfa[dfa.abuse_past_year == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 497 entries, 0 to 496\n",
      "Data columns (total 29 columns):\n",
      "CASEID      497 non-null int64\n",
      "M5FIRED     497 non-null int64\n",
      "M11HIGH     497 non-null int64\n",
      "M35SAFE     497 non-null int64\n",
      "M41ILLGL    497 non-null int64\n",
      "M42DAGRR    497 non-null int64\n",
      "M13TALKR    497 non-null int64\n",
      "M32OTHER    497 non-null int64\n",
      "M27HOW      497 non-null int64\n",
      "M30ARRES    497 non-null int64\n",
      "M31HOW      497 non-null int64\n",
      "M38ORDER    497 non-null int64\n",
      "SEVERER     497 non-null int64\n",
      "TOTINCR     497 non-null int64\n",
      "THREATR     497 non-null int64\n",
      "SLAPR       497 non-null int64\n",
      "PUNCHR      497 non-null int64\n",
      "BEATR       497 non-null int64\n",
      "UWEAPON     497 non-null int64\n",
      "FORCEDR     497 non-null int64\n",
      "MISCARR     497 non-null int64\n",
      "RESTRAIN    497 non-null int64\n",
      "CHOKED      497 non-null int64\n",
      "NDRUNK      497 non-null int64\n",
      "RDRUNK      497 non-null int64\n",
      "BOTHDRUN    497 non-null int64\n",
      "NDRUGS      497 non-null int64\n",
      "RDRUGS      497 non-null int64\n",
      "BOTHDRUG    497 non-null int64\n",
      "dtypes: int64(29)\n",
      "memory usage: 112.7 KB\n"
     ]
    }
   ],
   "source": [
    "# cursory glance at dfb\n",
    "dfb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-name columns in dfb into more readable features\n",
    "dfb = prepare.rename_columns_recid(dfb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-encode / clean values from dfb dataframe\n",
    "prepare.replace_nonvals_recid(dfb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge our dfb data onto our original phase one data set\n",
    "df = dfa_abused.merge(right=dfb, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    350\n",
       "0    147\n",
       "Name: reassault, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reassault.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will balance out our dataset for modeling by doubling the number of single-abuse cases.  This will reduce bias of accuracy when we create our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate single abuse cases into \n",
    "single_abuse = df[df.reassault == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# create new dataframe of just single abuse cases, reassign them new range of case ids\n",
    "single_abuse['id'] = range(999999, 999999 + len(single_abuse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append the padded single assault values to our greater dataframe\n",
    "df = df.append(single_abuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [sum_nulls, nulls_by_percent]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# formally check that there are no nulls in dataframe\n",
    "prepare.get_nulls_by_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no nulls!\n"
     ]
    }
   ],
   "source": [
    "# check no 2\n",
    "if not prepare.get_nulls_by_row(df):\n",
    "    print('no nulls!')\n",
    "else:\n",
    "    prepare.get_nulls_by_row(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644, 73)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    350\n",
       "0    294\n",
       "Name: reassault, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reassault.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of features\n",
    "features = [col for col in df]\n",
    "# drop features from this list that are perceived as primary key or target variable\n",
    "features.remove('id')\n",
    "features.remove('abuse_past_year')\n",
    "features.remove('abuse_status')\n",
    "features.remove('reassault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['length_relationship',\n",
       " 'partner_abusive',\n",
       " 'num_abusers',\n",
       " 'num_children',\n",
       " 'pregnant',\n",
       " 'beaten_while_pregnant',\n",
       " 'support_score',\n",
       " 'guns_in_home',\n",
       " 'jealous_past_year',\n",
       " 'limit_family_contact',\n",
       " 'location_tracking',\n",
       " 'threat_hit',\n",
       " 'threat_object',\n",
       " 'push_shove',\n",
       " 'slap',\n",
       " 'kick_punch',\n",
       " 'hit_object',\n",
       " 'beaten',\n",
       " 'choked',\n",
       " 'threat_knife',\n",
       " 'threat_gun',\n",
       " 'rape_with_threat',\n",
       " 'power_scale',\n",
       " 'harass_scale',\n",
       " 'id_age',\n",
       " 'age_disparity',\n",
       " 'children_not_partner',\n",
       " 'same_sex_relationship',\n",
       " 'partner_drug_use',\n",
       " 'partner_alcohol_use',\n",
       " 'threat_suicide',\n",
       " 'partner_reported_child_abuse',\n",
       " 'partner_arrested',\n",
       " 'violence_increased',\n",
       " 'severity_increased',\n",
       " 'weapon_ever',\n",
       " 'choked_ever',\n",
       " 'rape_ever',\n",
       " 'controlled_ever',\n",
       " 'jealous',\n",
       " 'capable_murder',\n",
       " 'gun_fired',\n",
       " 'anyone_high',\n",
       " 'safe_place',\n",
       " 'forced_illegal',\n",
       " 'life_danger',\n",
       " 'talk_about_it',\n",
       " 'left_or_not',\n",
       " 'medical_staff_helpful',\n",
       " 'perp_arrested_ever',\n",
       " 'police_resp',\n",
       " 'order_protection',\n",
       " 'level_severity',\n",
       " 'num_incidents',\n",
       " 'num_threats',\n",
       " 'num_slapping',\n",
       " 'num_punching',\n",
       " 'num_beating',\n",
       " 'num_weapon',\n",
       " 'num_forced_sex',\n",
       " 'miscarriage_resulted',\n",
       " 'restrained_by_perp',\n",
       " 'num_choked',\n",
       " 'num_perp_drunk',\n",
       " 'num_woman_drunk',\n",
       " 'num_both_drunk',\n",
       " 'num_perp_drugs',\n",
       " 'num_woman_drugs',\n",
       " 'num_both_drugs']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('phase2_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "X = df[features]\n",
    "y = df[['reassault']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .15, random_state = 0, stratify=y)\n",
    "\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will run chi-squared tests on our categorical variables in order to get a grasp of importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_relationship\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_abusers\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "beaten_while_pregnant\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "support_score\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "jealous_past_year\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "limit_family_contact\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "location_tracking\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "threat_hit\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "threat_object\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "push_shove\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "slap\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "kick_punch\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "hit_object\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "beaten\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "choked\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "threat_knife\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "threat_gun\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "rape_with_threat\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "power_scale\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "harass_scale\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "age_disparity\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "partner_drug_use\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "partner_alcohol_use\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "threat_suicide\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "partner_reported_child_abuse\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "partner_arrested\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "violence_increased\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "severity_increased\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "weapon_ever\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "choked_ever\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "rape_ever\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "controlled_ever\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "jealous\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "capable_murder\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "gun_fired\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "anyone_high\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "safe_place\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "forced_illegal\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "life_danger\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "perp_arrested_ever\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "police_resp\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "level_severity\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_incidents\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_threats\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_slapping\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_punching\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_beating\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_weapon\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_forced_sex\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "miscarriage_resulted\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "restrained_by_perp\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_choked\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_perp_drunk\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_woman_drunk\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_both_drunk\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_perp_drugs\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_woman_drugs\n",
      "Dependent (reject H0)\n",
      "-----------------------\n",
      "num_both_drugs\n",
      "Dependent (reject H0)\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# we will run chi-squared tests on our categorical variables in order to get a grasp of importance\n",
    "sig_feats, sig_dict = explore.get_chi_squared(train_df, features, 'reassault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# scale continuous variables\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(train_df[['id_age']])\n",
    "\n",
    "train_df[['id_age']] = scaler.transform(train_df[['id_age']])\n",
    "test_df[['id_age']] = scaler.transform(test_df[['id_age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_vars = ['id_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_feats_c, sig_dict_c = explore.get_significant_t_tests(train_df, ['id_age'], 'reassault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function that combines significant features from dictionaries created in statistical tests if both generated results\n",
    "# otherwise make list of features just from whichever (t test or chi squared) produced significant results\n",
    "if sig_feats_c and sig_feats:\n",
    "    features = explore.combine_significants(sig_dict, sig_dict_c)\n",
    "elif sig_feats_c:\n",
    "    features = [item[0] for item in explore.sort_sigs(sig_dict_c)]\n",
    "elif sig_feats:\n",
    "    features = [item[0] for item in explore.sort_sigs(sig_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore.make_bars(train_df, 'reassault', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore.swarrrm(train_df, 'reassault', ['id_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in continuous_vars:\n",
    "#    sns.lineplot(x=feature, y='reassault', data=train_df)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms\n",
    "# normalization(?)\n",
    "# explore.plot_hist(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore.make_rel(train_df, 'id_age', 'age_disparity', hue='reassault')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove any \"significant features\" that automatically denote target\n",
    "prepare.remove_phase_2_features(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying some things here:\n",
    "features.remove('harass_scale')\n",
    "features.remove('power_scale')\n",
    "features.remove('level_severity')\n",
    "features.remove('num_choked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some subsets of significant features to assess model performance\n",
    "top_5 = features[0:5]\n",
    "top_10 = features[0:10]\n",
    "top_15 = features[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA()  \n",
    "#  = pca.fit_transform(X_train[features],n_components=2))\n",
    "# # X_test = pca.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_relationship</th>\n",
       "      <th>partner_abusive</th>\n",
       "      <th>num_abusers</th>\n",
       "      <th>num_children</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>beaten_while_pregnant</th>\n",
       "      <th>support_score</th>\n",
       "      <th>guns_in_home</th>\n",
       "      <th>jealous_past_year</th>\n",
       "      <th>limit_family_contact</th>\n",
       "      <th>...</th>\n",
       "      <th>num_forced_sex</th>\n",
       "      <th>miscarriage_resulted</th>\n",
       "      <th>restrained_by_perp</th>\n",
       "      <th>num_choked</th>\n",
       "      <th>num_perp_drunk</th>\n",
       "      <th>num_woman_drunk</th>\n",
       "      <th>num_both_drunk</th>\n",
       "      <th>num_perp_drugs</th>\n",
       "      <th>num_woman_drugs</th>\n",
       "      <th>num_both_drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     length_relationship  partner_abusive  num_abusers  num_children  \\\n",
       "243                    1                1            1             0   \n",
       "124                    4                0            2             0   \n",
       "299                    1                1            1             2   \n",
       "76                     3                1            1             1   \n",
       "448                    5                1            1             1   \n",
       "\n",
       "     pregnant  beaten_while_pregnant  support_score  guns_in_home  \\\n",
       "243         0                      0             11             0   \n",
       "124         0                      1             10             0   \n",
       "299         0                      0             12             0   \n",
       "76          0                      0             12             0   \n",
       "448         0                      0              6             0   \n",
       "\n",
       "     jealous_past_year  limit_family_contact       ...        num_forced_sex  \\\n",
       "243                  1                     1       ...                     0   \n",
       "124                  1                     1       ...                     0   \n",
       "299                  1                     0       ...                     0   \n",
       "76                   1                     0       ...                     0   \n",
       "448                  1                     1       ...                     0   \n",
       "\n",
       "     miscarriage_resulted  restrained_by_perp  num_choked  num_perp_drunk  \\\n",
       "243                     0                   0          99               1   \n",
       "124                     0                   0          99               0   \n",
       "299                     0                   0           0               0   \n",
       "76                      0                   0           0               0   \n",
       "448                     0                   0           1              10   \n",
       "\n",
       "     num_woman_drunk  num_both_drunk  num_perp_drugs  num_woman_drugs  \\\n",
       "243                1               1               2                2   \n",
       "124                0               0               2                2   \n",
       "299                0               0               0                0   \n",
       "76                 0               0               0                0   \n",
       "448                0               0               0                0   \n",
       "\n",
       "     num_both_drugs  \n",
       "243               2  \n",
       "124               2  \n",
       "299               0  \n",
       "76                0  \n",
       "448               0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will attempt several different tactics and models as a means to find the best fit for our data set.  We will try with various features and par down with what we found as being statistically significant through chi-squared testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of lists that increase number of features in list\n",
    "that_list = []\n",
    "list_of_feature_lists = []\n",
    "for i in range(1,43):\n",
    "    that_list = features[0:i]\n",
    "    list_of_feature_lists.append(that_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Model based on top 1 features\n",
      "Accuracy of GNB classifier on training set: 0.73\n",
      "[[163  87]\n",
      " [ 62 235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.69       250\n",
      "           1       0.73      0.79      0.76       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.72      0.72       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 2 features\n",
      "Accuracy of GNB classifier on training set: 0.73\n",
      "[[163  87]\n",
      " [ 62 235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.69       250\n",
      "           1       0.73      0.79      0.76       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.72      0.72       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 3 features\n",
      "Accuracy of GNB classifier on training set: 0.70\n",
      "[[186  64]\n",
      " [101 196]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69       250\n",
      "           1       0.75      0.66      0.70       297\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       547\n",
      "   macro avg       0.70      0.70      0.70       547\n",
      "weighted avg       0.71      0.70      0.70       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 4 features\n",
      "Accuracy of GNB classifier on training set: 0.73\n",
      "[[179  71]\n",
      " [ 76 221]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       250\n",
      "           1       0.76      0.74      0.75       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.73      0.73       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 5 features\n",
      "Accuracy of GNB classifier on training set: 0.72\n",
      "[[190  60]\n",
      " [ 95 202]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.71       250\n",
      "           1       0.77      0.68      0.72       297\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       547\n",
      "   macro avg       0.72      0.72      0.72       547\n",
      "weighted avg       0.72      0.72      0.72       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 6 features\n",
      "Accuracy of GNB classifier on training set: 0.73\n",
      "[[181  69]\n",
      " [ 78 219]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       250\n",
      "           1       0.76      0.74      0.75       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.73      0.73       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 7 features\n",
      "Accuracy of GNB classifier on training set: 0.74\n",
      "[[182  68]\n",
      " [ 73 224]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       250\n",
      "           1       0.77      0.75      0.76       297\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       547\n",
      "   macro avg       0.74      0.74      0.74       547\n",
      "weighted avg       0.74      0.74      0.74       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 8 features\n",
      "Accuracy of GNB classifier on training set: 0.75\n",
      "[[186  64]\n",
      " [ 72 225]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       250\n",
      "           1       0.78      0.76      0.77       297\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       547\n",
      "   macro avg       0.75      0.75      0.75       547\n",
      "weighted avg       0.75      0.75      0.75       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 9 features\n",
      "Accuracy of GNB classifier on training set: 0.75\n",
      "[[185  65]\n",
      " [ 72 225]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       250\n",
      "           1       0.78      0.76      0.77       297\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       547\n",
      "   macro avg       0.75      0.75      0.75       547\n",
      "weighted avg       0.75      0.75      0.75       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 10 features\n",
      "Accuracy of GNB classifier on training set: 0.74\n",
      "[[188  62]\n",
      " [ 79 218]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.73       250\n",
      "           1       0.78      0.73      0.76       297\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       547\n",
      "   macro avg       0.74      0.74      0.74       547\n",
      "weighted avg       0.74      0.74      0.74       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 11 features\n",
      "Accuracy of GNB classifier on training set: 0.74\n",
      "[[186  64]\n",
      " [ 79 218]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       250\n",
      "           1       0.77      0.73      0.75       297\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       547\n",
      "   macro avg       0.74      0.74      0.74       547\n",
      "weighted avg       0.74      0.74      0.74       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 12 features\n",
      "Accuracy of GNB classifier on training set: 0.73\n",
      "[[188  62]\n",
      " [ 83 214]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72       250\n",
      "           1       0.78      0.72      0.75       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.74      0.73       547\n",
      "weighted avg       0.74      0.73      0.74       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 13 features\n",
      "Accuracy of GNB classifier on training set: 0.73\n",
      "[[190  60]\n",
      " [ 86 211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72       250\n",
      "           1       0.78      0.71      0.74       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.74      0.73       547\n",
      "weighted avg       0.74      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 14 features\n",
      "Accuracy of GNB classifier on training set: 0.73\n",
      "[[190  60]\n",
      " [ 89 208]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72       250\n",
      "           1       0.78      0.70      0.74       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.73      0.73       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 15 features\n",
      "Accuracy of GNB classifier on training set: 0.73\n",
      "[[188  62]\n",
      " [ 86 211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72       250\n",
      "           1       0.77      0.71      0.74       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.73      0.73       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 16 features\n",
      "Accuracy of GNB classifier on training set: 0.72\n",
      "[[186  64]\n",
      " [ 89 208]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       250\n",
      "           1       0.76      0.70      0.73       297\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       547\n",
      "   macro avg       0.72      0.72      0.72       547\n",
      "weighted avg       0.72      0.72      0.72       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 17 features\n",
      "Accuracy of GNB classifier on training set: 0.74\n",
      "[[191  59]\n",
      " [ 85 212]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.73       250\n",
      "           1       0.78      0.71      0.75       297\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       547\n",
      "   macro avg       0.74      0.74      0.74       547\n",
      "weighted avg       0.74      0.74      0.74       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 18 features\n",
      "Accuracy of GNB classifier on training set: 0.77\n",
      "[[166  84]\n",
      " [ 43 254]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72       250\n",
      "           1       0.75      0.86      0.80       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.76      0.76       547\n",
      "weighted avg       0.77      0.77      0.76       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 19 features\n",
      "Accuracy of GNB classifier on training set: 0.76\n",
      "[[166  84]\n",
      " [ 47 250]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.72       250\n",
      "           1       0.75      0.84      0.79       297\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       547\n",
      "   macro avg       0.76      0.75      0.75       547\n",
      "weighted avg       0.76      0.76      0.76       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 20 features\n",
      "Accuracy of GNB classifier on training set: 0.76\n",
      "[[166  84]\n",
      " [ 47 250]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.72       250\n",
      "           1       0.75      0.84      0.79       297\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       547\n",
      "   macro avg       0.76      0.75      0.75       547\n",
      "weighted avg       0.76      0.76      0.76       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 21 features\n",
      "Accuracy of GNB classifier on training set: 0.76\n",
      "[[166  84]\n",
      " [ 47 250]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.72       250\n",
      "           1       0.75      0.84      0.79       297\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       547\n",
      "   macro avg       0.76      0.75      0.75       547\n",
      "weighted avg       0.76      0.76      0.76       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 22 features\n",
      "Accuracy of GNB classifier on training set: 0.75\n",
      "[[164  86]\n",
      " [ 51 246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.66      0.71       250\n",
      "           1       0.74      0.83      0.78       297\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       547\n",
      "   macro avg       0.75      0.74      0.74       547\n",
      "weighted avg       0.75      0.75      0.75       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------\n",
      "Model based on top 23 features\n",
      "Accuracy of GNB classifier on training set: 0.76\n",
      "[[168  82]\n",
      " [ 49 248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72       250\n",
      "           1       0.75      0.84      0.79       297\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       547\n",
      "   macro avg       0.76      0.75      0.76       547\n",
      "weighted avg       0.76      0.76      0.76       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 24 features\n",
      "Accuracy of GNB classifier on training set: 0.75\n",
      "[[166  84]\n",
      " [ 51 246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.66      0.71       250\n",
      "           1       0.75      0.83      0.78       297\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       547\n",
      "   macro avg       0.76      0.75      0.75       547\n",
      "weighted avg       0.75      0.75      0.75       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 25 features\n",
      "Accuracy of GNB classifier on training set: 0.76\n",
      "[[171  79]\n",
      " [ 50 247]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.73       250\n",
      "           1       0.76      0.83      0.79       297\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       547\n",
      "   macro avg       0.77      0.76      0.76       547\n",
      "weighted avg       0.77      0.76      0.76       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 26 features\n",
      "Accuracy of GNB classifier on training set: 0.76\n",
      "[[170  80]\n",
      " [ 51 246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72       250\n",
      "           1       0.75      0.83      0.79       297\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       547\n",
      "   macro avg       0.76      0.75      0.76       547\n",
      "weighted avg       0.76      0.76      0.76       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 27 features\n",
      "Accuracy of GNB classifier on training set: 0.76\n",
      "[[170  80]\n",
      " [ 52 245]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72       250\n",
      "           1       0.75      0.82      0.79       297\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       547\n",
      "   macro avg       0.76      0.75      0.75       547\n",
      "weighted avg       0.76      0.76      0.76       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 28 features\n",
      "Accuracy of GNB classifier on training set: 0.71\n",
      "[[111 139]\n",
      " [ 19 278]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.44      0.58       250\n",
      "           1       0.67      0.94      0.78       297\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       547\n",
      "   macro avg       0.76      0.69      0.68       547\n",
      "weighted avg       0.75      0.71      0.69       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 29 features\n",
      "Accuracy of GNB classifier on training set: 0.71\n",
      "[[111 139]\n",
      " [ 19 278]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.44      0.58       250\n",
      "           1       0.67      0.94      0.78       297\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       547\n",
      "   macro avg       0.76      0.69      0.68       547\n",
      "weighted avg       0.75      0.71      0.69       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 30 features\n",
      "Accuracy of GNB classifier on training set: 0.70\n",
      "[[106 144]\n",
      " [ 19 278]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.42      0.57       250\n",
      "           1       0.66      0.94      0.77       297\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       547\n",
      "   macro avg       0.75      0.68      0.67       547\n",
      "weighted avg       0.75      0.70      0.68       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 31 features\n",
      "Accuracy of GNB classifier on training set: 0.65\n",
      "[[ 68 182]\n",
      " [  9 288]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.27      0.42       250\n",
      "           1       0.61      0.97      0.75       297\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       547\n",
      "   macro avg       0.75      0.62      0.58       547\n",
      "weighted avg       0.74      0.65      0.60       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 32 features\n",
      "Accuracy of GNB classifier on training set: 0.65\n",
      "[[ 68 182]\n",
      " [  9 288]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.27      0.42       250\n",
      "           1       0.61      0.97      0.75       297\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       547\n",
      "   macro avg       0.75      0.62      0.58       547\n",
      "weighted avg       0.74      0.65      0.60       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 33 features\n",
      "Accuracy of GNB classifier on training set: 0.65\n",
      "[[ 69 181]\n",
      " [ 10 287]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.28      0.42       250\n",
      "           1       0.61      0.97      0.75       297\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       547\n",
      "   macro avg       0.74      0.62      0.58       547\n",
      "weighted avg       0.73      0.65      0.60       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 34 features\n",
      "Accuracy of GNB classifier on training set: 0.65\n",
      "[[ 72 178]\n",
      " [ 11 286]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.29      0.43       250\n",
      "           1       0.62      0.96      0.75       297\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       547\n",
      "   macro avg       0.74      0.63      0.59       547\n",
      "weighted avg       0.73      0.65      0.61       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 35 features\n",
      "Accuracy of GNB classifier on training set: 0.67\n",
      "[[ 79 171]\n",
      " [ 11 286]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.32      0.46       250\n",
      "           1       0.63      0.96      0.76       297\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       547\n",
      "   macro avg       0.75      0.64      0.61       547\n",
      "weighted avg       0.74      0.67      0.62       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 36 features\n",
      "Accuracy of GNB classifier on training set: 0.68\n",
      "[[ 84 166]\n",
      " [ 10 287]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.34      0.49       250\n",
      "           1       0.63      0.97      0.77       297\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       547\n",
      "   macro avg       0.76      0.65      0.63       547\n",
      "weighted avg       0.75      0.68      0.64       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 37 features\n",
      "Accuracy of GNB classifier on training set: 0.68\n",
      "[[ 84 166]\n",
      " [ 10 287]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.34      0.49       250\n",
      "           1       0.63      0.97      0.77       297\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       547\n",
      "   macro avg       0.76      0.65      0.63       547\n",
      "weighted avg       0.75      0.68      0.64       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 38 features\n",
      "Accuracy of GNB classifier on training set: 0.70\n",
      "[[103 147]\n",
      " [ 16 281]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.41      0.56       250\n",
      "           1       0.66      0.95      0.78       297\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       547\n",
      "   macro avg       0.76      0.68      0.67       547\n",
      "weighted avg       0.75      0.70      0.68       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of GNB classifier on training set: 0.71\n",
      "[[104 146]\n",
      " [ 15 282]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.42      0.56       250\n",
      "           1       0.66      0.95      0.78       297\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       547\n",
      "   macro avg       0.77      0.68      0.67       547\n",
      "weighted avg       0.76      0.71      0.68       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of GNB classifier on training set: 0.71\n",
      "[[104 146]\n",
      " [ 15 282]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.42      0.56       250\n",
      "           1       0.66      0.95      0.78       297\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       547\n",
      "   macro avg       0.77      0.68      0.67       547\n",
      "weighted avg       0.76      0.71      0.68       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GNB classifier on training set: 0.71\n",
      "[[104 146]\n",
      " [ 15 282]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.42      0.56       250\n",
      "           1       0.66      0.95      0.78       297\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       547\n",
      "   macro avg       0.77      0.68      0.67       547\n",
      "weighted avg       0.76      0.71      0.68       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of GNB classifier on training set: 0.71\n",
      "[[104 146]\n",
      " [ 15 282]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.42      0.56       250\n",
      "           1       0.66      0.95      0.78       297\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       547\n",
      "   macro avg       0.77      0.68      0.67       547\n",
      "weighted avg       0.76      0.71      0.68       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# loop to identify efficacy of models\n",
    "for list_item in list_of_feature_lists:\n",
    "    gnb, y_pred, y_pred_proba = model.naive_bayes(list_item, X_train, y_train)\n",
    "    print('--------------------------------------------------------')\n",
    "    print(f'Model based on top {len(list_item)} features')\n",
    "    print('Accuracy of GNB classifier on training set: {:.2f}'.format(gnb.score(X_train[list_item], y_train)))\n",
    "    print(confusion_matrix(y_train, y_pred))\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression is a great tool for this particular problem because it is tailored to a binary outcome target.  Because we are looking at Reassault Cases vs Single Assault cases, we can expect this to perform fairly well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Results: \n",
      "[0.69090909 0.68181818 0.72477064 0.77981651 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 1 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.73\n",
      "[[163  87]\n",
      " [ 62 235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.69       250\n",
      "           1       0.73      0.79      0.76       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.72      0.72       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.7        0.67272727 0.72477064 0.74311927 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 2 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.73\n",
      "[[144 106]\n",
      " [ 42 255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.58      0.66       250\n",
      "           1       0.71      0.86      0.78       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.74      0.72      0.72       547\n",
      "weighted avg       0.74      0.73      0.72       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.69090909 0.68181818 0.75229358 0.74311927 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 3 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.73\n",
      "[[159  91]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.64      0.69       250\n",
      "           1       0.73      0.82      0.77       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.74      0.73      0.73       547\n",
      "weighted avg       0.74      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.69090909 0.7706422  0.71559633 0.71559633]\n",
      "--------------------------------------------------------\n",
      "Model based on top 4 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.73\n",
      "[[171  79]\n",
      " [ 70 227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.70       250\n",
      "           1       0.74      0.76      0.75       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.72      0.72       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.66363636 0.7706422  0.68807339 0.72477064]\n",
      "--------------------------------------------------------\n",
      "Model based on top 5 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.73\n",
      "[[177  73]\n",
      " [ 75 222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.71       250\n",
      "           1       0.75      0.75      0.75       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.73      0.73       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.70909091 0.67272727 0.78899083 0.72477064 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 6 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.73\n",
      "[[177  73]\n",
      " [ 72 225]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       250\n",
      "           1       0.76      0.76      0.76       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.73      0.73       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.68181818 0.7706422  0.74311927 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 7 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.76\n",
      "[[179  71]\n",
      " [ 58 239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74       250\n",
      "           1       0.77      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       547\n",
      "   macro avg       0.76      0.76      0.76       547\n",
      "weighted avg       0.76      0.76      0.76       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.7        0.75229358 0.74311927 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 8 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[178  72]\n",
      " [ 51 246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74       250\n",
      "           1       0.77      0.83      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.77      0.77       547\n",
      "weighted avg       0.78      0.78      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.7        0.79816514 0.75229358 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 9 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[178  72]\n",
      " [ 50 247]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74       250\n",
      "           1       0.77      0.83      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.77      0.77       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.73636364 0.77981651 0.74311927 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 10 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[182  68]\n",
      " [ 53 244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       250\n",
      "           1       0.78      0.82      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.77      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.72727273 0.78899083 0.75229358 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 11 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.77\n",
      "[[182  68]\n",
      " [ 58 239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74       250\n",
      "           1       0.78      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.72727273 0.79816514 0.74311927 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 12 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.77\n",
      "[[182  68]\n",
      " [ 58 239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74       250\n",
      "           1       0.78      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.71818182 0.78899083 0.74311927 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 13 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.77\n",
      "[[181  69]\n",
      " [ 59 238]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74       250\n",
      "           1       0.78      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.76      0.76      0.76       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69090909 0.72727273 0.78899083 0.75229358 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 14 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.77\n",
      "[[185  65]\n",
      " [ 61 236]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75       250\n",
      "           1       0.78      0.79      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.68181818 0.72727273 0.78899083 0.74311927 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 15 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.77\n",
      "[[183  67]\n",
      " [ 61 236]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       250\n",
      "           1       0.78      0.79      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.76      0.76      0.76       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.68181818 0.75454545 0.77981651 0.74311927 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 16 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.77\n",
      "[[184  66]\n",
      " [ 60 237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74       250\n",
      "           1       0.78      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.7        0.73636364 0.78899083 0.7706422  0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 17 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[187  63]\n",
      " [ 59 238]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75       250\n",
      "           1       0.79      0.80      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.77      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.70909091 0.75454545 0.75229358 0.75229358 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 18 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[186  64]\n",
      " [ 56 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76       250\n",
      "           1       0.79      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.7        0.75454545 0.78899083 0.76146789 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 19 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[186  64]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       250\n",
      "           1       0.79      0.82      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.70909091 0.73636364 0.75229358 0.76146789 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 20 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.79\n",
      "[[189  61]\n",
      " [ 56 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76       250\n",
      "           1       0.80      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.79      0.79      0.79       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.72727273 0.75229358 0.74311927 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 21 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[189  61]\n",
      " [ 62 235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       250\n",
      "           1       0.79      0.79      0.79       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.71818182 0.74311927 0.7706422  0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 22 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.79\n",
      "[[192  58]\n",
      " [ 58 239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       250\n",
      "           1       0.80      0.80      0.80       297\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       547\n",
      "   macro avg       0.79      0.79      0.79       547\n",
      "weighted avg       0.79      0.79      0.79       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.72727273 0.72477064 0.77981651 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 23 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.79\n",
      "[[192  58]\n",
      " [ 57 240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       250\n",
      "           1       0.81      0.81      0.81       297\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       547\n",
      "   macro avg       0.79      0.79      0.79       547\n",
      "weighted avg       0.79      0.79      0.79       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.71818182 0.75229358 0.76146789 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 24 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.79\n",
      "[[192  58]\n",
      " [ 58 239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       250\n",
      "           1       0.80      0.80      0.80       297\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       547\n",
      "   macro avg       0.79      0.79      0.79       547\n",
      "weighted avg       0.79      0.79      0.79       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.72727273 0.75229358 0.76146789 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 25 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[188  62]\n",
      " [ 59 238]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76       250\n",
      "           1       0.79      0.80      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.72727273 0.75229358 0.77981651 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 26 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.77\n",
      "[[186  64]\n",
      " [ 60 237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       250\n",
      "           1       0.79      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70909091 0.72727273 0.75229358 0.77981651 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 27 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.77\n",
      "[[188  62]\n",
      " [ 62 235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       250\n",
      "           1       0.79      0.79      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.70909091 0.72727273 0.75229358 0.75229358 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 28 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[188  62]\n",
      " [ 61 236]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75       250\n",
      "           1       0.79      0.79      0.79       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.72727273 0.73394495 0.77981651 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 29 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[190  60]\n",
      " [ 58 239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76       250\n",
      "           1       0.80      0.80      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.76363636 0.70909091 0.7706422  0.73394495 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 30 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.79\n",
      "[[193  57]\n",
      " [ 57 240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       250\n",
      "           1       0.81      0.81      0.81       297\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       547\n",
      "   macro avg       0.79      0.79      0.79       547\n",
      "weighted avg       0.79      0.79      0.79       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.76363636 0.70909091 0.7706422  0.73394495 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 31 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.79\n",
      "[[193  57]\n",
      " [ 56 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.77       250\n",
      "           1       0.81      0.81      0.81       297\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       547\n",
      "   macro avg       0.79      0.79      0.79       547\n",
      "weighted avg       0.79      0.79      0.79       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.70909091 0.70909091 0.76146789 0.73394495 0.75229358]\n",
      "--------------------------------------------------------\n",
      "Model based on top 32 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[186  64]\n",
      " [ 58 239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       250\n",
      "           1       0.79      0.80      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.77      0.77       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.71818182 0.72477064 0.74311927 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 33 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[184  66]\n",
      " [ 56 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       250\n",
      "           1       0.79      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.77      0.77       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.72727273 0.72477064 0.7706422  0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 34 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.78\n",
      "[[186  64]\n",
      " [ 56 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76       250\n",
      "           1       0.79      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.76363636 0.75229358 0.77981651 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 35 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.80\n",
      "[[191  59]\n",
      " [ 48 249]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78       250\n",
      "           1       0.81      0.84      0.82       297\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       547\n",
      "   macro avg       0.80      0.80      0.80       547\n",
      "weighted avg       0.80      0.80      0.80       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.77272727 0.74311927 0.73394495 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 36 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.80\n",
      "[[188  62]\n",
      " [ 49 248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77       250\n",
      "           1       0.80      0.84      0.82       297\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       547\n",
      "   macro avg       0.80      0.79      0.79       547\n",
      "weighted avg       0.80      0.80      0.80       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.77272727 0.74311927 0.76146789 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 37 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.80\n",
      "[[188  62]\n",
      " [ 49 248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77       250\n",
      "           1       0.80      0.84      0.82       297\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       547\n",
      "   macro avg       0.80      0.79      0.79       547\n",
      "weighted avg       0.80      0.80      0.80       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.76363636 0.74311927 0.76146789 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 38 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.80\n",
      "[[188  62]\n",
      " [ 49 248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77       250\n",
      "           1       0.80      0.84      0.82       297\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       547\n",
      "   macro avg       0.80      0.79      0.79       547\n",
      "weighted avg       0.80      0.80      0.80       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.76363636 0.74311927 0.76146789 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.80\n",
      "[[189  61]\n",
      " [ 50 247]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77       250\n",
      "           1       0.80      0.83      0.82       297\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       547\n",
      "   macro avg       0.80      0.79      0.79       547\n",
      "weighted avg       0.80      0.80      0.80       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Results: \n",
      "[0.74545455 0.76363636 0.74311927 0.76146789 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.80\n",
      "[[189  61]\n",
      " [ 50 247]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77       250\n",
      "           1       0.80      0.83      0.82       297\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       547\n",
      "   macro avg       0.80      0.79      0.79       547\n",
      "weighted avg       0.80      0.80      0.80       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.76363636 0.74311927 0.76146789 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.80\n",
      "[[189  61]\n",
      " [ 50 247]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77       250\n",
      "           1       0.80      0.83      0.82       297\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       547\n",
      "   macro avg       0.80      0.79      0.79       547\n",
      "weighted avg       0.80      0.80      0.80       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.76363636 0.74311927 0.76146789 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Logistic Regression classifier on training set: 0.80\n",
      "[[189  61]\n",
      " [ 50 247]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77       250\n",
      "           1       0.80      0.83      0.82       297\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       547\n",
      "   macro avg       0.80      0.79      0.79       547\n",
      "weighted avg       0.80      0.80      0.80       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# loop to identify efficacy of models\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for list_item in list_of_feature_lists:\n",
    "    clf, y_pred, y_pred_proba = model.log_reg(list_item, X_train, y_train, solver='liblinear')\n",
    "    print('--------------------------------------------------------')\n",
    "    print(f'Model based on top {len(list_item)} features')\n",
    "    print('Accuracy of Logistic Regression classifier on training set: {:.2f}'.format(clf.score(X_train[list_item], y_train)))\n",
    "    print(confusion_matrix(y_train, y_pred))\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see efficacy drop off after 10 features for logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we will investigate Decision Tree modeling.  This type of model would be a good fit for this scenario, as the answers to the survey were largely binary, allowing for a branch split to be largely intuitive.  Let's first look at a series of trees with a reasonable base of hyperparameters, in this case a maximum depth of 3 and a maximum feature selection of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "2          2           3.0  0.654479\n",
      "1          2           1.0  0.669104\n",
      "7          4           1.0  0.685558\n",
      "6          4           NaN  0.689214\n",
      "4          3           1.0  0.691042\n",
      "5          3           3.0  0.694698\n",
      "8          4           3.0  0.716636\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.731261\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.65454545 0.71559633 0.73394495 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 19 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.74\n",
      "[[147 103]\n",
      " [ 39 258]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.59      0.67       250\n",
      "           1       0.71      0.87      0.78       297\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       547\n",
      "   macro avg       0.75      0.73      0.73       547\n",
      "weighted avg       0.75      0.74      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          2           1.0  0.594150\n",
      "4          3           1.0  0.645338\n",
      "5          3           3.0  0.678245\n",
      "8          4           3.0  0.683729\n",
      "7          4           1.0  0.685558\n",
      "6          4           NaN  0.698355\n",
      "0          2           NaN  0.720293\n",
      "2          2           3.0  0.722121\n",
      "3          3           NaN  0.738574\n",
      "Cross Validation Results: \n",
      "[0.65454545 0.67272727 0.66972477 0.75229358 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 20 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.74\n",
      "[[149 101]\n",
      " [ 41 256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.60      0.68       250\n",
      "           1       0.72      0.86      0.78       297\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       547\n",
      "   macro avg       0.75      0.73      0.73       547\n",
      "weighted avg       0.75      0.74      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "2          2           3.0  0.667276\n",
      "7          4           1.0  0.696527\n",
      "6          4           NaN  0.702011\n",
      "5          3           3.0  0.703839\n",
      "4          3           1.0  0.714808\n",
      "0          2           NaN  0.720293\n",
      "1          2           1.0  0.720293\n",
      "8          4           3.0  0.725777\n",
      "3          3           NaN  0.738574\n",
      "Cross Validation Results: \n",
      "[0.70909091 0.67272727 0.70642202 0.74311927 0.71559633]\n",
      "--------------------------------------------------------\n",
      "Model based on top 21 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.74\n",
      "[[149 101]\n",
      " [ 42 255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.60      0.68       250\n",
      "           1       0.72      0.86      0.78       297\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       547\n",
      "   macro avg       0.75      0.73      0.73       547\n",
      "weighted avg       0.75      0.74      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "5          3           3.0  0.643510\n",
      "2          2           3.0  0.648995\n",
      "4          3           1.0  0.654479\n",
      "7          4           1.0  0.663620\n",
      "1          2           1.0  0.692870\n",
      "6          4           NaN  0.702011\n",
      "8          4           3.0  0.707495\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.738574\n",
      "Cross Validation Results: \n",
      "[0.7        0.64545455 0.76146789 0.75229358 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 22 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.75\n",
      "[[165  85]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.70       250\n",
      "           1       0.74      0.82      0.78       297\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       547\n",
      "   macro avg       0.75      0.74      0.74       547\n",
      "weighted avg       0.75      0.75      0.74       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "8          4           3.0  0.672761\n",
      "1          2           1.0  0.680073\n",
      "7          4           1.0  0.683729\n",
      "6          4           NaN  0.700183\n",
      "0          2           NaN  0.720293\n",
      "4          3           1.0  0.731261\n",
      "3          3           NaN  0.738574\n",
      "2          2           3.0  0.740402\n",
      "5          3           3.0  0.740402\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.73636364 0.64220183 0.68807339 0.63302752]\n",
      "--------------------------------------------------------\n",
      "Model based on top 23 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.74\n",
      "[[209  41]\n",
      " [103 194]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.84      0.74       250\n",
      "           1       0.83      0.65      0.73       297\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       547\n",
      "   macro avg       0.75      0.74      0.74       547\n",
      "weighted avg       0.75      0.74      0.74       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "2          2           3.0  0.650823\n",
      "5          3           3.0  0.652651\n",
      "8          4           3.0  0.681901\n",
      "7          4           1.0  0.691042\n",
      "1          2           1.0  0.700183\n",
      "6          4           NaN  0.702011\n",
      "4          3           1.0  0.707495\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.738574\n",
      "Cross Validation Results: \n",
      "[0.63636364 0.66363636 0.71559633 0.75229358 0.75229358]\n",
      "--------------------------------------------------------\n",
      "Model based on top 24 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.75\n",
      "[[166  84]\n",
      " [ 55 242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.70       250\n",
      "           1       0.74      0.81      0.78       297\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       547\n",
      "   macro avg       0.75      0.74      0.74       547\n",
      "weighted avg       0.75      0.75      0.74       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "2          2           3.0  0.669104\n",
      "4          3           1.0  0.678245\n",
      "1          2           1.0  0.689214\n",
      "7          4           1.0  0.694698\n",
      "5          3           3.0  0.698355\n",
      "6          4           NaN  0.700183\n",
      "8          4           3.0  0.712980\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.738574\n",
      "Cross Validation Results: \n",
      "[0.68181818 0.68181818 0.70642202 0.76146789 0.67889908]\n",
      "--------------------------------------------------------\n",
      "Model based on top 25 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.71\n",
      "[[175  75]\n",
      " [ 81 216]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69       250\n",
      "           1       0.74      0.73      0.73       297\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       547\n",
      "   macro avg       0.71      0.71      0.71       547\n",
      "weighted avg       0.72      0.71      0.72       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          2           1.0  0.634369\n",
      "2          2           3.0  0.654479\n",
      "7          4           1.0  0.667276\n",
      "4          3           1.0  0.678245\n",
      "6          4           NaN  0.702011\n",
      "8          4           3.0  0.712980\n",
      "0          2           NaN  0.720293\n",
      "5          3           3.0  0.722121\n",
      "3          3           NaN  0.738574\n",
      "Cross Validation Results: \n",
      "[0.68181818 0.7        0.71559633 0.75229358 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 26 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.73\n",
      "[[180  70]\n",
      " [ 75 222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.71       250\n",
      "           1       0.76      0.75      0.75       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.73      0.73       547\n",
      "weighted avg       0.74      0.73      0.74       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "2          2           3.0  0.654479\n",
      "5          3           3.0  0.674589\n",
      "1          2           1.0  0.696527\n",
      "6          4           NaN  0.700183\n",
      "7          4           1.0  0.712980\n",
      "0          2           NaN  0.720293\n",
      "4          3           1.0  0.720293\n",
      "8          4           3.0  0.729433\n",
      "3          3           NaN  0.738574\n",
      "Cross Validation Results: \n",
      "[0.68181818 0.70909091 0.69724771 0.66055046 0.71559633]\n",
      "--------------------------------------------------------\n",
      "Model based on top 27 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.72\n",
      "[[150 100]\n",
      " [ 52 245]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.60      0.66       250\n",
      "           1       0.71      0.82      0.76       297\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       547\n",
      "   macro avg       0.73      0.71      0.71       547\n",
      "weighted avg       0.72      0.72      0.72       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "4          3           1.0  0.616088\n",
      "1          2           1.0  0.638026\n",
      "2          2           3.0  0.667276\n",
      "5          3           3.0  0.672761\n",
      "6          4           NaN  0.702011\n",
      "7          4           1.0  0.707495\n",
      "0          2           NaN  0.720293\n",
      "8          4           3.0  0.720293\n",
      "3          3           NaN  0.738574\n",
      "Cross Validation Results: \n",
      "[0.66363636 0.67272727 0.6146789  0.69724771 0.6146789 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 28 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.70\n",
      "[[200  50]\n",
      " [113 184]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.80      0.71       250\n",
      "           1       0.79      0.62      0.69       297\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       547\n",
      "   macro avg       0.71      0.71      0.70       547\n",
      "weighted avg       0.72      0.70      0.70       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          2           1.0  0.659963\n",
      "4          3           1.0  0.659963\n",
      "7          4           1.0  0.705667\n",
      "6          4           NaN  0.718464\n",
      "0          2           NaN  0.720293\n",
      "2          2           3.0  0.727605\n",
      "8          4           3.0  0.727605\n",
      "5          3           3.0  0.736746\n",
      "3          3           NaN  0.742230\n",
      "Cross Validation Results: \n",
      "[0.67272727 0.68181818 0.72477064 0.76146789 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 29 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.73\n",
      "[[187  63]\n",
      " [ 84 213]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72       250\n",
      "           1       0.77      0.72      0.74       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.73      0.73       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "2          2           3.0  0.643510\n",
      "5          3           3.0  0.658135\n",
      "1          2           1.0  0.665448\n",
      "4          3           1.0  0.676417\n",
      "7          4           1.0  0.696527\n",
      "6          4           NaN  0.698355\n",
      "8          4           3.0  0.714808\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.742230\n",
      "Cross Validation Results: \n",
      "[0.67272727 0.70909091 0.68807339 0.68807339 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 30 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.74\n",
      "[[147 103]\n",
      " [ 41 256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.59      0.67       250\n",
      "           1       0.71      0.86      0.78       297\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       547\n",
      "   macro avg       0.75      0.72      0.73       547\n",
      "weighted avg       0.74      0.74      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "7          4           1.0  0.654479\n",
      "1          2           1.0  0.659963\n",
      "2          2           3.0  0.672761\n",
      "4          3           1.0  0.680073\n",
      "5          3           3.0  0.683729\n",
      "6          4           NaN  0.700183\n",
      "8          4           3.0  0.702011\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.742230\n",
      "Cross Validation Results: \n",
      "[0.7        0.64545455 0.58715596 0.77981651 0.71559633]\n",
      "--------------------------------------------------------\n",
      "Model based on top 31 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.73\n",
      "[[198  52]\n",
      " [ 97 200]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.73       250\n",
      "           1       0.79      0.67      0.73       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.73      0.73       547\n",
      "weighted avg       0.74      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "2          2           3.0  0.628885\n",
      "5          3           3.0  0.652651\n",
      "1          2           1.0  0.654479\n",
      "7          4           1.0  0.658135\n",
      "4          3           1.0  0.663620\n",
      "8          4           3.0  0.676417\n",
      "6          4           NaN  0.691042\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.742230\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.73636364 0.69724771 0.71559633 0.73394495]\n",
      "--------------------------------------------------------\n",
      "Model based on top 32 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.73\n",
      "[[180  70]\n",
      " [ 77 220]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       250\n",
      "           1       0.76      0.74      0.75       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.73      0.73       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          2           1.0  0.595978\n",
      "4          3           1.0  0.599634\n",
      "7          4           1.0  0.650823\n",
      "5          3           3.0  0.656307\n",
      "2          2           3.0  0.658135\n",
      "6          4           NaN  0.692870\n",
      "8          4           3.0  0.698355\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.736746\n",
      "Cross Validation Results: \n",
      "[0.66363636 0.62727273 0.65137615 0.73394495 0.75229358]\n",
      "--------------------------------------------------------\n",
      "Model based on top 33 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.73\n",
      "[[201  49]\n",
      " [101 196]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73       250\n",
      "           1       0.80      0.66      0.72       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.73      0.73       547\n",
      "weighted avg       0.74      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "2          2           3.0  0.632541\n",
      "1          2           1.0  0.652651\n",
      "7          4           1.0  0.674589\n",
      "4          3           1.0  0.676417\n",
      "6          4           NaN  0.691042\n",
      "8          4           3.0  0.691042\n",
      "5          3           3.0  0.702011\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.736746\n",
      "Cross Validation Results: \n",
      "[0.69090909 0.7        0.71559633 0.76146789 0.72477064]\n",
      "--------------------------------------------------------\n",
      "Model based on top 34 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.72\n",
      "[[164  86]\n",
      " [ 67 230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68       250\n",
      "           1       0.73      0.77      0.75       297\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       547\n",
      "   macro avg       0.72      0.72      0.72       547\n",
      "weighted avg       0.72      0.72      0.72       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          2           1.0  0.614260\n",
      "4          3           1.0  0.656307\n",
      "2          2           3.0  0.674589\n",
      "5          3           3.0  0.689214\n",
      "6          4           NaN  0.689214\n",
      "8          4           3.0  0.694698\n",
      "7          4           1.0  0.696527\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.736746\n",
      "Cross Validation Results: \n",
      "[0.65454545 0.66363636 0.71559633 0.66972477 0.71559633]\n",
      "--------------------------------------------------------\n",
      "Model based on top 35 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.72\n",
      "[[134 116]\n",
      " [ 39 258]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.54      0.63       250\n",
      "           1       0.69      0.87      0.77       297\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       547\n",
      "   macro avg       0.73      0.70      0.70       547\n",
      "weighted avg       0.73      0.72      0.71       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          2           1.0  0.632541\n",
      "7          4           1.0  0.658135\n",
      "2          2           3.0  0.659963\n",
      "5          3           3.0  0.659963\n",
      "4          3           1.0  0.665448\n",
      "6          4           NaN  0.685558\n",
      "8          4           3.0  0.698355\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.736746\n",
      "Cross Validation Results: \n",
      "[0.69090909 0.71818182 0.72477064 0.77981651 0.73394495]\n",
      "--------------------------------------------------------\n",
      "Model based on top 36 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.76\n",
      "[[183  67]\n",
      " [ 67 230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       250\n",
      "           1       0.77      0.77      0.77       297\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       547\n",
      "   macro avg       0.75      0.75      0.75       547\n",
      "weighted avg       0.76      0.76      0.76       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "7          4           1.0  0.623400\n",
      "2          2           3.0  0.643510\n",
      "5          3           3.0  0.661792\n",
      "1          2           1.0  0.665448\n",
      "6          4           NaN  0.685558\n",
      "8          4           3.0  0.689214\n",
      "4          3           1.0  0.692870\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.736746\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.68181818 0.76146789 0.74311927 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 37 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.75\n",
      "[[200  50]\n",
      " [ 86 211]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75       250\n",
      "           1       0.81      0.71      0.76       297\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       547\n",
      "   macro avg       0.75      0.76      0.75       547\n",
      "weighted avg       0.76      0.75      0.75       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "2          2           3.0  0.625229\n",
      "5          3           3.0  0.641682\n",
      "1          2           1.0  0.669104\n",
      "7          4           1.0  0.669104\n",
      "6          4           NaN  0.685558\n",
      "4          3           1.0  0.703839\n",
      "0          2           NaN  0.720293\n",
      "8          4           3.0  0.727605\n",
      "3          3           NaN  0.736746\n",
      "Cross Validation Results: \n",
      "[0.64545455 0.7        0.69724771 0.60550459 0.65137615]\n",
      "--------------------------------------------------------\n",
      "Model based on top 38 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.69\n",
      "[[181  69]\n",
      " [100 197]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68       250\n",
      "           1       0.74      0.66      0.70       297\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       547\n",
      "   macro avg       0.69      0.69      0.69       547\n",
      "weighted avg       0.70      0.69      0.69       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          2           1.0  0.572212\n",
      "4          3           1.0  0.625229\n",
      "2          2           3.0  0.647166\n",
      "7          4           1.0  0.658135\n",
      "5          3           3.0  0.659963\n",
      "8          4           3.0  0.681901\n",
      "6          4           NaN  0.689214\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.736746\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.64545455 0.73394495 0.72477064 0.66972477]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.73\n",
      "[[174  76]\n",
      " [ 74 223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       250\n",
      "           1       0.75      0.75      0.75       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.72      0.72      0.72       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          2           1.0  0.572212\n",
      "4          3           1.0  0.625229\n",
      "2          2           3.0  0.647166\n",
      "7          4           1.0  0.658135\n",
      "5          3           3.0  0.659963\n",
      "8          4           3.0  0.681901\n",
      "6          4           NaN  0.689214\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.736746\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.64545455 0.73394495 0.72477064 0.66972477]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.73\n",
      "[[174  76]\n",
      " [ 74 223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       250\n",
      "           1       0.75      0.75      0.75       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.72      0.72      0.72       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          2           1.0  0.572212\n",
      "4          3           1.0  0.625229\n",
      "2          2           3.0  0.647166\n",
      "7          4           1.0  0.658135\n",
      "5          3           3.0  0.659963\n",
      "8          4           3.0  0.681901\n",
      "6          4           NaN  0.689214\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.736746\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.64545455 0.73394495 0.72477064 0.66972477]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.73\n",
      "[[174  76]\n",
      " [ 74 223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       250\n",
      "           1       0.75      0.75      0.75       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.72      0.72      0.72       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          2           1.0  0.572212\n",
      "4          3           1.0  0.625229\n",
      "2          2           3.0  0.647166\n",
      "7          4           1.0  0.658135\n",
      "5          3           3.0  0.659963\n",
      "8          4           3.0  0.681901\n",
      "6          4           NaN  0.689214\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.736746\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.64545455 0.73394495 0.72477064 0.66972477]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.73\n",
      "[[174  76]\n",
      " [ 74 223]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       250\n",
      "           1       0.75      0.75      0.75       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.72      0.72      0.72       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# iterate through models with depth of 3 and 4 max features (gini)\n",
    "for list_item in list_of_feature_lists[18:]:\n",
    "    clf, y_pred, y_pred_proba = model.decision_tree(list_item, X_train, y_train, criterion='gini', max_depth=3, max_features=5)\n",
    "    print('--------------------------------------------------------')\n",
    "    print(f'Model based on top {len(list_item)} features')\n",
    "    print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf.score(X_train[list_item], y_train)))\n",
    "    print(confusion_matrix(y_train, y_pred))\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's dial up the depth to a level we might consider too high as a means to create a metric for overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.711152\n",
      "2          6           9.0  0.711152\n",
      "1          6           7.0  0.716636\n",
      "3          7           NaN  0.744059\n",
      "5          7           9.0  0.744059\n",
      "4          7           7.0  0.747715\n",
      "7          8           7.0  0.755027\n",
      "6          8           NaN  0.760512\n",
      "8          8           9.0  0.760512\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.78181818 0.71559633 0.74311927 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 9 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.85\n",
      "[[209  41]\n",
      " [ 41 256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       250\n",
      "           1       0.86      0.86      0.86       297\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       547\n",
      "   macro avg       0.85      0.85      0.85       547\n",
      "weighted avg       0.85      0.85      0.85       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.705667\n",
      "1          6           7.0  0.716636\n",
      "3          7           NaN  0.722121\n",
      "2          6           9.0  0.727605\n",
      "5          7           9.0  0.727605\n",
      "4          7           7.0  0.740402\n",
      "7          8           7.0  0.749543\n",
      "8          8           9.0  0.751371\n",
      "6          8           NaN  0.753199\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.79090909 0.70642202 0.81651376 0.78899083]\n",
      "--------------------------------------------------------\n",
      "Model based on top 10 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[206  44]\n",
      " [ 35 262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84       250\n",
      "           1       0.86      0.88      0.87       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.86      0.85      0.85       547\n",
      "weighted avg       0.86      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          6           7.0  0.709324\n",
      "2          6           9.0  0.712980\n",
      "3          7           NaN  0.712980\n",
      "0          6           NaN  0.716636\n",
      "5          7           9.0  0.720293\n",
      "6          8           NaN  0.723949\n",
      "4          7           7.0  0.725777\n",
      "8          8           9.0  0.727605\n",
      "7          8           7.0  0.745887\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.70909091 0.70642202 0.80733945 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 11 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.85\n",
      "[[225  25]\n",
      " [ 56 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       250\n",
      "           1       0.91      0.81      0.86       297\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       547\n",
      "   macro avg       0.85      0.86      0.85       547\n",
      "weighted avg       0.86      0.85      0.85       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.714808\n",
      "3          7           NaN  0.725777\n",
      "5          7           9.0  0.731261\n",
      "6          8           NaN  0.731261\n",
      "4          7           7.0  0.733090\n",
      "8          8           9.0  0.736746\n",
      "7          8           7.0  0.753199\n",
      "1          6           7.0  0.755027\n",
      "2          6           9.0  0.764168\n",
      "Cross Validation Results: \n",
      "[0.70909091 0.73636364 0.72477064 0.78899083 0.75229358]\n",
      "--------------------------------------------------------\n",
      "Model based on top 12 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[221  29]\n",
      " [ 49 248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       250\n",
      "           1       0.90      0.84      0.86       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.86      0.86      0.86       547\n",
      "weighted avg       0.86      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.707495\n",
      "4          7           7.0  0.707495\n",
      "5          7           9.0  0.714808\n",
      "1          6           7.0  0.718464\n",
      "2          6           9.0  0.722121\n",
      "3          7           NaN  0.725777\n",
      "8          8           9.0  0.729433\n",
      "6          8           NaN  0.731261\n",
      "7          8           7.0  0.747715\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.70909091 0.76146789 0.73394495 0.78899083]\n",
      "--------------------------------------------------------\n",
      "Model based on top 13 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.84\n",
      "[[220  30]\n",
      " [ 55 242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       250\n",
      "           1       0.89      0.81      0.85       297\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       547\n",
      "   macro avg       0.84      0.85      0.84       547\n",
      "weighted avg       0.85      0.84      0.84       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.711152\n",
      "2          6           9.0  0.722121\n",
      "7          8           7.0  0.722121\n",
      "1          6           7.0  0.723949\n",
      "5          7           9.0  0.723949\n",
      "4          7           7.0  0.731261\n",
      "3          7           NaN  0.738574\n",
      "6          8           NaN  0.738574\n",
      "8          8           9.0  0.749543\n",
      "Cross Validation Results: \n",
      "[0.7        0.75454545 0.78899083 0.74311927 0.79816514]\n",
      "--------------------------------------------------------\n",
      "Model based on top 14 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.85\n",
      "[[219  31]\n",
      " [ 53 244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       250\n",
      "           1       0.89      0.82      0.85       297\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       547\n",
      "   macro avg       0.85      0.85      0.85       547\n",
      "weighted avg       0.85      0.85      0.85       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.703839\n",
      "1          6           7.0  0.714808\n",
      "8          8           9.0  0.720293\n",
      "4          7           7.0  0.725777\n",
      "6          8           NaN  0.731261\n",
      "5          7           9.0  0.734918\n",
      "7          8           7.0  0.736746\n",
      "2          6           9.0  0.742230\n",
      "3          7           NaN  0.745887\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.71818182 0.73394495 0.77981651 0.82568807]\n",
      "--------------------------------------------------------\n",
      "Model based on top 15 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.84\n",
      "[[224  26]\n",
      " [ 60 237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       250\n",
      "           1       0.90      0.80      0.85       297\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       547\n",
      "   macro avg       0.84      0.85      0.84       547\n",
      "weighted avg       0.85      0.84      0.84       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "8          8           9.0  0.700183\n",
      "5          7           9.0  0.707495\n",
      "0          6           NaN  0.714808\n",
      "2          6           9.0  0.723949\n",
      "4          7           7.0  0.725777\n",
      "1          6           7.0  0.738574\n",
      "7          8           7.0  0.740402\n",
      "6          8           NaN  0.744059\n",
      "3          7           NaN  0.756856\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.69090909 0.71559633 0.72477064 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 16 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[227  23]\n",
      " [ 55 242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       250\n",
      "           1       0.91      0.81      0.86       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.86      0.86      0.86       547\n",
      "weighted avg       0.86      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.691042\n",
      "1          6           7.0  0.729433\n",
      "4          7           7.0  0.729433\n",
      "8          8           9.0  0.729433\n",
      "5          7           9.0  0.731261\n",
      "7          8           7.0  0.731261\n",
      "6          8           NaN  0.734918\n",
      "2          6           9.0  0.736746\n",
      "3          7           NaN  0.755027\n",
      "Cross Validation Results: \n",
      "[0.64545455 0.72727273 0.74311927 0.77981651 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 17 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[215  35]\n",
      " [ 41 256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       250\n",
      "           1       0.88      0.86      0.87       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.86      0.86      0.86       547\n",
      "weighted avg       0.86      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          6           7.0  0.687386\n",
      "0          6           NaN  0.696527\n",
      "2          6           9.0  0.703839\n",
      "5          7           9.0  0.707495\n",
      "4          7           7.0  0.711152\n",
      "8          8           9.0  0.718464\n",
      "6          8           NaN  0.731261\n",
      "7          8           7.0  0.731261\n",
      "3          7           NaN  0.733090\n",
      "Cross Validation Results: \n",
      "[0.68181818 0.75454545 0.74311927 0.75229358 0.79816514]\n",
      "--------------------------------------------------------\n",
      "Model based on top 18 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.85\n",
      "[[218  32]\n",
      " [ 48 249]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       250\n",
      "           1       0.89      0.84      0.86       297\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       547\n",
      "   macro avg       0.85      0.86      0.85       547\n",
      "weighted avg       0.86      0.85      0.85       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          6           7.0  0.680073\n",
      "2          6           9.0  0.691042\n",
      "4          7           7.0  0.691042\n",
      "0          6           NaN  0.703839\n",
      "8          8           9.0  0.709324\n",
      "5          7           9.0  0.718464\n",
      "7          8           7.0  0.725777\n",
      "6          8           NaN  0.729433\n",
      "3          7           NaN  0.733090\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.67272727 0.73394495 0.76146789 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 19 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.87\n",
      "[[219  31]\n",
      " [ 39 258]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       250\n",
      "           1       0.89      0.87      0.88       297\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       547\n",
      "   macro avg       0.87      0.87      0.87       547\n",
      "weighted avg       0.87      0.87      0.87       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.702011\n",
      "1          6           7.0  0.703839\n",
      "2          6           9.0  0.711152\n",
      "5          7           9.0  0.712980\n",
      "6          8           NaN  0.725777\n",
      "3          7           NaN  0.733090\n",
      "8          8           9.0  0.747715\n",
      "4          7           7.0  0.758684\n",
      "7          8           7.0  0.767824\n",
      "Cross Validation Results: \n",
      "[0.69090909 0.72727273 0.64220183 0.80733945 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 20 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.87\n",
      "[[219  31]\n",
      " [ 40 257]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       250\n",
      "           1       0.89      0.87      0.88       297\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       547\n",
      "   macro avg       0.87      0.87      0.87       547\n",
      "weighted avg       0.87      0.87      0.87       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.680073\n",
      "5          7           9.0  0.702011\n",
      "1          6           7.0  0.709324\n",
      "2          6           9.0  0.712980\n",
      "4          7           7.0  0.714808\n",
      "6          8           NaN  0.731261\n",
      "3          7           NaN  0.740402\n",
      "7          8           7.0  0.744059\n",
      "8          8           9.0  0.749543\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.72727273 0.69724771 0.81651376 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 21 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[199  51]\n",
      " [ 23 274]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.84       250\n",
      "           1       0.84      0.92      0.88       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.87      0.86      0.86       547\n",
      "weighted avg       0.87      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.685558\n",
      "4          7           7.0  0.700183\n",
      "5          7           9.0  0.703839\n",
      "2          6           9.0  0.707495\n",
      "1          6           7.0  0.712980\n",
      "7          8           7.0  0.731261\n",
      "6          8           NaN  0.738574\n",
      "3          7           NaN  0.765996\n",
      "8          8           9.0  0.773309\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.74545455 0.78899083 0.77981651 0.78899083]\n",
      "--------------------------------------------------------\n",
      "Model based on top 22 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[222  28]\n",
      " [ 49 248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       250\n",
      "           1       0.90      0.84      0.87       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.86      0.86      0.86       547\n",
      "weighted avg       0.86      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.687386\n",
      "2          6           9.0  0.702011\n",
      "5          7           9.0  0.702011\n",
      "1          6           7.0  0.725777\n",
      "4          7           7.0  0.727605\n",
      "8          8           9.0  0.738574\n",
      "6          8           NaN  0.744059\n",
      "3          7           NaN  0.755027\n",
      "7          8           7.0  0.780622\n",
      "Cross Validation Results: \n",
      "[0.69090909 0.71818182 0.75229358 0.79816514 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 23 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[214  36]\n",
      " [ 39 258]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85       250\n",
      "           1       0.88      0.87      0.87       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.86      0.86      0.86       547\n",
      "weighted avg       0.86      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "4          7           7.0  0.698355\n",
      "0          6           NaN  0.709324\n",
      "8          8           9.0  0.734918\n",
      "6          8           NaN  0.736746\n",
      "1          6           7.0  0.744059\n",
      "2          6           9.0  0.751371\n",
      "3          7           NaN  0.751371\n",
      "5          7           9.0  0.756856\n",
      "7          8           7.0  0.760512\n",
      "Cross Validation Results: \n",
      "[0.68181818 0.77272727 0.75229358 0.71559633 0.80733945]\n",
      "--------------------------------------------------------\n",
      "Model based on top 24 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[237  13]\n",
      " [ 63 234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86       250\n",
      "           1       0.95      0.79      0.86       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.87      0.87      0.86       547\n",
      "weighted avg       0.88      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.705667\n",
      "7          8           7.0  0.709324\n",
      "4          7           7.0  0.720293\n",
      "2          6           9.0  0.722121\n",
      "1          6           7.0  0.742230\n",
      "3          7           NaN  0.745887\n",
      "5          7           9.0  0.751371\n",
      "8          8           9.0  0.751371\n",
      "6          8           NaN  0.753199\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.72727273 0.73394495 0.72477064 0.71559633]\n",
      "--------------------------------------------------------\n",
      "Model based on top 25 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.90\n",
      "[[224  26]\n",
      " [ 31 266]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       250\n",
      "           1       0.91      0.90      0.90       297\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       547\n",
      "   macro avg       0.89      0.90      0.90       547\n",
      "weighted avg       0.90      0.90      0.90       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.705667\n",
      "4          7           7.0  0.712980\n",
      "1          6           7.0  0.736746\n",
      "8          8           9.0  0.736746\n",
      "7          8           7.0  0.740402\n",
      "2          6           9.0  0.742230\n",
      "5          7           9.0  0.747715\n",
      "3          7           NaN  0.749543\n",
      "6          8           NaN  0.755027\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.75454545 0.76146789 0.75229358 0.69724771]\n",
      "--------------------------------------------------------\n",
      "Model based on top 26 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[221  29]\n",
      " [ 46 251]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       250\n",
      "           1       0.90      0.85      0.87       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.86      0.86      0.86       547\n",
      "weighted avg       0.87      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.703839\n",
      "4          7           7.0  0.709324\n",
      "7          8           7.0  0.709324\n",
      "8          8           9.0  0.714808\n",
      "5          7           9.0  0.729433\n",
      "2          6           9.0  0.734918\n",
      "1          6           7.0  0.744059\n",
      "3          7           NaN  0.760512\n",
      "6          8           NaN  0.769653\n",
      "Cross Validation Results: \n",
      "[0.79090909 0.71818182 0.7706422  0.73394495 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 27 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.88\n",
      "[[236  14]\n",
      " [ 53 244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88       250\n",
      "           1       0.95      0.82      0.88       297\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       547\n",
      "   macro avg       0.88      0.88      0.88       547\n",
      "weighted avg       0.89      0.88      0.88       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "5          7           9.0  0.691042\n",
      "2          6           9.0  0.698355\n",
      "0          6           NaN  0.705667\n",
      "1          6           7.0  0.711152\n",
      "8          8           9.0  0.711152\n",
      "4          7           7.0  0.716636\n",
      "3          7           NaN  0.745887\n",
      "7          8           7.0  0.749543\n",
      "6          8           NaN  0.767824\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.75454545 0.67889908 0.74311927 0.73394495]\n",
      "--------------------------------------------------------\n",
      "Model based on top 28 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.84\n",
      "[[203  47]\n",
      " [ 41 256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       250\n",
      "           1       0.84      0.86      0.85       297\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       547\n",
      "   macro avg       0.84      0.84      0.84       547\n",
      "weighted avg       0.84      0.84      0.84       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "0          6           NaN  0.714808\n",
      "1          6           7.0  0.714808\n",
      "8          8           9.0  0.718464\n",
      "2          6           9.0  0.722121\n",
      "5          7           9.0  0.729433\n",
      "7          8           7.0  0.734918\n",
      "4          7           7.0  0.738574\n",
      "3          7           NaN  0.740402\n",
      "6          8           NaN  0.755027\n",
      "Cross Validation Results: \n",
      "[0.68181818 0.70909091 0.75229358 0.72477064 0.80733945]\n",
      "--------------------------------------------------------\n",
      "Model based on top 29 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.88\n",
      "[[239  11]\n",
      " [ 55 242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       250\n",
      "           1       0.96      0.81      0.88       297\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       547\n",
      "   macro avg       0.88      0.89      0.88       547\n",
      "weighted avg       0.89      0.88      0.88       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "4          7           7.0  0.689214\n",
      "5          7           9.0  0.709324\n",
      "1          6           7.0  0.720293\n",
      "7          8           7.0  0.720293\n",
      "0          6           NaN  0.725777\n",
      "2          6           9.0  0.725777\n",
      "6          8           NaN  0.725777\n",
      "3          7           NaN  0.727605\n",
      "8          8           9.0  0.745887\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.75454545 0.73394495 0.76146789 0.67889908]\n",
      "--------------------------------------------------------\n",
      "Model based on top 30 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.87\n",
      "[[226  24]\n",
      " [ 45 252]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.87       250\n",
      "           1       0.91      0.85      0.88       297\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       547\n",
      "   macro avg       0.87      0.88      0.87       547\n",
      "weighted avg       0.88      0.87      0.87       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          6           7.0  0.700183\n",
      "2          6           9.0  0.705667\n",
      "3          7           NaN  0.709324\n",
      "0          6           NaN  0.712980\n",
      "8          8           9.0  0.723949\n",
      "4          7           7.0  0.729433\n",
      "6          8           NaN  0.729433\n",
      "5          7           9.0  0.734918\n",
      "7          8           7.0  0.751371\n",
      "Cross Validation Results: \n",
      "[0.7        0.70909091 0.79816514 0.7706422  0.73394495]\n",
      "--------------------------------------------------------\n",
      "Model based on top 31 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.84\n",
      "[[218  32]\n",
      " [ 55 242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       250\n",
      "           1       0.88      0.81      0.85       297\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       547\n",
      "   macro avg       0.84      0.84      0.84       547\n",
      "weighted avg       0.84      0.84      0.84       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "5          7           9.0  0.705667\n",
      "7          8           7.0  0.707495\n",
      "1          6           7.0  0.723949\n",
      "0          6           NaN  0.725777\n",
      "2          6           9.0  0.729433\n",
      "3          7           NaN  0.729433\n",
      "4          7           7.0  0.729433\n",
      "6          8           NaN  0.731261\n",
      "8          8           9.0  0.760512\n",
      "Cross Validation Results: \n",
      "[0.70909091 0.7        0.73394495 0.70642202 0.73394495]\n",
      "--------------------------------------------------------\n",
      "Model based on top 32 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[225  25]\n",
      " [ 50 247]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       250\n",
      "           1       0.91      0.83      0.87       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.86      0.87      0.86       547\n",
      "weighted avg       0.87      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "4          7           7.0  0.711152\n",
      "7          8           7.0  0.712980\n",
      "8          8           9.0  0.712980\n",
      "5          7           9.0  0.716636\n",
      "2          6           9.0  0.718464\n",
      "0          6           NaN  0.722121\n",
      "1          6           7.0  0.722121\n",
      "6          8           NaN  0.733090\n",
      "3          7           NaN  0.738574\n",
      "Cross Validation Results: \n",
      "[0.67272727 0.72727273 0.73394495 0.71559633 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 33 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.85\n",
      "[[221  29]\n",
      " [ 51 246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85       250\n",
      "           1       0.89      0.83      0.86       297\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       547\n",
      "   macro avg       0.85      0.86      0.85       547\n",
      "weighted avg       0.86      0.85      0.85       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "2          6           9.0  0.712980\n",
      "4          7           7.0  0.718464\n",
      "0          6           NaN  0.722121\n",
      "3          7           NaN  0.734918\n",
      "5          7           9.0  0.736746\n",
      "6          8           NaN  0.744059\n",
      "1          6           7.0  0.745887\n",
      "8          8           9.0  0.753199\n",
      "7          8           7.0  0.755027\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.75454545 0.75229358 0.76146789 0.78899083]\n",
      "--------------------------------------------------------\n",
      "Model based on top 34 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[228  22]\n",
      " [ 53 244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86       250\n",
      "           1       0.92      0.82      0.87       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.86      0.87      0.86       547\n",
      "weighted avg       0.87      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          6           7.0  0.709324\n",
      "0          6           NaN  0.718464\n",
      "3          7           NaN  0.723949\n",
      "4          7           7.0  0.723949\n",
      "2          6           9.0  0.725777\n",
      "8          8           9.0  0.725777\n",
      "6          8           NaN  0.734918\n",
      "5          7           9.0  0.738574\n",
      "7          8           7.0  0.758684\n",
      "Cross Validation Results: \n",
      "[0.68181818 0.76363636 0.76146789 0.72477064 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 35 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.87\n",
      "[[224  26]\n",
      " [ 46 251]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       250\n",
      "           1       0.91      0.85      0.87       297\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       547\n",
      "   macro avg       0.87      0.87      0.87       547\n",
      "weighted avg       0.87      0.87      0.87       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "3          7           NaN  0.702011\n",
      "0          6           NaN  0.714808\n",
      "1          6           7.0  0.714808\n",
      "8          8           9.0  0.725777\n",
      "2          6           9.0  0.727605\n",
      "4          7           7.0  0.727605\n",
      "6          8           NaN  0.727605\n",
      "5          7           9.0  0.729433\n",
      "7          8           7.0  0.742230\n",
      "Cross Validation Results: \n",
      "[0.77272727 0.74545455 0.75229358 0.66972477 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 36 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.85\n",
      "[[201  49]\n",
      " [ 35 262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.83       250\n",
      "           1       0.84      0.88      0.86       297\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       547\n",
      "   macro avg       0.85      0.84      0.84       547\n",
      "weighted avg       0.85      0.85      0.85       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "3          7           NaN  0.709324\n",
      "5          7           9.0  0.714808\n",
      "0          6           NaN  0.720293\n",
      "7          8           7.0  0.720293\n",
      "4          7           7.0  0.722121\n",
      "6          8           NaN  0.729433\n",
      "2          6           9.0  0.731261\n",
      "1          6           7.0  0.740402\n",
      "8          8           9.0  0.742230\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.72727273 0.66055046 0.68807339 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 37 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[244   6]\n",
      " [ 69 228]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.98      0.87       250\n",
      "           1       0.97      0.77      0.86       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.88      0.87      0.86       547\n",
      "weighted avg       0.89      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "3          7           NaN  0.707495\n",
      "8          8           9.0  0.718464\n",
      "2          6           9.0  0.720293\n",
      "6          8           NaN  0.720293\n",
      "0          6           NaN  0.723949\n",
      "5          7           9.0  0.723949\n",
      "7          8           7.0  0.734918\n",
      "4          7           7.0  0.736746\n",
      "1          6           7.0  0.747715\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.64545455 0.74311927 0.67889908 0.67889908]\n",
      "--------------------------------------------------------\n",
      "Model based on top 38 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.87\n",
      "[[223  27]\n",
      " [ 45 252]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       250\n",
      "           1       0.90      0.85      0.88       297\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       547\n",
      "   macro avg       0.87      0.87      0.87       547\n",
      "weighted avg       0.87      0.87      0.87       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          6           7.0  0.669104\n",
      "2          6           9.0  0.692870\n",
      "7          8           7.0  0.692870\n",
      "3          7           NaN  0.711152\n",
      "0          6           NaN  0.714808\n",
      "8          8           9.0  0.718464\n",
      "5          7           9.0  0.723949\n",
      "4          7           7.0  0.727605\n",
      "6          8           NaN  0.740402\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.73636364 0.73394495 0.71559633 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[230  20]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       250\n",
      "           1       0.92      0.82      0.87       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.87      0.87      0.86       547\n",
      "weighted avg       0.87      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          6           7.0  0.669104\n",
      "2          6           9.0  0.692870\n",
      "7          8           7.0  0.692870\n",
      "3          7           NaN  0.711152\n",
      "0          6           NaN  0.714808\n",
      "8          8           9.0  0.718464\n",
      "5          7           9.0  0.723949\n",
      "4          7           7.0  0.727605\n",
      "6          8           NaN  0.740402\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.73636364 0.73394495 0.71559633 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[230  20]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       250\n",
      "           1       0.92      0.82      0.87       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.87      0.87      0.86       547\n",
      "weighted avg       0.87      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          6           7.0  0.669104\n",
      "2          6           9.0  0.692870\n",
      "7          8           7.0  0.692870\n",
      "3          7           NaN  0.711152\n",
      "0          6           NaN  0.714808\n",
      "8          8           9.0  0.718464\n",
      "5          7           9.0  0.723949\n",
      "4          7           7.0  0.727605\n",
      "6          8           NaN  0.740402\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.73636364 0.73394495 0.71559633 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[230  20]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       250\n",
      "           1       0.92      0.82      0.87       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.87      0.87      0.86       547\n",
      "weighted avg       0.87      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "1          6           7.0  0.669104\n",
      "2          6           9.0  0.692870\n",
      "7          8           7.0  0.692870\n",
      "3          7           NaN  0.711152\n",
      "0          6           NaN  0.714808\n",
      "8          8           9.0  0.718464\n",
      "5          7           9.0  0.723949\n",
      "4          7           7.0  0.727605\n",
      "6          8           NaN  0.740402\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.73636364 0.73394495 0.71559633 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.86\n",
      "[[230  20]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       250\n",
      "           1       0.92      0.82      0.87       297\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       547\n",
      "   macro avg       0.87      0.87      0.86       547\n",
      "weighted avg       0.87      0.86      0.86       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# set parameters for gridsearch cv\n",
    "params = {'max_depth': [6, 7, 8],\n",
    "          'max_features': [None, 7, 9]}\n",
    "# iterate through models with depth of 7 and 8 max features (gini)\n",
    "for list_item in list_of_feature_lists[8:]:\n",
    "    clf, y_pred, y_pred_proba = model.decision_tree(list_item, X_train, y_train, params = params, criterion='gini', max_depth=7, max_features=8)\n",
    "    print('--------------------------------------------------------')\n",
    "    print(f'Model based on top {len(list_item)} features')\n",
    "    print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf.score(X_train[list_item], y_train)))\n",
    "    print(confusion_matrix(y_train, y_pred))\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the Decision Tree models with a large depth, we see that we can break 90% accuracy, but we sacrifice reproducability.  The cross validation for a model based around the top 25 features (with max depth 7 and max features 8) performs at 90% accuracy overall on our training set but upon inspecting the cross validation it drops down to the consistent low 70's.  This is a model that would not reproduce well on the Test set.  In other words, a model such as this will have an even lower generizability over our simplest naive models that we inspected earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid cv results: \n",
      "   max_depth  max_features     score\n",
      "2          2           3.0  0.669104\n",
      "4          3           1.0  0.678245\n",
      "1          2           1.0  0.689214\n",
      "7          4           1.0  0.694698\n",
      "5          3           3.0  0.698355\n",
      "6          4           NaN  0.700183\n",
      "8          4           3.0  0.712980\n",
      "0          2           NaN  0.720293\n",
      "3          3           NaN  0.738574\n",
      "Cross Validation Results: \n",
      "[0.69090909 0.68181818 0.72477064 0.77981651 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 25 features\n",
      "Accuracy of Decision Tree classifier on training set: 0.73\n",
      "[[163  87]\n",
      " [ 62 235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.69       250\n",
      "           1       0.73      0.79      0.76       297\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       547\n",
      "   macro avg       0.73      0.72      0.72       547\n",
      "weighted avg       0.73      0.73      0.73       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# single Decision tree with a maximum depth of 1 with first 25 features by importance\n",
    "clf, y_pred, y_pred_proba = model.decision_tree(features[0:25], X_train, y_train, criterion='gini', max_depth=1, max_features=25)\n",
    "print('--------------------------------------------------------')\n",
    "print(f'Model based on top {len(features[0:25])} features')\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'.format(clf.score(X_train[features[0:25]], y_train)))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at a decision tree selecting from 25 features with a single branch of depth.  We have a rough 70% accuracy simply from this single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEECAIAAACp6mh2AAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOyddVyTXRvHz4LubgEJaSQMUBBQsBUTRAzAQMIObEwMDHxQJBRbRBEVTB4JQVQE6ZIG6e7Y2N4/7uedY8BGDAZ6vh/+YOdc9znX2eDayd9BEYlEAIFAICMPmtEOQCCQvwUYbiAQyCgBww0EAhklsIx2YLzS2dmZnp5eVVXV3NzMaF8gw4WFhYWPj09VVZWfn5/RvvzJwHAzOOrr6+/duxccHPz582c8Hs9odyB0RkFRccnixTY2Nqqqqoz25Q8EBVemBkhbW9uFCxcuXryIRmNMFy6dNcdMTVNbVEycg5OL0a5BhktXZ2ddXU12RtqX6Mj3IcGF+XmLlyy5fOmSvLw8o137o4DhZkAEBwfv2Lmzob7Bae+htbZbYIj5gyESiVEf35875lKYn7tr167jx4+zsrIy2qk/BBhuaEAkEg8fPnzu3LmVVuv3HzsjKCzCaI8gowEej3/k73P5zHEVFeUXL14ICwsz2qM/ARhuqNHe3r5u3bqQkJCzV71WrFnPaHcgo01eTvYmy6VEQvfr0FA4mzN8YLjpFwKBsHr16o/hET4Pg6bozWS0OxDGUF9Xu3XtipKi/Lhv36SkpBjtzvgGhpt+OXTokLu7+92gN3oGRoz2BcJIWluaV84zZGHCxkRHc3JyMtqdcQzc5tc3z58/P3funJvHzfESayLC3oY8f8JoLyghEAiMdoEOcHBy+T4KLi0t27JlC6N9Gd/A3k0ftLW1KSkrTzcwvuDpx2hfBorlotlFBflf0gsY7QgAABTk5tzzuxH2JqS5qVF3mr6tw44Zs0z6tCQQCAsNdbt77mCSnCBzO/DVqHg6CCLC3tquXhIREWFkZMRoX8YrsHfTB+fPn6+vq9979BSjHRmXdHS0b7IyD3xwx3C2qbXt1oL8nE2W5nGx0X0aV5T9ykpPRWMw/IJCpB8evrG4tdfYdP7seQsdnZzg9s4hA3cVU1JfX+/u7r7jwDFhETFG+zIucT91ND/np//TEKM58wAANvbO8w109jrYfkrK6W1cmJ8HALjifVdZTWO0HR08R067m+lpBAQEWFtbM9qXcQns3VBy7949NBqz1nYsjtI7OzuuuJ2YpaWoKMJhpKN0aNe21pa+T2x9jYk6ttfZWFdZT1V2u531Q3+f7u5uUq6TrdX1y+cS4r442Vppy4uZTde4efXioOZZaqoq7/l5pfyI75317NE9JVV1JNYAAASFRQxNzEqKCpPi43obF+blolAoWXmFgVfNQGTk5M0WLvX29ma0I+MVGG4oCQ4ONl24dGzuGz66x+n6Jbep+gaHTp43Np0fHPBw/fIFvc2+REdam88NeR5oaGJmud62vLTkyG7HCycPkwxio8KfPvC3WbUY19VltWETKzv7+ROHDu20p+lAfW3NI3/ftUvNpqtIH9+3vay0pLdBY0P9TKPZ5IlINElJSuhdYGFBrrjkhLaWlvD3r5/c90+I+0IeFscg5qutYmNjKysrGe3IuAQOpnrQ0dERGxt78cYtRjvSB12dncGBj4zNFly8/p970rJyJ1x2FeTmUPQOXgUFYLDYqMRsbh5eAID9zn2Gmoof34YePHGOZFNUkH/kjLudww4AwO7DJ6zN5wY+uLPW1l59snbvqhsb6t+FvHj94mnsp4huPF5ZTcNxz0HTBUvUNLUoLPNyfwIAKMahcvKKAIDa6qreJRfl57U0N83UkG9vb0NS1CdrX/a+K6+oNLh3Z7SYYTQbg8FERkZaWFgw2pfxB+zd9CAzMxOHw6lqUP4XjQW6Cd0AgK8xUekpSUjK+s0O6aUNE2QnUlhuctz1KvwrEmsAALiuLm4enpaeQhncPLy227Yjv6PRaMfdLkQiMToijKKomqpK29VLdBUlDu926Mbjj5y+GJOS+yY6YdfB471jDQCgKD8XAEAx1yshJQ0AaGps6G1fmJ/b0tK848DRiPjMZ+8/rdm4KSM1ebPVsra21gG9KaMOGxv7RAXF1NRURjsyLoG9mx6Ul5cDAMQlJBntSB+wsbHvOHD00ulji2ZNkVdU0jMwMjKbP8vEDIPBUFjKKUyqr6v19byS+P3rr+LCgrzcluYmEVFxchsZOXkUCkV6qaCsAgAoLsijKKq2pjoi7C0Gi92w2WHV2o1KqurUnWRmYQEANNbXkScisYOHl6+3vfuN2ywsLIrKqohLOlP1uLh5fK5deh8SvMxijE7HiolLIn8nkMECezc9aG1tBQCwsXMw2pG+cdpzMPJHtvO+w2zs7A/9fewslprqaVRXVVCY+Vy7pKci88/FMzgcbobRbPcbt3Sn6VPYUIx32Nk5AAAsLJRHn+UVlW4HvjJfZfX04d35M7UNJyucPrw3Lja6vxkWIWFRAEBxYT55YkN9HQCAX1Cot736ZG0k1pAwNp0PAMjOTO/7LRgDsHFwtrS0MNqLcQkMNz1ANj2Sf+2PHXBdXU2NDZITpHcfcn0V8e1rZtH6zQ4FuTl3va+Tm9XVVJ8/cYiLh+dLeoHvo+cHjp+du8i8s7ODojRk1EPiV3ERAGCiwiQKMwwWa2w63/3GrYScMt9Hz3Wm6gfcu22x0GTKJMl9jnbFhZS7CmXlFVAoVHFRj/TMtBQAgJbOVArj8tKSt6+el/0qJk9EyhQQHLsnsFEouDl2iMBwM26IjY7QlBEKCQpAXgoJi27dvgcA0NhQT25WWlJMIBDmLTInLa6Vl5ZkpCZTlJafl1OY9zviPH14BwCgoq7ZX+1MzMxz5i++4nM3IbfM617gjFkmb14EpackUpiJiIpP1TeI+xxdVPBfBwePw7189lhUTEKt1yR0Q329wwYLz0tu5ImhwYEAgKnwTOyfCJy7GTfoTtMXEBL2uHBaVFxSVWNyYX7e9UtuAADjuT3WwicqKLJzcIYGPzUynSenoBT/LfbSmeOcXNytrS35OT8nKigiZoTu7i1rl+85clJWXvF9SPAdb8+Fy1b1PvheV1Md+OBOb2dU1SfLyimIiIn3znLc7WJjscTJxtJxz0EeXr6bHhdLCgtuPXmJ9Bkf3/E7utdp+/4j2/cfUVJV154yPeDuLT4+gXmLlxEIhODAh9HhYfOXLNfUmUKP9wwytoDhZtzAwcnl4XNvzzbbNYvnICksLKx7j54yMVtAYXbR03ef0+ZNa5YBAHj5+I+edWdj59i7zdZMXzO3uh0x059lIiom4bDBAtndN33mrFPu//SutLqq8vyJQ/251OdWYAMT0yved1yct25bvxoAwM3De+SMO2nXH5FI7O7uJg1afR4GHdi+9caV8zeunEcMrG23Hj5zcXBvDWScAEehPQgMDLSwsCioxzHakX5pb2/LSk8tKynmExCcpKwqINT3HEd9XW1GSpKQqJjCJGWkW1FfV9vU0CA9UQ4AoC0nqqGle+dZaGNDfWpigoi4hMIkZfr62Y3HpyQlEAiEyTpTe6+dUVBaUpSf85Obh1d+ktLY3GBJjqPNGg4mVGBgIKMdGX/A3s04g42NXUt3mpbuNOpmfPwCM3pu7eXjF+DjF6Aw4+Hlm2k8h84uAgAAwGCxNJ0kISEljezNgfzZwKliCAQySsBw8zciJCLKJyDIaC8gfx1wMPU38j42idEuQP5GYO8GAoGMEjDcjD/C3rx6Hfx0JIwHzhBEiFtbmuvranund+Px1JdHiUQixVZGyDgFhpvxxz/uZ6nshRmOMU0KcnNOuOyaqSGvNVHEzmLp56jwAT5YX1c7e4ra6vlG5IkRYW8XzZqiIsmrqyjhbLe2t8BoY0O9y46tKuI8k2WF1aT4nWyt6mtr6NIQCEOAczfjjw2bHTo6KM9A0cWYOogIcUVZ2dJVlnx8Am9Dnm+yNL8b9HqqvgHNZw84b6msKOPi5ialvAoK2Ll5veQE6S3OeyrLS18HP4sMe/fy4xfSvmdcV5fNqsVJCXGrrTdqTdFL/hH3+I5fRemvZ+8/0aU5kNEHhpvxx6Du86Tj5Z+DEiEm58Ft76iP73nJRHBwXV1uR13Y2DlCo74jujwHjp+drirjbGf1+tN/gqRBj+8nxn87dOrCZqddAACLdTYoFOqRv29qYoK6lg69GgUZTeBgaoySlZ5qv26Vgab8ZqvlQY/vfY786LDREpn7cD2wc5+jHcnSZcfW4/u2V1aU7di0boa63Cwtxf1Om0jyVBTGw2FQIsQkfmZlnDm8z8XVTVhElJSYk51ZUV5qbDafpAEmICRsaGyakZrc3NSIpAQHPhQQEt64xZH0lONul8s3/fkF4RL+eAWGm7FIXGz0ctOZcV9idKfP5OHlO7Zvx/H9O96+DOpobwMA/Pj+9dvn3wOKjNTk8A9vzE30y0pLFq9YLSYh9fTh3T32NkguhfGQGawIMUJnZ8d2u7VT9Gdu3OpEnl5ZUQYA0NTucQ4TOZb5MysDeVmYl2s0Zx4TM3NxYcG/b0NSk36IiIovs7CG+4/HL3AwNeYgEAiuB3Yys7CERHxF/rU2O+1abEztQMCv4iL7nfv2HzuDQqEIBMJSk+k0J3Hra2vu37rZX+68JcsVlVTIUwYrQoxw9uiBqorye8/fUEgIScvIAQC+fIpABkoIOdmZAICczAydqXptrS1VleWCwsJ2lubh71//V53CpIs3bg38bARkrAHDzZgjPSUpMy1l2879pK/xSSpqi5atDn7yoL9HWFnZdrocQ/6l0Wi0zjT9tOTEirJfouL9qqDW1tZccTvRX66svAJFuBmsCDEAIPz963u+N27ef9r7xi4ZOXl1LZ3Pn8Kf3Lu9aPkqAoEQHPjozYtn4P+SzMj9U/43/5GRlTtxwUN7ql7Ct9hzxw9utlr+/nNifwdTIWMcGG7GHIhgMIWwHsU/PwUCQsLkup+IKjAihNofcgqTMsub+stlYmKmSBmsCHFVZflex00W623nLjLvnYtGoy96+tlZmrvs2HrCZReBQCAQCZYb7B75+yItRfRGuzo7b9wLlFOYBABQ09Sqqar0vOQW8jyQYmgGGS/AcDPmaGxoAADw8ffoRyDf+f3BykqpMQz+L4TaHygUipWVbeBeDVaE+MEt7/ramuamJtJEdUV5GZFI3OdoJyuv6LDrwCQVtfexiaHBz3KzM4RFxGYaz/kaEwUAUFBSAQCIikkAALR0p8mRhd3Z8xZ5XnLLzc4cuNuQMQUMN2MOyQnSAID4b7Gz5y0iJZIue6EX1VUV/1w401/uKmsbigunBiVCDAAQEBRSUdcszPu9Rt7V2UkgEjJSk9FoNK6rq6SokE9AwGKdDcnA68oFYRExZL1cXEoKAIDH9xAe6uhoBwBw8fAMpqGQMQQMN2MORRVVDBYbE/HvgeNnkZTiwoLPkR/pW0tTY2PA/dv95U6bYUgRbshFiKVlJwKqIsQAgA1bHDeQrWEDABYbTe1ob0e21TQ1NsyeqrpkhaWH330kt6Ls19uQ56utNyIvWVnZ9A2NYz9FFOblysjJI4kfXr8EAOhM1RtqoyEMBi6EjzlExSRs7Z3TkhP3OthF/vvujrfnxlUL6V6LnMKkn5Wt/f0sXLaq9yOOu11weJyTjeW7kOAv0ZF2a8xLCgvcrt0krTo9vuMnL8h67cJpmrVz8/DqGxq/eRUU+OBOY0N9yo94O0tzMXGJQyfPk2wOHD+LQqEcbSwj/333MzP9jrfnI39f3ekz5sxfTK83ATLKwN7NWOTA8bPcPLy3va4FPb7Hxy+wdNUabh7eaxdOc3Jx0354xKAuQgx66hDT5IKn73Y76wPOmw84bwYAqGlqefg9IFcO1dDWvR34ap/jJptV/8WXOfMXX7zuR88mQUYXqFXcg7GmVdzYUI+s+xzfvyP8/evo5Fyaj4w0gxIhpg6RSMzOSCsuzFfT1BKXnNCnDR6Hy85Mr6upnqSq1ntBnSFAreIhA3s3Y46OjnarxaZaU6YdPXsJiTVtba2fwj+oqE9mtGsADFKEmDooFEpJVZ36RcBYJiZVjTHRcMjwgeFmzMHKysbLx3/X53pzU6PJ3IWNDQ3PHt6pLCs7f82H0a5BIMMChpuxiIff/euXz8VE/Pvs0T02dg41TS2/gBcD0XmAQMYyMNyMRbi4eVxc3YCrW3NTIwcnFxoNFxAhfwIw3IxpuLjhljbInwP82vxLiQh7G/L8CaO9GBz9qR1Dxguwd/OX4u3hXlSQv3i5BWPdIBAICw11u/F48kTJCTK3A19RWNbX1c6foc3FzR32LRVJ+RwVfuLAzj6LVZusc/mm/0g4DBkOMNxAGElF2a+s9NRJKmrk0qIUMhcIvdWOUSgUlomJwqyzsyM/56eMnMIIOQwZDjDcQBgJomtzxfuuspoGFbPeascAAH1D4zfRlEKCx/fvaGlqPnPlOt1dhQwfOHczqnR2dlxxOzFLS1FRhMNIR+nQrm2tLc3kBl9joo7tdTbWVdZTld1uZ/3Q36e7+z/pCZcdW/dssy3Kz3PZvkVPVdZqiemLwIcAAL/rVxcbTdVREN+4clFh3u9tx062Vtcvn0uI++Jka6UtL2Y2XePm1Yv93Q/V1NhwdI/TXD3NKZMk7detigh7Oyi3h0xhXi4KhUJESPujT7XjPon6+P7BrZtXfO4ichmQsQbs3YwqR/c4PQ94sMxiraqGVlFBXsDdW9npaUEf/rtf6Ut05Lpl87i4eZastOQXEIyJ+PfIbsfiwvyDJ84BADJSkytKSz9HfuTm4dEzMAoNDvwaE/XyaUB05L/GpvMlpKTDP7xZaz43OjkHWTiPjQpPS0rw9nDXMzCy2rDpU0TY+ROHCvNzzvXaLlhR9mvVfKO6mprlltZc3Dyfwj9ssjQ/fPqi7bbtA3F7OBQW5IpLTmhraYmNCq+uqpKfpERxNoJc7TjgLrUDU/V1tfsdNy9atlrf0Hj4jkFGAhhuRo+uzs7gwEfGZgsuXr+FpEjLyp1w2VWQm4N8vb8KCsBgsVGJ2cj9BPY79xlqKn58G4qEGwBAdVXFniMnnfYcBAAsWWlhs2rx15iosC8pyON7HeyCHt8rys8jdRaKCvKPnHG3c9gBANh9+IS1+dzAB3fW2tpTiEucdz38q7goOOzzZN2pAIBdB49vXLXonOvB5ZbWvHz8NN0mMVj9YwBAUX5eS3PTTA359vY2JEV9svZl77vyikrIy/7UjntzbN/2psaGA679ivhAGA4MN6MHosj3NSYqPSUJOQe0frPD6nU2JN3PTY67Nm5xIt2Fguvq4ubhaW76LfGJwWC2Ou9BfkcmO/QNjUn/89Nnzgp6fC8nO4OUws3DS+qhoNFox90uX6IjoyPCyMNNQ33dy2ePNbR1kVgDAGBiZrbcYBf7KeJ9yAuL9bY03SYxWP1jAEBhfm5LS/O+I6fmLjKvra0Oenwv8L7/Zqtlrz/Fs7NzUFE7puBnVsbr4KeOu136O+oJGQvAcDN6sLGx7zhw9NLpY4tmTZFXVNIzMDIymz/LxIw0dpBTmFRfV+vreSXx+9dfxYUFebktzU0iouKkEoRFxZmY/1MRRv7bhcV+/x9iMGgAAK6ri5QiIydP3ilQUFYB/9dCJpGf+5NIJLa1tDjZWpESW5qaAABFBXkDcZvEYPWPAQDuN26zsLAoKqsi3upM1ePi5vG5dul9SPAMo9lU1I4p8PZwZ2JmtnPse10cMkaAU8WjitOeg5E/sp33HWZjZ3/o72NnsdRUT6O6qgLJ9bl2SU9F5p+LZ3A43Ayj2e43bulO0yd/nJ2dnaJA6ucbKDoF7Owc4P9xikRDXS0AgJmFhQnLRPrh4xcwX2WlqKwyELdJIPrH/f30qVahPlkbiTUkjE3nAwCyM9PJ1Y6Rn4ryssqK8n2OdjeunCd/pOxX8ctnj80WLuXtawUdMnaAvZvRA9fV1d7eJjlBevch192HXKurKjzd3e753rjrfX3v0VN1NdXnTxziFxSKTMgkqUxdv+Q2nBqR21pI/CouAr3ueJCSmQgAkJFTuOJzl5TY3d3d2tLMxsZO023yogarf1xeWpKU8F1TW5d8BFRcWAAAEBAUZmZmpqJ2TF7O4zt+3Xi8hbUNgIxtYLgZPWKjIzauXHTF+4756rUAACFh0a3b99zzvdHYUA8AKC0pJhAI8xaZk2JNeWlJRmqyoJDIkGvMz8sh1/p9+vAOAEBFXZPcRkZWjl9Q6NPHD3gcjrRrzuvK+Utnjj99G6k7fQZ1t8kZrP5xQ329wwaLNRs3nb3iRUoMDQ4EAEzVm6mpM4WK2jE5nyLCePn49WeZ0Ho/IAwGhpvRQ3eavoCQsMeF06Likqoakwvz85DOi/HcBQCAiQqK7BycocFPjUznySkoxX+LvXTmOCcXd2trS37Oz4kKikOokdDdvWXt8j1HTsrKK74PCb7j7blw2aopejPJbZiYmfcfO+OyfcvOrRvsd+zj4uL+8ObVP+5nZxrP0ZmmT9NtchD944G7p6Sqrj1lesDdW3x8AvMWLyMQCMGBD6PDw+YvWY5c4DsQGhvq05J+zJ63CJ6bH/vAcDN6cHByefjc27PNds3iOUgKCwvr3qOnTMwWILkXPX33OW3etGYZAICXj//oWXc2do6922zN9DVzq9uHUKP+LBNRMQmHDRbI7r7pM2edcv+nt5nFOpuO9ja3Yy6vg58CADBYrOU6271HTyHTzNTdHg4oFMrnYdCB7VtvXDlPmo6xtt16+MzFgRfyJTqSQCBoT5k+TGcgowDUKu7BKGgVt7e3ZaWnlpUU8wkITlJWpbh/tr6uNiMlSUhUTGGSMvLfXl9X29TQID1RbrAVacuJamjp3nkW2thQn5qYICIuoTBJmYp9a0tzekpSa2uLkoqamITUoNweJqUlRfk5P7l5eOUnKZGro49NoFbxkIG9m9GGjY1dS3daf3K/fPwCM4xmU6Tw8QsMp0YeXr6ZxnNomnFwclERDKTu9jCRkJImXYgO+YOBw10IBDJKwHDzxyIkIsonIMhoLyCQ38DB1B/L+1g6XysOgQwT2LuBQCCjBOzdMJ6IsLctzU0M1/EEADy+41dbWw0AkFdUmrd4GXlWW2sLOwfnkEsmEAjD2RdDpfZuPB6NwdA8L05OdHhYcmI8AICVlW0TPGY1isBww3jGiGwwAMD/5rVfxUXCYmJGc+Yh4SYtOfHCycMpP+IbG+oFhUVMFyw+dPI8clX5QGSGC3Jz7vndCHsT0tzUqDtN39Zhx4zB7P2lUjsAICLs7aXTx3KyMzm5uPUNjdfZ2SMrazQ1jJMS4oIC7tdUVTExMcFwM5rAwRSkB1P1DSITslzPXwUApCYmWC0xTUv6sXSlpfO+w1zc3I/v+K01n4tsGkRkhtEYDL+gEOmHXGa4o6N9k5V54IM7hrNNrW23FuTnbLI0j4sdqCgX9dpfBQXYWSxtamzY4rxn9twF4e9e21ma5+f8BP/XMKb46SZ052RntjQ3AQCc9x2OTMgayEFzCH2BvRtIv9z1vdHR0f7i31jkmNXuQ67W5nM/R4W/e/V8gflKmjLD7qeO5uf89H8aYjRnHgDAxt55voHOXgfbT0k5fdoPvHbTBUvcjrqwsXOERn1H5IEOHD87XVXG2c7q9ad4qGE8ZoG9GzpwfP+OVfONqirLyRMP7rRft3w+oj5DRYGYgt32Nru2bCBP8bp6YdV8I9KYhbqoMH1JiItVUdckP9K5cu0GAEDSj+9gADLDzx7dU1JVR2INAEBQWMTQxKykqDApPm6YtedkZ1aUlxqbzSdJkQkICRsam2akJjc3NfYuCmoYjxFguKEDMhPl479+fhfygpRSWVEWeN+fl4+fiZn5S3SktfnckOeBhiZmlutty0tLjux2vHDycJ9FpSUlpCb1+GYuzMuJ//qZNH5ZaKj7PODBVH2DVVYbfhUXbrI0v+11bSQahcfhDE3MNmx2IE8sL/0FAEBkZUgyw+HvXz+5758Q94U8htbX1jQ21M/suUMaiU0pSZRdj8HWXllRBgDQ1O5xjBM51fkzK4OiKKhhPHaAgyk6sHSl5Zmj+9++DFq/aRuS8jr4GYFAWGW1AQxAgXjgUBcVpjAegnIwOVgmphMXPMhTaqur7vl6YZmYZs9dCGjJDOfl/gS99L3k5BWRcmi2lHrtiDDgl08Rm512kQxysjMBADmZGTpT9cgfhBrGYwcYbugAv6CQ0Zx5kWFva6urkLOLIc+fiIpJICeVaCoQDxCaosIU9kNQDqZC+PvX+5231NVUH3O7PElFDdCSGUaUvSguqEMORjU1Ngy83j5rJxAI6lo6nz+FP7l3e9HyVQQCITjw0ZsXz8D/BaFJQA3jMQUMN/RhxZp1H9+Fvg99aWWz+VdxUVJ8nMOuA8hOE5oKxAOEpqgwBUNQDu6TooL8U4f2fHwXKj1RzsPnHukEKRWZ4WUW1swsLACAxvo68qLa2loBADy8fAOsur/a0Wj0RU8/O0tzlx1bT7jsIhAIBCLBcoPdI39fihgKNYzHFDDc0IfZcxfy8PK9eRVkZbM59HkgAGCl1X8zvj7XLl0+68rMwjJthuEMo9mOew76eV4pKSocYMkN9f+J5pGLCpNyKUSFyUGUg4fRJgAAeBH48PBuJxQKdfDEuY1bnZAggkAhzQcAMDad73PtUnZmOgAAmZQtLszv2ZY6AAC/oNDwa5+kovY+NjE0+FludoawiNhM4zlfY6IAAApk4QbRMJ6/ZDnUMB4jwHBDH5hZWBYtWxVw/3Z9XW3I8yc6U/WQadHBKhCjUCgCscdFl/k52cgvNEWFKRiscnBvwt+/3m1voz1l+rVbDygGI9RlhgEAsvIKKBSquKiA/KnMtBQAgJbOVOr10qwd19VVUlTIJyBgse63PrHXlQvCImLkkQVqGI81YLihGyus1j/097npcTEjNfmchzeSOFgFYskJMtGR/5Jkg39mZRT+f6BEU1SYoqjBKgf35sLJI1zcPDfuPel9zRN1mWEAgIio+FR9g7jP0UUF+dKyEwEAeBzu5bPHomISarTqpQpnNO0AACAASURBVFl7e3vb7KmqS1ZYevjdR1Iqyn69DXm+2nojuRnUMB5rwHBDN7R0p8nKK9y6fpWNjX3hspVI4mAViCfrTg3/8Gavg53lBrui/Dwvjwtc3Dz1tTVgAKLCFAxWOZiCxob6n5npqhqT/TyvUGRNnznL2GwBTZlhx90uNhZLnGwsHfcc5OHlu+lxsaSw4NaTl8j5pls3PNyOHdi+/8j2/UcGW7vJ3IX6hsZvXgXNeDB77qKlRfl5B3fai4lLHDp5nrwEqGE81oDhhp4st7C+dOb43MXLSOd6BqtAvMlp14+4ry+fPUY6Asss1gIAvK5eQHKpiwrTl4RvsUQiMS05MS05kTIPhTKZu5CmzLCBiekV7zsuzlu3rV8NAODm4T1yxp20649AIHR3d/enXUuz9guevtvtrA84bz7gvBkAoKap5eH3gFx4FGoYj0GgVnEPRkireLAKxHU11RXlZcpqGn3GEeqiwsPBbLqGuOSEO89CB/4ITZnhbjw+JSmBQCBM1plKcbOd5yW3CTKyS1ZYDs1bIpGYnZFWXJivpqk1hHXuPdtsw9+/TsyvHOyDUKt4yMDezWgwWAVi5Lhjf7nURYVHGZoywxgstk+F46L8vKcP/ANCPw65ahQKpaSqrqSqPuQSIKMMHNZCepCRmuxos+bWDQ/apsOjqCDPL+AlfXtnA+Tpw7uONmu+ff40+lX/5cDeDeQ3Biam5aW/iATCKAyxDWebjXQV/UEkEokEgoaWDgfn0AXDIEMAhhvIb46evcRoF0aD1dYbKZbMIaMDHExBIJBRAoYbOhMR9jbk+RNGe/FXQN+3Ois91f/mP40N9fQqENIbGG7ojLeH+9mjLoz24q+A/K1OiPvi6X62pmrQq9okvn/9fPLg7uphlAChCQw3kD+B77Exl84cr6qsYLQjEGrAcDMsiEQi3CcJgQwQGG6GSGZairX5XA1pQWUxbvM5+pH/vuvTjLpKcWdnxxW3E7O0FBVFOIx0lA7t2tba0kwza/i4Hth5wHlzRdmvY3udteX/OwBJXQV5hBpCvViays0IB3faP/T3BgDsd9rkSnblC/UWpfyId9hoaThZwdp87j3fG/BrYxSAC+FD4WtM1MaVi/j4BSzW2TQ3Nb59FbxpzbInr8MpZCu/REeuWzaPi5tnyUpLfgHBmIh/j+x2LC7MJ8mGHt3j9DzgwTKLtaoaWkUFeQF3b2WnpwV9iKaeNXyy0lOrqypsVi/JSk9V09QCAFSU/Vo136iupma5pTUXN8+n8A+bLM0Pn75ou237yDWEZrFpSQmISDMJknIz+WmIiXKKPzPSfxUXycorykyURxKpt+hrTJTt6iUsrKxzF5uj0ehLZ45z8/DQ5b2FUAGGm0FDIBBOHtzNzMISEPoROfS0Zfte02nqD/xuUoQb6irFXZ2dwYGPjM0WXLx+C7GXlpU74bKrIDdHQmpCf1m9bz4YmiZxfs5Pw9lmnv6P5RQmAVoqyCPUEHqpOG923t3d3f3j+9dtO/eTbm6g3iLkEwyJjJOcIA0A2OK0Z4GBzqAqhQwBGG4GTXpKUmZayoo160kHLOUUJrmev0rxPQxoqRQjqrpfY6LSU5JUNSYDANZvdli9zoaFhbWrq7O/rN7+DFmTeM+hE0isoamCPEINoZeKc2+ot0hRRTUzLcVpz0Ek1gAAZOTkl1mufeTvO/yqIVSA4aYHrKysAICuzk5ynUoKENFvRB6cxPqeV5QgUFcpZmNj33Hg6KXTxxbNmiKvqKRnYGRkNn+WiRkGg6GS1WctQ9Ak5hcU0tDWRX6nqYI8Qg2hl4pzb6i3CIPFAgDIb7ACACgqqQ6w8M72dkHufo/XQqgAp4p7ICAgAACoq6uhYlNXWwMAEBWn/V/hc+2SnorMPxfP4HC4GUaz3W/c0u2pg+W052Dkj2znfYfZ2Nkf+vvYWSw11dOorqqgnkUBoknc30+fEQoAwMz8O56SqyCTfshVkEeoITSL7Q1JuZmGGdUWIZLJ6J7vTJ89xz6pr6vh54fix0MB9m56oKSkBADIzkgTFZPozwbpgSfFxy1ebkFKfB5wn0AgrrRaT0qhqVKM6+pqb2+TnCC9+5Dr7kOu1VUVnu5u93xv3PW+vuPA0f6y9h49ReHP8DWJqasgj1BDbLdtp6niTEW5eTgtCv/wBgDw7fMn8mvCfxUXDqRkIpGYk5W5xQ7qHw8F2LvpgYCAgIKi4pfoSCo2Glq6rKxssZ8iSCk52Zl7Hey+fY4iN+tPpZhkEBsdoSkjFBIUgLwUEhbdun0PAKCxoZ5KVm9/EE3i/n6K+7oThgJyFWRSoteV85oyQsk/vo9QQ2gWCwCQnCDzq7iI5BW5cvNwWqShpYNlYiL/BLvx+JfPHg+k5NTEhObmJj09PdqmkF7AcEPJ4kWL3r16TmUXhqCwiO227VnpqYd3O6QmJjwPuL/dbi0Gi11rs5XcjKRS/PFdaGFe7rNH95abGZJUigEAutP0BYSEPS6c/hoT1dzUmJr04+TBPQAA47kLqGT19gfRJO7vZ+GyVTSbjKggtzQ37dy6IS05sSg/z9fzCkkFeYQaQrNYAMBk3am4rq69DnZfY6Ke3Lu9Ze1yLu6+l6slJkwAADy+45vyI55mi8QkpNZv2padkXbAeXNacmJ6StK2DRYDnKJ+8ypogrS0hobGQIwhlBAhPUlLSwMA3A58VVCP6+8nt6Zj2879pGkRYRGx6/6PkaxpMwxFxSWR36/7P2bn+E9RhZeP/5LX7Rt3n7Czc2CwWMTgQfA78plRFhbWvUdP0cwa/g+5k6Qf1/NXSfMXGCx2rc2WxPzKEW0IzWIzyhpJ2saiYhLbdu7ftnM/AOBnZStFK37kVSCagdNnzhpIi7IrWiw32JG8mjHL5Ir3HQBA2LdUKu9bRlmjgKCQq6sro/9IxytQq7gPlixZ8jMvPzQqHoulNrfV1taalZ7KycUtO1GeibnvBSCaKsXt7W1Z6allJcV8AoKTlFWRO39pZo0QVFSQR6ghA1Fxpq7cTE5lRRknJxe5ZDJ1Xefy0pKsjDR5RWUpaZmBvD+Xz7re9fHM+flTWHjEP4s/Ehhu+iAvL09NTe3gyfN9Lm9D/k7KfhXPmaZ+5vTpXbt2MdqX8QoMN31z8OBBL6+bQWExyEY4yF8OHofbsHJhbVV5akoKExMT7QcgfQHDTd90dHSYmJiUllUE//t54HdaQ/5Ujux2fPn0UUxMjKamJm1rSD/Alam+YWVlffHiBQpFtF+3qqWZDtvqIeMXT/ezj+/6PXr0CMaaYQLDTb8ICwu/Dg0tKcpfOc9wgHvAIH8YeBzu4E77q+dOenp6Ll68mNHujHtguKGGqqpq3LdvrMxMy+bMoFBLgfzx/Cou3LByYWjQk+Dg4G3btjHanT8BGG5oICUlFRMdbTpntu3qJZvWmBfm5TLaI8iI097edvmsq+l0jdqq8piYGNivoRdwqnigREZGOm/fnp2VZbpgyTKLtTOMZrOxsTPaKQg9IRKJqYkJb14FPXt4F4/rOnbsmLOzM1yHoiMw3AwCPB4fEBDg7e0dGxuLwWAmKiiKiklwcHGPshtdXZ0YNAZDdQvi+KWjo52ZmQWNHtV+d1dHR11tdU5WZnNz0wRpaVsbm23btsG9fHQHhpuhUFlZGRkZmZycXFlZ2dxMNwnhARIbG4vD4WbNmjXK9Y4CBALh7du30tLSampqtK3pBysrKx8fn4qKip6eHjwPNXLAcDPOCAgIsLKy+vDhw5w5cxjty4jg5eW1ffv22NjYKVOmMNoXCJ2B4WY8UVNTo6qqunz5ci8vL0b7MlIQicS5c+f++vXrx48fiLgi5I8BrkyNJ5ydnbFYrJubG23TcQsKhfLx8fn169fZs2cZ7QuEzsBwM24IDQ0NCAjw8vLi5eVltC8ji4yMzNmzZ93c3OLj4xntC4SewMHU+KCxsVFNTW327Nl37txhtC+jAZFINDMzq6qq+v79O3M/4h6QcQcMN78JCwsrLi6mYrBixQpG9SxsbW3fvn2bnp7+94hyFxQUaGho7Nmzx9XVlYpZVlbW58+f+8zi4OCwtLSkWdGbN2+ampoGYgkZLozQ9Bqj0Nw8mp6ezhDHPn78iEKhnj17xpDaGYiHhwcWi42Pj6dic/Nmv1f6SUlJDaSWWbNmSUpK0sllCDVg7+Y3ubm5DQ0NyO8/f/5cu3atmZnZmTO/LzlQU1Mb/bWS1tZWDQ0NHR2dwMDAUa6a4RAIBBMTk4aGhu/fv/e3u9fb29ve3n7Xrl1LliyhyGJlZZ0+fTrNWoyMjPLy8kpKSujgMYQqf+bO1KEhLy9P+h354+bn59fV1WWcRwAAcODAgcbGxn/++YexbjAENBrt7++voaHh5uZ27NgxKpaKiopGRkaj5RdkiMCVqUGzfft2Ozu7X79+OTo6CgkJAQDWr19vbW1NbnPu3DkDAwM8Ho+8bGhocHBwUFNTExUVXb58+Zs3bwZYV2xsrJeXl4eHh4iICH1bMV6QlZU9derUqVOnfvz4MZxyIiMjHR0dFRUVpaSk1qxZc/Pmze7u7t5mHR0dx48fl5OTY2FhUVBQ2Lp1K8Wu8SF/lBAA4NxNPyQlJQEALC0te2fNmjVr0qRJyFZ3bW1tIpGooqKipKREbmNrawsA6OzsJBKJJSUlMjIyHBwc27Ztc3Fx0dLSQqPRV65coelDR0eHsrLyggUL6NSm8Up3d7eBgcHkyZO7urp65yJzN15eXlRKCA8Px2Aw/Pz8Tk5Orq6uM2bMAADs27cPySWfu7GxscFgMBs3bvTw8Ni+fTsbG5uenh6pnCF/lBAEGG76hnq4AQDMnTs3MzMTSaEebtauXQsA+Pr1K5LV2dlpYmLCzMxcW1tL3Ye9e/dyc3MXFxfToT3jnLy8PA4OjlOnTvXOQsKNpqameU9WrlxJstm8eTMLC0t9fT3ysr29XUxMjPSRkcJNR0cHExPTkiVLSA96eHgAALKzs5GXQ/4oIQgw3PQNzXATFxdHSqESbmpra1Eo1JQpU8hzHz9+DADw9fWl4sC3b98wGAx1m78Kd3d3ZmbmlJQUinQk3HBxcQn3REJCgmSTmZlJ/mBjY6OysrK4uDjykhRuWltbmZiYuLm5f/z4gWR1d3e3tLTg8XgikTjkjxJCAk4VDwUhIaEBHiBEvhhbWlosLH5fKN7U1AQAyMvr9/7Zrq4uOzs7Q0NDOzu7/mz+Nnbt2vXixYsNGzZ8+/at9yrVhQsX7O3t+3tWSUmptrb20qVLX758KSwszMnJaWpqEhcXpzBjZ2c/fvz4kSNHtLW1lZWVjY2NFyxYMHfuXOT+wqF9lBBy4FTxUGBhYaFuUFdXh/xSW1uL2DORISAgsHbtWlVV1f4eP336dH5+vq+vL82L3P4e0Gi0n59fVlbWxYsXB/vsxYsXJSUlT506hcPh5syZc+fOHWT6pjeHDx/Ozc09evQoOzv7zZs3Fy1apKqqWlFRAYb6UUJ6wOju1RiF+mCKYleYqqqqoqIieYqysjIAoLOzMz09HQCwatUq8lw8Hl9fX4/M7PQmOTmZiYnJw8Nj2I34A7lw4QILC0tqaiopheZUcVVVFRqNFhERaWpqIiXq6Oj0Hkx1dnbW19cjQycikVheXu7k5AQAOHToEJFIHMJHCaEA9m7ogIyMTGFhIQ6HQ16mp6fn5v4naSwvLy8kJPT+/XtSLgDAzc2Nj48vLi6ud1F4PN7Ozk5XV9fR0XEUPB937NmzZ8qUKevXryd/P6lTVFREIBCWL1/OxfXfZb4lJSXI1wkF4eHhfHx8yHQMAEBUVHTfvn0AgPr6ejD4jxLSB4yOd2OUQfVuTp48CQCwsrKKiIjw9fWVl5cXFBQE/1+Z8vPzAwCsXr06ISEhJyfH3d2dhYXF1NSUQCD0LvzMmTMsLCyMOi0xLsjKymJjYzt37hzykmbvpqmpiZOTk5+f/9WrVz9//vT395eUlOTj4+Pm5s7KyiKSfaBNTU3CwsIKCgoRERENDQ3x8fHLli0DAISGhiJFDeqjhPQGhpu+GVS4aW1tnT9/PhK+JSQkXFxcXFxcSOGGSCReu3aNdPoBi8Xa29v3uXSalZXFyspK+keC9Me5c+dYWFjS0tKIA9t3ExgYyMnJibz//Pz8d+/effbsGQcHBxaLJfb8QMPCwsinkFlZWc+cOUNe1AA/SkifwDNTdKO6urq0tFRTU7PP+d3m5ubExMSWlhZ1dXUpKaneBgQCYdasWS0tLXFxcVD9nzoEAsHAwKC7u/vz58/IshFNamtrExMTxcTEVFRUkA+otra2vr6e/OQKQltbW0pKSnFxsaCgoJqaWm+BdJofJaQ/YLgZK1y9enXfvn1xcXFaWlqM9mUckJWVpaWldfLkSWR6BTIugOFmTFBYWKiurk5T2wVCztmzZ0+ePPnjxw8VFRVG+wIZEDDcMB7i/8XAExMTae7ogZDA4/H6+voYDCYmJmaAQyoIY4EL4YzHx8cnPDz87t27MNYMCiwWe/fu3aSkpKtXrzLaF8iAgL0bBlNWVqaqqrply5bz588z2pdxyenTp0+fPg2HVOMCGG4YzNKlS7OyspKSktjY2Bjty7gEj8fr6ekxMTFFR0fDIdUYBw6mGMm9e/dCQ0P9/PxgrBkyWCz21q1bCQkJ165dY7QvEBrA3g3DqK6uVlVVtbS0hP8nw+fkyZPnz59PSkpSUFBgtC+QfoHhhmGsXLkyPj4+NTWVdJYHMmTwePz06dNZWFiio6PRaNhnH6PAD4YxPH369Pnz597e3jDW0AUsFnv79u34+HhPT09G+wLpF9i7YQC1tbWqqqqLFy/29fVltC9/FK6urhcvXkxOTu59NAEyFoDhZsTB4/FYbA/VxHXr1n38+DE9PZ2Pj49RXv2R4PH4adOmsbGxffr0iXxI1d3dDRetxgJwMDWyEAgEbW3tkJAQUsqbN28ePHhw48YNGGvoDjKkiouLu3HjBikxJSVl6tSpZWVlDHQM8h8MOon+t0CScbK0tKyurm5sbJSSkrKysmK0X38yiPRnTk5OV1fXiRMnkK7lw4cPGe0XBApQjDAeHh579+7F4/FMTEycnJyampppaWnp6em9ZQ0g9KKrq0tXV5eVlRURb+3u7mZiYtq4caOPjw+jXfvbgYOpkSUiIgIJ6DgcrrGxMSoqSkpKauDCl5AhgEajjYyMEhISMjIykKsycTjcu3fvGO0XBE4VjyREIpGPj6+xsZE8kYmJiYWF5dKlS5s3b4YXLdCdlJQUa2trUqAhp7CwUFpamiFeQRBg72YESUtLo4g1AAAcDtfS0mJvbz937tySkhKGOPZH0tXVdezYMW1t7aysrN6xBoPBREVFMcQxCAkYbkaQqKgoiiVwEhgMprS0tKOjY5Rd+oNpaGiIjIwkEAh9jlXRaHR4ePjoewUhB4abESQ8PLzPsSoKhbKwsPj+/Ts84ENHhIWFIyIijh07hkKhep9jwOFw79+/Z4hjEBJw7makIBKJAgICyBVFJLBYLAqFunjx4o4dOxjl2B/Px48fV69e3dzc3Lubk5+fLysryxCvIAD2bkaOjIwMiljDxMQkIiLy+fNnGGtGlNmzZycnJ2tra1PsJMZgMBEREYzyCgJguBk5IiMjySdu0Gi0qalpamrqlClTGOjVX4KkpGRMTMzhw4fJB1YoFApO3zAWGG5GCtKOGwwGg0ajjx49GhISAg8ujBpYLPbEiRMvX75Erq8DAODxeDh9w1jg3M2IQCQSBQUF6+rqsFgsHx9fUFCQgYEBo536SykoKFi+fHlaWhoejwcAZGVlTZo0idFO/aXA3s2IkJWVVVdXBwCYNm1acnIyjDUMRFZW9uvXrw4ODsjLyMhIhrrzVzOU3k1lZWVkZGRycnJlZWVzc/NIuDXeycvL+/Hjh7Kysqqq6ohuHUaj0by8vBMnTtTW1p45cybp+uoxQnJy8tevX9PT0+vr6zs7OxnrTElJyffv38XFxadPn85YT8YvXFxcIiIimpqaRkZGIiIig318EOEGj8cHBATc9Lrx5es3DBqlKCUqxs/JyQpvs+6DpLwyYV5OcQHuka6IQCTWt3YWlNf9qqrjYGdbvmLl9u3bdXV1R7pe6lRVVXl5efneul1aUszGySUiq8LKzYdhYnwo7GpvKf+ZIq2pz2hHxiu49paW2vLKwp9EQve06XoO2+wtLS3728vam4GGm8jIyO3OTllZWQunq1gYac7SkGNjgYGmX5raOrjZR/W/q6y26V1c1r1/f6Tkla61sjp/4YK4uPhoOoCAw+H++ecf1xMnUVhmzXlrVYyWiCtOHlNHw3CdHWg0GsPEzGhHxjG4jvb8H1HJH55kRr9WUlLy/OeakZHRQB6kHW5aWlq2bN78OCBg3lTl0zbz5MQF6OAvZMQI/Zpx9M6Hmqa2i+6X7O3tR7Pq5OTk1RaWhUVF+hZOBla7mFjhbTZ/OLW/8t5fP5IV+87Sco2vrw8nJyd1exrhpqSkZMniRaXFhdedzU11FOnqKmSk6OjCX34W5R4Y6eTkeOXK1dHRzQwJCbFcYyWmpL10/z+8ohNGoUbIGOHn17CX5x1lpCReh7ySkpKiYkkt3KSnp5vOmc3Hin582GqCMNwwMs54GZvu4PHcyNg4+MVLZuaRHTt4eXk5OTtrL7BeuPMiBgtH2X8dDRXFjw5aEtsaPv4bpqqq2p9Zv+Gmqqpq2pQpYlyYJ0esudhZRsxPyAiSkPNr2fG7K1au9r9zZ+RqCQkJMTc3N7Y5OGv93pGrBTLG6WxtfuiyuruxIj7uW39ilX3vu+no6DBfuoTY1XrvgOUox5o33zKDY1JHwnjgEAazOQDfTegmEKjkUuk/Us8dPjoKkv77Vj948ODcuXMjVEV6errVWmut+VZjMNZkxbxJiwgeCeOBQ+z/b6M3hG48gUCp1EOeS/OvpbOtpa2pbuA10hEWDq41Zx51EDDzFyxsa2vr06bv3s3Bgwe9PK+Fnd+sICk0wk5SYrLHq665LclnD92NaZJbVuP3+tubuMym1o5pytIOS/RnacpRsX8alez75ltKfll3N0FWlH/zwul2C6ah/78KE5bw8/SDsOySai52FkP1iXYLpumrypCepZ5LX7xDvxy69TYuLk5HR4e+JeNwODV1jW5OYesLz8bgGMp7i0lbU92ugCS6G9OktiT3W7BfVsybjtamCerT9Fc5TNSZRcU+Jezpt2Df8pwUQnc3v4TstGWbp5rbof5/2uvn17CPfqerC7NZOLhktQ2nmtvJ9LWW39ZUd91mBisHt/O9b3RpxRCoKc7xczDd7rjNzc2tdy7G1dWVIikvL2+dtbXrelOGzA0zM2F1FSW15CXobkydji7cokO3PqcXLpquoq8q+y2j6Pa77/qqMlLCvH3aB0QkbrsaxM7KbGWirS4rllpYERyTyoTBIFEj6FPK+vOPWZmxNvOmivBxhX7LfB6dskhPVYCbnWYu3dFVlIpJK3z9b6StnR1916SvXr0aFBy83v05Ozc/HYulF1gmZkllXQklLbobUwfX2XF7x6LC5M/KBotkJusXpX6Lf3VbWkOfV7TvadSk9wHPz25jYmXXmmclpqBekZuaFhGMwTIhMSX1Y9CTY+uxzKxTltpw8otkRYemhj9XMVjEzkO5Rvz05KayrEQOXoFpyzYPvxVDg51HgImV48G1MxYWFgIClB720btZsnhRXtqPqMvbsJi/6IjD4VtvbryKfXps/RwdRQBAVUOLwQ5PNham/rpOM3d4dnbhwy9tQwabFXXNmpvdebnYsu+4dOG7J2+51NTakX57Pw8HKwCgurFV1eaC0gThT1cdqeeOUOtSC8qNd3vduXvX2tqaXmVWVVXJKyjqLNtiYnuIXmX+Gby7fjg28Ma6C08Vps0BALTUV92wMWBiZeuv63Tddia+q9PeO5yFgwsA0FxTcdlSk42Ld39wdjeu64rl5I7Wpr3P0lk5eQAArfXV7itVhWSUHG59Ii8k7uXtd/8cYmJj5+QTYmDvBgBA6MZ7b56lrSwXGvKKIosyoKSnp4eEvnZdbzqisSa9sGKd2yPNzZeszjx4HJ4YmZy38fzjuuY2AMAB31DHa88Rsx2eL/Z5h1TUNW+6FKi+yV1r62Wna8/bOrpI5ZAbD5NH4YmqMqJz/t+hE+blNNFSKKqsj//5q7dxU1tHZlHlHB0F0sSWKD+XgcbEhuZ2XHd3dklVeW2Tme4kJJoAAIR4OIy15FMLypvaOqjn0qUtvVGXFbMwnnze7Swdy7xx4wYKy2xgtYuOZQ6Byrz0x0fWXbbQfHTIKund47yEyCfHNyLzF288DgSf+y+Cv7y44/XVfc01FU9Pbrq0Wv3KGq3gc05dHb+nGMiNh0ni20cicqpIrAEAcPIJy081qS8v+pUR39u4o7WpqiBTcdocJNYAALgERSdqGbQ3N3TjcdVF2U015YrTzZBYAwDg4BOSm2JckZva0dpEKqSqIOv99cOm9q5cAoM+WEB30Bjs7C2ur0ND0tPTKbMoXt++fXuihNAc7REUtYxNLzTd7/0lo3C6ijQvJ9s+75D9PqEvY9PbO3EAgO9ZJZ/TChDL1ILyD/E/TfZ6ldY0rjBQlxDkefjxh/3VZ6SiyI2HQ21TW0NLu1HPmRp5CQEAQFJuaW97LBr9xm3TzhWGpJSmto70wgpjLXkmDKairhkAoK3QY4inoygJAMgqrqKeO/y29MemBdPSMjLj4uLoUhqRSPS77a85by1j9/IVJsf6OJgWpXyR1pjOysUbenXf66v70yNf4jraAQAl6d8Lkz4jlhU5qdlfPnhvNWmqKlU3WcEjLJH49uHzM7+3QZIbD4e2xtr25gY5HSPyRAEpeQBAaXYfvRs0Bmt37c1Mq52klI7Wpor8dPkpxhgsU1NNBQBAQlmb/BFJZR0AQFVBFvIS39X59KSdtIb+9BVb3tcnxAAAIABJREFUh+8/XVCYNkdQUtbf358infKwQ+irl0umK4/crnMCkXjAN5SFCRtxyQGZFnEyn2m8+0Z/9sVV9TtXGB5bZ4pCoQhEosker6jkfJq11Da13Xrbb39yiZ6q0oQeC3W5pdUAABE+LvJEeQkhAEB1Q0vvEthZmacp/3eFiNer2JLqhg/x2QQCcffKWQAAGVF+AMCnlHwn85mkR7KLqwAAmcVVyOROf7lTlUZqg5yWvMQEUYGQkJCpU6cOv7SUlJTSkuJFRkuGX9SQIRIIb64dwDKx2PtG8IpIAQBmWDjd3GLcn31DRbGB1c45W46hUCgigXBzq0l+Au27Gdoaa+Ne3OovV8VwibCsEnlKTXEuAICilyEoJQ8AaK2v7l0CMyv7BPVpyO9fnno1VJb8/PKB2E0wWLsbAMAvLgMAKPjxaYaFE+mRqsJsAEB1YeYEtakAgPdeR5trKta7Px87h0VQKJSSwZIXr0Lc3d3J03uEm9ra2p+5eWfXzgQjRkp+eVpBxc4VhqQpWBVpkWUG6k8i+h7WsjIzuViaIO8jGoWapjwhOa+srLaJ+unH2qZWt0cf+8uVFxegCDf55XUAAD6uHl/UUkK8AIDGVhoDnFMPwpB+mdIEYVZmJgCAnLiAlrzEp5T8e2Hxy2eqE4jEwMjkF5/TAAAEAoF6LvW6homBmszXL7F0KerLly9snFziipPpUtrQKM9JqchNM1i7E4k1AACRiSpqxsuSPzzp056JhdXYxgX5W0Kh0dJq08p/JjdVl3ELUTtc1tpQG367j0UWBAFJeYpwU1eaDwBg4+6xLRaZJO5oobwFiIJ//U4h/TJhWSUmFlYAgICknMQkrfyETwmh99RMlhOJhOQPgemRLwAAhG4CACA79v23575rTt8fC8MocmS1DWIee9TV1fHz/15G6BFuMjMzAQDK0iPod0F5LQBAQUKQPFFJqt8bbIV4OViYfzvJy8EGAGhtpyFloCAhWP70eH+5TFjKTf0sTBgAQH1zO3liW2cXAICXk8ZgoSzweF5Z7dfMopP3P8zZezPt1j5hPk7P7cstT9/f4fnCxfc1gUgkEogbzHT9339XmiCMRqGo5FKva5goTxCOfJtIl6IyMzOFZZQY+3VaV1YAABCU6jHwp/jnJ4eDVwjL/HsTGSsXLwCgq72Vei2CExSOfijvLxfDRLn8j2FiAQC0N/WQqUYmidi4+l7lJHH0fVntr7zi1K9hPid97OfseZrGyS9s7uL50MXy5cUdb/5xIRIIRCJRd9GG76/8hWWVmmsrg8856ixar2ywiHrJo4+IrDIAICsrS1//95o9Ze8GADBCy7EIDa0dAAD+nlUQCP1uXkL6CxTQ3BiHQqH6fLA/hPm4AACFlT32RyHRR5CHow8HiEQiAKQtNnLiAnLiAmgUysEj6ENCtvUcHRVpkdhrzsExadklVSJ8XMaT5WPSCgAAShNEAADUc0cOQW6Omlr67AGrra1l5xGkbTeStDc3AADYeXqswVPZVodl6eOMPs2NcygUiqmvB/uDU0AYAFBfVkieiEQfdt4+3jEikQiIRNIWGwFJOQFJORQK/dzN4efXD9oLrEUmqjjeiU2PCK4qzOYSEJHTNS5IigEACMsofXnm1dZY29HSRJrkbqouB0Ri8DlHAUl5Q2tGzuKz8woAAGpqasgTe4QbRACJhWmg6hVDYIIwLwDgW2bxvCm/v4VS8svoW0tVfcuFwH41963n6EyW69F/lhcXRKFQRRU9vpHSCsrB/ydxKbga9Onk/bDAY+vJtyYhYbq0prEL311UWS/Azb7O9Pe2uitBn0T4uPg42ajnDrqpg4GZCdPZ1UXbbgB0dXWhmRh8tIVPdAIAoDj12yT9eaTE8pwU+tbSUlcVefdCf7naC6zFJ/UYUQpKyqNQqLryIvLEitw0AICkSh/bLKMfXv3X96T1+UDF6aakRGRPTWNVaTeuq768iJ1XQHvhut+PPLrCJSDCxs3HzisoKq9e+yuPlNWN6yQSiOU5qSgUg3exYJlYAAAUFzeOYGTpE5UJIlgMOiIp9/h6MySlsKIuMjmP+lODpbG1/f6HPhYdEWaoylCEG1F+Ln1Vmc/phQUVdbKi/AAAXHf3s08pYgLcFJYIKtKiAICIpFzycHP3QzwAQE1GrL0TN9Xh6gpDDb89q5GsstqmkNh06znaAADquZCBIzxRBY3B5sZHmG79b+BcX1aYFx9J31o6WhoTXt/vL1dm8gyKcMMlKCqtqV+U/LmurIBfXBYA0I3Hpfz7jFtQrM+pLpGJKgCAvPgI8nATH3oXACAqp4brbL+2bqr67BWrjvkhWU3VZRlRIdoLrAEA05dvmb58C3lpXpuN8J3tFFtyxg6jHW7EBLjtF+t7vohx8AhaPlM9r7zW7zX9tyQpSApVBp0Y1CO7V86yOHXP5kLAnlVGvJysHkHRhRV1T46uQ6Yn7rz/vvdmyH5L4/0WxgAAU11FFWkRn9CvPByss7UUymqbXn5OexeXpa0gMXfKJCwGbagx8dXn9AeaCYumq+SX1+28/kJckPukzTwAAA8HK5VcyMDhFhTTW2n/+YnnczcHdZPltb/yvgX70b0WwQkKx/+tHNQjhta7HxyweHLcZta6PWxcvNGPPOrLC63PPUH+luJD7oRe3mu0cb/Rhv0AAMXppiITVb4F+bBy8shPnd1cXZYW+TI79p2EkvYk/bloDHaitmFG1Ksfbx4oGyyqK81/eXEnt5C42baTdG/pKDDa4QYAcHy9GQ8Hq9er2Mfhifxc7KtmafJwsF54EsHYc+cmWvLeu1Y6e75Yf+4RAICHg/WM3QLSrj8iAN2E38cp0SjUw0Nrt1x5du5x+LnH/11dtFhP5fzmRcj2SE/n5XaXAp3/CXb+JxgAoCkn7rdnNSfbfw2kngsZOKZbj7Ny8nx56pX07jE7N7+G6SpWTp7IuxdIW+YYgvwUkxWHvV9ecA44uh4AwMrJM8/xDGnXH5FIJBC6SX9LKDTa6szDZ6e3RPifi/D/7yStiuHiBTvOozFYAIC5i+fTE3Yvzju/OO8MABBT1Fx5zI+FnYaQ1dikxyGGwMBACwuL+penR6fuhpZ2ZN1nv0/o++/Zyb70OWk5HPDdhKTcUgKRqKMoiel1zzQFBCKxqLI+51c1KzOTgoSgWM+1eSKRmFFUWVhRryknJilEuSRBPXeECI5Jtb34hC5n0FevXp1RjbM4QbmPi1G0Nzcg6z6vPfZnx77f/SSZ0R4BQje+NDuJSCBIquig0TQUzogEQn1FUU1RDpaFVXCCAregWI9cIrEqP6OurFBcUZNHpI/JxLHJsVl8T548Wb16NSlltHs3HV24xUduT5kkddZuARJr2jq6whNz1CeKjrInfYLFoHUnUZMjIweNQsmK8iNzPb1BoVCqMqKqMn23i3ouZCDgOjvu7FwsqTplvtNZJNZ0dbTlxoWLKagz2jUAAEBjsFIqA9WoR6HR/OKyyFxPH7kolIicqohcv7JV44XRDjeszEx8nGw+oV+bWjvmTlFqaGl/+PFHWW3TNadlo+wJZLzDxMLKxs33Lcino6Vpkv7cjuaGH28fNtWULd1/jdGuQfqGAXM3fntXX34aFZGU+yg8kZ2FSVNOPODIupFTe4H8waw85vfp/uW8+Iikd4+YWNnFFTXXugX0qQUDGQswINxws7O6bpjrumFuU1sHJxsLeswc9ICMO1g5uM3sXQFw7WhtYmHjRNGaboMwFgaEGxKjfBMT5A+GlWPEbxCEDJ8/89sgLOHn82g67y4dJq0d1LbzUs+FMJCfX8NSP9JHU4kuUNczBgM4BUbTYORgZO9m5PB4Hl1QXrvcQIPRjoDkvLKT9z/8yCltaGkX5uVcME355MZ5pB1G1HMJRKLhzuv47h6HgCYI8wYeWz/azfiLiXnsUVdaoD57OaMdoaFnXP4zOcznZGnWj/bmBk4+YaWZC+ZuO0m+/4imwSjwZ4abMUJibqn5UX8sBr3SUIOPiz04OvXO++8p+WVhF+3RKBT1XABAWU1jemGFirQIH9fvE63kv0P+HpLeBwS7OQhIyeut3IbrbM+IevXaY39HSyNyAUZpduLdXeZoDFZjzko2br7U8OD4kDvlOSlbvMKQeETTYHSA4WYE8X39taML96+7vbqsGADgkNVs82P+Ucl5r2LTzWeoUc8F/1fh8d61Sk0Wbs/52/n8xJNfUm7rzY9If8TAaudlS81vwb5IuPn23BfX1bH15r+i8uoAABPbQ3d2m+cnRGV8eqVqZD4Qg9GBnuGmswt/+VlUYFRyWU2jpBCvocbEUzbzSHvzY9IKXnxOi0zKbe/ETVeRmakms95Ml7Rzd4fniy589z4Lo6tBnz7+yJETF7Seo73aaPL1l5+fRiWX1jRqyomf37zof+2dd1wTSRuA35BA6L036SAi0kRRQJpiP1ERRbFwltNT9OTE7qknnl3BruenKIgigoqNJlVF6VVpQekghE4gkOT7Y70YAmwSmi3PL38kO8PsLEne7O7MPC+Sodz9+F0DNXnLseqXwl7HZxVLiwkvtjXymG/V3yBXU1vHwVsRr3I/EJvbzfVUl08zoy+tRO/zIHn7vnSsugISTRCW2pvEZRanFZbPm2yAXgoAxVX1GAwGcZj+bHSTO+P9T2VGBjV/qhSTVdYwsXbc8Dd95n5JRmJuzIPilNiuTtIow4lq4yxN5yynz9x9eHwzpYtss2JbfMCZorfRUsqaJjOXjZu26FXQ+czIe821FYo642ZuPiqlrAkAQfvd5bUM1Iwsk4IvEdLihSSkjRwXWy726O83v6O1KerKwQ9Zr9obiSoG5qazl9OXVqL3eTAgPuOJ89cy+YwJ6QmU7i4sjrcs562C1lgklCCYzFhKSI0rf5eGRBOWFUaGoQw3npce3YnJcLE1MtRQKKki+kWk5H6siTi6FgASsglO+26ICuIXThknJSoYk1G89eKjD9UNB1Y6In+bXVJVUd8Um1kkJiRgZagRmpCdmFNyLz4rNqNoqqmOiox4REr+vH3XM6968mAwcZnFGUUVPiEJVobqKxzHx6QXHbgZQaiq73OuYGV984wdV+ua2xbbGokK8r9IL1z8961D7jPWz52E3udB0kWh2Blrm2r3mHJeUdcEABLCAuilyMuSqnplGbFWEjkuk1Db2KqrIsPO0oofg7BTnpnhd8Y5uihoGxIrSlIf+9UQctdciACAkvQEv61OeGFRQ4eFgmJSxSkxYae2NlR9mPbb50W51YXZTZ8qilNj+YXF1I2tcmJCP2QkZkXdK06J1Zk4VVxOpSAp4sbWeVvvZGJ4eAipcZX5GYm3fdRNrMzmrChOjom8fKC+nDCvr7mCzZ8q/904o72xzshxMV5YtOjti4Cdi6dvOGThvB69z4ME8RlLKKrRtzD6jCndXVrmdojAmE5TbQUACIhIAADLCiPGkIWbzq7uoNjMaWY65z0+31RTV5DccfVJUWWdlqL0/fgsHJYn/Yonkn5gy3zrcWtPPkt+Tw83AFDb0LpnmYOnsw0ALLQydD54MzG75PU5Dy1FaQDY4HM/8EU6oaoeeVlSTfT+deaGuZMAYPdSh3l7r/tHpbnPmNDbF7HfL7y0tiHy+G9mOsoAsNPV3vmA336/8MV2xoJ4XpQ+M7XDqf+YF4s9traHY+1TU9vVJ0m8WKzjeD30UmQLoaq+pb3TcM0JRE4KAEaaipe3OuuMeK7BEaa7qzMrMkjHYprTjvPIFkkl9ae+O+rLiqRUtLKi7vNgcX8EpiPJCaxct5xePO79y2f0cAMArcRa+9V7prh5AoChw8JbXs4fMhI3+b1GFOUh/2zIeB5IrCAgL4mVJdN/9560aAMA2P+6+8bWeelP/c1/cWcySwBAxOX9jdWlay9GKuubAYDdqp23vJwjLu83clzMKyCI0memdjj1H6P7jLE43lmbexh52ho+vQm9isXx6k5yZKfCiDFk4QYx8iXmlGQRqgw1FABgzayJbg6miPrz918mr51tQU91Qu6miAnxM+U5wfLwbHKyQp4bqCsAgLWhBv1rb2mgHvgiPb/0E7JFTIh//RwLpIgHg9nqPCUhmxCTXsgUbhpaScHxWSbaSmb/WbL4cNgV08ziswhhr3Odrceh9JkJTv3HTIQn5286G1LX3P7P6pn6vfSsfZYSqoitpM49y6bOnqhf39wW+CL9VmSqq7d//OnfBfn5UPb1vUOjUAGgJCOxqjBLQdsQACY4rTGZ5YaoPye7/D5xwVp6IhRKF5lfWIwxCwoA8PBgLRdvQp7LaxoAgLqJNf1rr25kmfE8sPZDPrKFX1gMOT0BAAwPj7Xb1pL0hKLkGKZwQ2puyI4KVtIzUf5vJRSWl8909gpCWnxefJihgzNKn5ng1H/MSG+fMRP5r8IfHNvU3lg3Y9M/iEyH0wrDx5CFGwE87/Yltof8o6b8cV5HWcbKUGOaqY6dsTZy8q+tLENsaT/3IDE5v6y0pqG4qr6lvVNesscgnLykCN9/FmHkC6/AUAFph9zdjbzUVJRiFOWOVpUFgJJqZjNmUfknGo3WSiK7H/+iy0bCXEkVEb3PTHDqP6ZTUk3c9e/T58nvNRSkrnguYkovg1J6YfMCPA6LqKM1FaXM9VRFBfl9QxPCXue52H5NJ/lww8svYLNye/S/hy6uniIzSkfd2Epn4jQtczvk7oy0qnZ7M/Hl3XNlucmN1aX15cWdbS0i0j3upotIy2N5P0dk5AsvIvXlHhkPFgsAlO7Pc52klDUZP0uyaqPhPxEyI3VlRTQajUxqDdrvTt/Y2daMVEbvMxOc+o8Z6dNnjBQRK0uend2V/+q5pJLGwr1XmJLPsFNhuBnSezfONvOtDANfpEem5F9/9vba0zdaitJPDq+WlRD2DU04fDsaj8NNNlCzMdLyXGRz7sHLjz3dwL1/sVHWNzAlaRHE80Ff2lNiCwnZzpilD5HsIBEKpc9MTXHqP0YIis3YevERBoM5sNJx3WwLph6il/a+MJxqpuMbmvCulDPb0/fIFDfPsfbzM54HFiRFJj+6/vbBNSkVrV99nwhLyiYG+r7432EcL17NaLKmqc0UN8+Xd8819JR18vIzTxfg6f+eF1MOAz5+QQDg7XVW0t5EBAAsL54H9+VtEhCTNJzqjEQolD4zNcWp/5ilzxgAMiOCwk5txWAw0347MHHhOlwvtSvLCiPAkIUbcjeF1NmlKiu+y9V+l6t9bUPriXuxV58kXX7yev2cSQf8IqTFhFIv/UEf9DkZFDuY3SGDxHRKaxsAQFuJ+aaGmrwEAGgqSl3Z6kzfSKFSW0lkATwvSp/3LpvK1BSn/mMACE/O/+3M/fG6Ktf+XNRbaoNeWlHXlFpQbqKtxFj0oZoI/djafyQoXeSuTpK4vKqd+y47912txNq4WyfehFxNun/Zwnl95JUDQmLSm2+n0gd94m6dHMzu6it6ZC5rrC4FAClV5syOSMonKWXNhXuu0DdSqRRyeysvXgClzw5r9jI1xan/GN1nDAD5r8JDDv+mMma8875rfQpxWFYYGYZsmCMhi6Dmeuh+/OelA7ISwh5OlgDQ2Eoq+9RIpdFmW+jTY01FXVN2SfVgdldcWVdcWU9/GRCdBgC9pTnqClLSYkLR6YVdlC/zvk8Hx6u5HkorKEfpc+89Iv7j/h5IQhsmDt6KEBXE39yxpE+BFnppQwtpxdHAk/d65F0LTcwGAIsfffU8IT3h8Cy17Kj7yEthSVnLxR4A0NHS2FhTRqNS9a1n02NNU21FdWH2YHZXX1bMaBdPexYAAApazNIcSSV1IXHpouRoSncXfWOC/+nDs9TK36eh9Ln3HhH/cX+P3tdxdJ8x40a6zxgAoq4exAuJuhy82V8oYVlhZBiys5sJo1VlxISO3Y1RlBYz1FAgVBGR8xdHM11tJWkhfr7QhOyppjraSjJv3n30DogSEcS3dZALK+qYck6xCYVKW3o4YM8yBy1F6bDXuZfDXjtZjrXQV2OqxofD7nOb5nEudN2p4M3zrUQE8U/fvDsRFGtrpDVhtGpbB7m/PvfeI6f+48ZW0rvSWkMNhXMPmFPBWhqoTxitilLqOF53jJrceD1Vv4gUCRHBORb6VBotKDbjRXrR3EljmIbPfzxUDSYIScjE+h0TlVVU0DYklhOQ8xcdC0dpFW0+AaHsmFDtiVOlVbVLs99EX/PGC4mQSW11pYXSvU5J2IFGpdzevdRh9R4pZa28+LCk+5cNbJ1GGVowVcPy8k1du+/BMY/7h9ZZuW7GC4m8S3wad/OEppmtqsEEMqmtvz733iOn/mN0nzGppbG25J28tuGru+eY/lDNyJKdCuz3ZJAMWbgRFsBf8Vy0/kzwnN2fR/jwfLi9y6ZOM9MFgHMe8zf6hiw55A8AEsICh1fPFMTzrfe5P2mT76eQgUiepxhqKEiJrjgSSKXRAMDSQP3Eb3P6rOk21ZTU2bXP7zlyaoDD8rhNNdvrNhWDwaD3eZC8eVdKo9Eyiyszi5nT2iC3pFBKHcfrYjCYgF1LPc6Gng6OOx38+RzHfYa5t/uMwfftGwcvKLxw75WQw+uvb/78nuL48A5r9upYTAMApx3nQo9sDNi5BAAERCVmbDzMxy8Ycnj9uZWT9r/oIysuSzRMpojIKNzZtwLJUaVuZDl764k+a5rMciN3kiIu7suJCQUAHizOdLabw+q9GAwGvc+DBN1nXJr9hkajVRVkVhX0UqZiMLqTHFlWGHwP2WSIXcWkzq7cD9VlnxqlRIVGj5KTYbjLQGxpzyJUyUuI6KrIIAMBxJb2xlaShgLHs2Y1lx021lYK/mtFYyspvahCUUpUt/88nAitpM4sQlVbB1l/lJyStBibff4WKKttLKyoExPm11WWGeR05+/LVdzVQaom5DbVlAmKScmpjxaS+HJjrr2ZWFWYJSIpL6Omi3yW2puJHS2NkkoanO7lyBxNJT1jt+PBpJbGyvx0UWlFGTUWPzad7a1VhVlkUpuchr6YrBKbfR486D7jb5BhdxUL4HnNdFX61P1KiggyjQFLighKDm7BobiwgK0R8xyqPhEWwPcnDETp87eAiqw4PZ/6TwUvv4CKvlmful9BUUmmQVxBUUlB0b6l0WwiICKuaWbLTk28oHB/wkCUPg8edJ/xd8FPMSOeCxcu3wLfZbiRkxSREv22Lnm4fKcIS8kh2ay5jADfpYDile+mr90FLj8IG2+8+tpd+In4Ls9uuHDh8j0y0mc3kakFLe0d34LW80Z4cn1zGwDoKMvOsWB3oRqNRmtq6xD/zxHRm24KFYOBAWsiWLbf1kEWYljt8SK9KL2oHAD4+Xh//2XywHb6nVKQFNnZ1vItaD1Twm60NdYDgMwoHX3rLxMyqJRuSnc3R+sVOIJMauMT6PeuApXSDRgMywSedIqSX1S8TwcAXjz/pEW/D00XezLS4ebbsQhfCntdWtugICnqYKrNFG5MfzttaaDus7GHdqixlfTXjfCguMwOcpewAH6qqc7xdXOkRL+MrN2Ly7z69E0WoZJCoarLS66ZNfHXmRPYT2uD3n5/VuPUgrI7MRm1ja28WJ6fLdx8Oxbh18GXGqtLRaQUdCY4IOGmKPlF5OUDtSXvqJRuMTmVyS4bEa8wITXuie/2PhtR1DFasPsSO7tjaR1GsRrTqNQLq62plG7GBiXkVZcdDSrPS80Iv9PWUMuD4/1Bws03xaQxasF/rWDaeDs6jVBVb2nQY7iR3E1xPngztaB8mYPJeF3VtMLyG+HJFXVN4f+JuO7EpG/wCdFSkl4/ZxKps+vR61yvK4+b2jr+XGTDTk/Q20exGm9zsd3mYrv+zP3w5PdD8B/hMlDUDCe5HQ9GnhNS425tW8gvLGY8YykWh8uNffTEx6utsc7OfSdgMFgc80LfbnJnXWkhYhdkCUvrMLrVuPlTZU1xrpyGvoDoF7EW8txmxTabFdtCDq/Pfx0+JP+T3vzU4YaRyvrmo4Ev0orKc/pazBX4Ij0lv+zvVdM3zrMEALepphiA6+HJ6UUVxlpKAHDuwUtNBano478heRS2LLAet+bE1adJbIYb9PZZWo25fFPE3jxOo9HWXXmBzJFxWPvXiYX6r+6es1nppWFiveFaAlP9Jz5enW3Ncz1Ps9M4S+swutUYWY+6YPdlea2v8Mnh+BaD15XHM3ZerWloYdy45fyD+X/dIHdTACAxp+TPy2Fm60+PcT/264mg68/fUqjUPpv67Uzw2lP3GLecuR8/Y+dVeqqTprYOz0uPLDb56q444vbP7cjUAk57yz6tpM6iyjpRQX4TbaXepUGxGTJiQmtnf1lHs9V5yqUtC6VFhQCgub3j3ccaB1Ntes4WeUkRK0ONxhYS49JQFNDb79NqDABpheUDOdRvhic+Xtc2zmip77F66OHxLX6e8yldZAAoyUh8fPpPn6VmJxaOuXfw1+SH1/tLsXTf+7fgQz2UrwkBZ65tnEG/auhobXp8yvPcSotj83QD97gVJEUOzzEBADTVVojKKNLn4+EFhZX1TCmU7m5yZ+/KhW+j3z64tmDPld6eij7p0zoMAOXv0uA/q7HOBAcmqzGppRFZWVpfXozBYHoLBkcGjs9uNBSkrj5JCnudt3rmZ5thNbHlVmTqvMkGfDgsSycxIxlFldSeE+qLK+uT8j4iG9Edw0OOjrLMk8OrAYBQVW/6G/PvTHFlvYOpDh8O+6Ga+K60VkFK1EBNnu64wvHwPP1ntZr8l1mtze0duR+qbY21eLFs3ahDaZ8dq/F3iqSSxpuQq3nxYROcViNbWuqq057eGmMzD8vLx9JJzEhlQQat569afXnxx+wkGpUKWBaO4SFH32r2y7vnCpIiEV9EXWlhSXqChpkNXy8LT3sz8cGR3w1snTRMrNlpmaV1GN1qDADEihIxWWUyqZWQGtfWUCs9SldZ35T928mDhONws9DC0ZkGAAAZGklEQVTacO/1Zw9f5tDDTWhiNpVGc3UwAQB2nMRsguIY7v0141QkzBFtHeSahhZZceHFh26FJ+cjG7WVZS54zEeWPgjy800YPQrZfvHRq7JPjREp+VQqbevCKYNvnx2r8XeKocPC8At782If0sNNTkwojUo1meEKAOw4idkExTHMeAsDgVORcG8mLFhbnBoXsMNFxcAcx8dfkp4gIiXvsHpP75qPT2/raG2atm4/mwfC0jqMbjUGAGIFobO95ZSLIWIgBQBFXaMFuy/LjNJhsw+DgeNwIy0m5GCiE5la8KmpDVnNGJKQpSAliqxdYsdJzA7ojuHlU5nXpAxSJIwOoaoeAC6FvVZXkDy2dra5nuqbd6V/+YW7evu/POvBtKTzb/9IxGSupyrLpv2Po/bRncffF0Li0toTHAqTItsaPiGrGbNfhIhKKyBrl9hxErMDumPYdDZzStLBiIQR+IXFxOVVqouyK96nY7E4GpXKg8V1klqZqtWWvM+NCbVetnXADhp063CfVuP6ckJne6vDmj2jrWa3NdZnPA9Me3Lr9i7X9dfie598DTkDuVW8xM74efL7x0l5qxzHl9Y2pBSU/7FwCjLiy46TmB3QHcO96w9YJMwODS0kAOjs6r65fYm2sgwAjNNUrG1sPXkvNiQha93sHmKUyqC/iivrk959PHgrwuHPSznXtvX2kA6sfXTn8XeK8fQl+a+e5yU8Hj93VWN1aXleivWyP5ARFnacxOyA7hjuXX8wImGEaxtn1BDyZm89OdZuPo6Pv/BN5MPjm/23L9rklyQur0qvlhjog8XxDWzImR3rcJ9W4/k7L+D48LLqowFASllT1cCcX1g0MdD3XXzYuGkuA+gJRwxkNprjeF1xYYFHL3MAICQhGwBc7Y2RIt/QBH33Y8fvxnZ1U2yMtC5sXkC/ymCHhtZ25AmjY5j+YHQMM4GIhPt7DDI3k4KUKACY6apoM2RcmW6uBwD5ZZ8AgEajMd6E0lSUWmpvsn+5YxeFEpGaP/j2ASAoNsNq87nEnJIDKx1fnd30Y8QaANCZ5CggIp4X+wgAsl+EAIDxdFekKDHQ98QC/Ti/49TuLk1Tm/k7L9AvE9iB1NKAPGF0DNMfjI5hJhCRcH8Plrc5Pn0sqCHkqRtZmv/iLiAizovn17eeYzzdtauDlBcfRq/WVFOeFRWsZzWr99UcSzIjgi64W33ISJz224GNfq8YYw2NRmO8hyWlrGk8Y+m0dfsp3V0FSREAoKhrhMQaOtoTpwJADeEdp90YAAM5u8Hz4pwsx96KTCG2tIckZJvrqSLJWOqa2jhyEmMwQKP0uFVcWF6HPEF3DPduagAiYfZRkREDgO7uHmMiHeQuAEAuG8/cjz94KzJo33J6ck4AQGboIfd0B9k+utX4uwbHizewc0p9fKu9mZgdHaJqYI4MmrQ11nHkJMZgMEzDDnWlhcgTdMdw76Y4FQkzUVOcAwBqRj2mXGqOt30VdJ7EIBJNCbtBpXSbzlqG0lSfoFuH0a3GTbUVFe9SlfRMGP+wofIDAAhJDESqySkDnHfjamd8/flbn/sJ2SVV9Nm3/TmJZcT7nmetKisRm1HURaEgwzfvS2vpF0qMjmH64M7p4HjvgKhn/6yZqM98xoSIhPvr7eQxaoMJN/x8vNaGGvFZhOLKeiRrMAA8ScoDAHM9VQDQHyUPADEZRYzhxi8iBQAM1Fg7kFi2T7caM+Wf+DEwmu6a/PB64m2f6qLsX7b5IBv7cxILSfYtrBKXVy1OiUUy2AJAbcl7YsXnCyVGxzB9il2C/+noa96/nns2auxEpqYQkXB/vVUzmowebmTU9AAgN+6h7aod9I05L0LhP+UwQlFyjICohIYJW4MJjNCtw0wJJBDoVmPGcEO3GpOaG+7sW2E2Z+XcP7+MvSJ96y1LHQ4GGG7MdFW0FKXPP3wpgOd1mvx5CgCnTmIzHeWIlPwNZ0JWOJoRqup97ieICuHrm9uBlWO4d384FQlzyl/LHR22XVp17M4+t6lK0mLx2YTr4ckT9UfNMNcDgKlmOvqj5K48ThIT4rc31q6sb374Muf52/cm2kqO43UB4MKjV/uuP/dabOvl0rfACaV9dOcx0v53jYq+mZSK1qu753n5BQxsP6dd5tRJrDzarOB1ROg/G0znrCCWExJu++CFRNub6oGVY7h3fzgVCTMhq6anNd6uKPnFzW0Lx01dJK6g+i7+cXZ0sKy63mjLWUgdUktjZUGG7qTpfWYifxV0IeLiPpuVXjYrvJiKWFqH0a3GGB6sypjxqY/9BMUkRlvPoVGpWRFBRckv9KfMZRpcHyYGPqvYxdbIOyBqjoUhfW6bsACeIyfxxnmWb/PLguMzg+MzFaREXWyMAODM/XikFMUxPOA+DxgTbaWgvW6/+4Y4H7yJbJlhrnd+8wLkOQ8GE7Br6drTwUcCXxwJfIFsnGOhf3TNbCS/FZVKpVCpKNZOlPbRncc/QLgBAKNpLtHXvMdaz6FPTsMLCnPkJJ7ssrEs921WVHBWVLCotMI4RxcASAg4g5SiOIaH/FgwPDzO+/594uOVHX2/6O3n0VK1cZPm7ThHz7RXkp5Ao1JVxozvswUajUqlUvr8tLC0DqNbjQHA1TvgwTGPeP/T8f6fT3DMf3F3/N17sIfNHkPsKgbOncR1TW1VxGYDNfk+33sUx/AgmbjRV1lGrPeaKRS6KJR3H2vrmtrGqMn1vq6h0mgfaxoKyz/x8/FqK0kjN4DpnLwXqyYnucAabW0qevsoIGumCAG70at9X65i4NxJ3NZY11JXJadp0OdnCcUxPEjOrpgoLqtMXzOF0PypsrbkXVdnh8woHSkVLY5CW9ytk5KKamPtFwysPyytxo01ZXWlhfzCYjKjdOmXqwjImqmdYQQYNMPuKgbOncTSYkIoedpQHMMjDy8Wi6QS7xMeDEZdXlJdvg9jLqGq3j8q7bH3r4Np/yeEUyexkLi0kHi/tzxRHMPDgaiMoqjMQO4YEisIaU/93X0eD3jXLK3G4nIq4nJfQc79Uy/RzC6pWnXszng91Q3DszCCTkk18c6eZUN7doYQEJ0WlVqQ+p0vnvoBqCrKvvvXKpUx4yct2jDIpogVJcv+uTO051/skP4soCApquJd6vDt4ucNN3bGWhV1TVQabUguLtCxNx5IujV2QKb8GGspDTInDJfBoDXerqm2gkajAgzBZ0nL3H7wjQwAGo1Go1EV9YyZLq+GkJ833Bz+debX7sIQsMzBdJnDSIwpcEFhxsbDX7sLQ4DJzGUmMzmeB8QRXFcxFy5cRohvNNxEphaEJGR97V5wGUYKkiKzo0O+di9+Cob2X11TnPs6+BLjDGn2+UbDjU9Iwt7rz792L4aXt+9LTwTF1jYyLxT+SUgM9Am/uPdr9+KngPFfXZrzNu7midaG2gG39jE76dnZna3EgbTwjYabn4FXuR+8A6KYvIhcuAwrH7NeRV/zbq0f+LTpwfBNhBvaiAwPfUWoP/TRscMP/xZzYYevPDKVU1K95/qztMJycjfFYJT8jiV2DqZ9WMUSc0oevMyJzSgidXZN1FezNFBbPs2MrpXoJHefCo4LisusrGtSlhG3NtT4e9V0ZGAYpWjwbD73gI8X6+lss+f6szfvSnFYnslj1I6tnS34Xx6ogvJPu//3LL2wvLWDrK8qt2WB9dxJY5CiLecfxGQUA8BG35CJ+qOOrpnd726+c6qLcp5f2FPxPo3SRZbXNLBdtUN7gkPvaiUZibkxD4pTYrs6SaMMJ6qNszSds5xue+gmd8b7n8qMDGr+VCkmq6xhYu244W9kvBalaJA89dlO7mi3c98Z738qJ+bBjkdFyPaO1qaoKwc/ZL1qbySqGJibzl7OuB4S5UDQu4peiv7/ue/9G41GZVzynhBwpuB1+CqfMGTtAsLD41uKU2IAIPTIxlFjJ87cfJTl4QBAxfu0xEDfyvwMCUW10ZazYBArP75muEnMKVl4wE9SRNDNwbS5vfPRq9wl3v5PDq9GlkHTYek/9rz06E5MhoutkaGGQkkV0S8iJfdjTcTRtehFgye7pKq+uf3Jm3ej5CQWWI1NKSgPiE5rbu+4ucMVAJLyPi444CctKrTS0VwAj3v+9v2Ko4G7XO23udgCgKaidF5pbWltg5aidH/LO34ASjISb21bKCgqaTrLraO1OS/uUcDOJe6+T1QNzHtUY6UlDjvlmRl+Z5yji4K2IbGiJPWxXw0hd82FCPSiQVJNyG0l1t7avqimOFdBZxyyEV17jH4g6F1FKWX5/0FXNdORVtGsLclrrC6VUtGSVNZgeTjIO+i/fRGOj1/feg4GwxN9zZvuVxwAXy3cUGm0nf8+weNwj71/Rb5vHk6WEzb6/vv0DVO4Qfcfd3Z1B8VmTjPTOe/xOb2ZuoLkjqtPiirrVGTE+ytCBD2MDMx2XFrbsGWB9T63qYhvxc7zYlwmAQBoNNqOf5/gcdjwo2sRmaHHfKuF+/1OBMU6WY3VUpTe5GRJoVKT35duWWjNmGLhR4JGpT47uxPHi3f3fYyscrJc4nF2+YS3D/5lCjfoWuLurs6syCAdi2lOO84j9SWV1J/67qgvKxKTV+mviCnZwMAMxHWlhVrm9i77r9PXoKNrj1EOBOUopFS00EuHSts8efEmKpVSlptsvXQLksuBpcUZeQfXX41FPISTF2+88KsVRztl5KuFmyxCVU5J9RI7Y/pvu7ayzNE1s3rf5kD3H1OpNABIzCnJIlQhC47WzJro5mCK58ORuyj9FfXuz8Bsx/x8vDsW2yGr73gwmAmjVTOLKyvrm2sbWzOLK3+ZNIYuTuXFYl3tTOKzCLEZxb2D3Q9JVWFWdVGO0fQl9BWV0qraMz2O0mjMiYDQtcQ0ChUASjISqwqzFLQNAWCC0xqTWW44PjyFTO6viGkXAzYQ2/+6ix5rWGqPUQ4E5ShYlg6VtpkJlodTlpdSXZQzxc2T7jyVUtY0mrY4+dEAl+b2+OIhXxsajTYCkgfEB84k914zi9l1BKz8xwJ43u1LbA/5R03547yOsoyVocY0Ux07Y20sD48Anqe/oj72MiDbsYy4EGPwEhcSAIA2Uiehsg4AJvdMxTlOUxEAiirq+tvLcEP77y0ePBgMhuWEfWIFAXo6pQBgwvw1vWuia4l5+QVsVm6P/vfQxdVTZEbpqBtb6UycpmVux8OD5em/qPcuBmAgFhKXVtIzob9kqT1GORCUo2BZOlTaZiZYHk7dxwIAYMxpBQAyrMzwCMjIANPnrccXT1hYGACQRALDTX1TGwAo9rQ09AlL/7Gns03a5a3bXGwF8bzXn711+fuWxUbf2oZW9CImBmY77jPXAg0AkYSpyvbQ0HZ2dQMAlucr+HoQWkmdIsL9Lr7nCGFh4e6OdvQ6bY31ACAqzXpVNEst8RQ3zy2BaTYrtvHyCyY/uu6/w+XsCgtk6gdKESMDMxDTDTUILLXH6AeC3lWU0gFom+mqZhRYHg7SCE/PXGm8vc4c+4Tc3goAoqI9vuA9zm4UFBQAoKKuidHRPUwgX8WUgvL5Vl8UMHdi0qlUmqs9w+8JK/8xuZtC6uxSlRXf5Wq/y9W+tqH1xL3Yq0+SLj95vX2xXX9Fe5f1uPcOQ207HiUnAQCv8z4w6q+S88sAQK0vQ8XIUFXfLC83NLli5OXlW+KS0OsgZ+Dl71LG2s+nb8wIv0OjUo1nuNK3sNQSU7rIXZ0kcXlVO/dddu67Wom1cbdOvAm5mnT/su3K7f0VOazpMYdwkAZiBHTtMfqBoByFw5q9KKUWzutZaptRVM0DPhwAkFAYBQAfMl6OtvoyctpQVcqyZQBorqsCAHn5HqdgPX60R48ezYvDZRKYrXHDgbG2Ej8fb3zWF4tPflntBp+Ql7kfGKv15z+mV0jIIqi5Hrof/3nFg6yEsIeTJQA0tpJQinr3B7Ed9/coqarn6OgMNRT5cNiYjCLGjYnZBCwPj92wrQ5nSRaheqzhuCFpytDQsOZjIT01Wp8ojTbmxfMT0uLpWz59yA/9Z8OHzB4W1P60xPQKhPSEw7PUsqPuIy+FJWUtF3sAQEdLI0oRU2cQA3F/jz4zwPSGUXtM35jgf/rwLLXy92noB4LeVZRSlv8fABCXV22sLqX3ilHVPODDAQBFXWMsjpfxHaRSurOigvtoqxdVBZk4Xl49vR5XXj3ObvB4/KRJFlFpRQuth+ZDiYKsuPD6uZNOB8dtvfDQbZpZflntuQcvcTw8q6b3GLNg6T+eMFpVRkzo2N0YRWkxQw0FQhUROfdxNNNFKerdn6G1HctLiqyZNfH8w5eelx6tnjEBh8MGx2U+fJW7xM6YLj9XlRUHgBvhyUvtTftMTD60dHZ1x2eXHF0+kKxGvZkyZQqNSilOjdWbPKO/OsISshbO6+P9T4ed3Goy2+3Th/yXd8/xYHHj565irMZSS6xqMEFIQibW75iorKKCtiGxnID8tutYOKIUMXVmkAZiBHTtMZnUhnIg6F1FKWVH24yiamZCXE4VAFIe3TCeuVRJzwTd4iwmq2TutPr1vYsPjm6a4LQaMJiYG0c72btFXfQ2ysJiEh7f48oLwzTX08fHZ8+une/+9+cI+FMoVOoh/6izoYkUKhUA5CREjqyZNW+yAQDM3n2tpKo+939eAPDgZc5G35C2DjL09B+Tu7oR/3FsZvH6M8HVxM+rAfB8OK9Ftludp6AXDR47z4utHeS35zfTt/xzO/rY3Zg35zfrKMuQuyl/3Xh+Kew1vXTVdPMja2bx/XfXmdjS7vL3rZT8MksD9TBWor/BE5qYvebUvQ8fPiorDzBnIxOTJlu24GUW7UcbpKBSKdH/HnoZeJZKpQCAiJTcTI8jY2zmAcD/Ns8mVpT8GZwLALmxD0KPbCST2qCnlri7i4xoiYtTY0MOr2+p+3xWi+PD26zwsl62Fb1okDD2kJGkkCsRF/d1kzuBQXuMDBujHwh6V1FKWf5/ujpId/YtL3wTBQCMqua/omqwvHyMB9LeTAzY7lKWl6JuZLnKJwz9cACgu6vzyZntqY/9kJcaplOMp7ve91636eYblDy/ne2tJxeOPnrY28PDg3E7c7hpaGhQVlLa7mLt4TTw0XWOaO8g536oFhHk11CU4utnAIil/5jU2ZX7obrsU6OUqNDoUXKMiW5RikaAT01t2YQqPC92jJq8eK/U5gBQTWwRFuAb7uBOo9Gmbr+qpGP48FEY69rs4e/vv3KV+0a/11LKLHLskTvaa4pz8YIiUsoaTDdf6bDUEnd1kKoJuU01ZYJiUnLqo5EkvyyLhgkU7TH6gaB3FaWUHW0zuqqZkZa6aj5BYfrVGUuLc1NtRQ0hT2aUDnI3hyWJgb4JfkcrKsolJHqMljCHGwDYv3//yeNHUy5s/iGzGv2c3I5O8zj/IDU1bdy4IbtMplAoxiam3cIKS/4JHKo2ufwAtDbUnls2fpvnH/v372cq6mN818vLS1JK+m//qJHoGpfhp6W98++A6HXr1g1hrAEALBbr63Pm3avnBUmRQ9gsl++dqCsHJSTEvbyYk2RBn+FGUFDw9Bmf29FpgS/Sh79vXIYXKo229nQwDct38ODfQ964jY3N4sVLHh79vbGarcFRLj88Gc8D05/d9j1zWlCwj+Qrfc9emz9//o4dOzaff5CQPQTpZrh8RfbdeB6bSQh98FBKalgWgl679q+OhlrA9kUdrayzoXP5sfmYnRR28o+dO3fOnz+/zwp93LtBoFKpi5ydX0SFB+xcYqGvNox95DI80Gi0o3dijt2NCQgIWLJkyfDtqKysbLz5BEHZUS7eAShJoLj82HzMen1nz1JHe7t794J4+pmF369ei4eH55a/v52D47x9N7hXVd8dHeTutaeCTwXHX758eVhjDQCoqKhER0VSmqqvbZjKzmRWLj8eGc8D/bbOm2Zv5+9/q79YAyhnNwg0Gm337t1HjhxxtTfZ5zZVVny4EtBwGUKS8j56/fu0vL71XvB9e/sRSlpUW1s795d52bl5tu67x/+yitHqxOUHprWhNurKwfRnt3fs2OHt7Y0+Bs8i3CCEhoZu2ezRQKz/09nafbo5N4PaN0txZf2ROy/ux2dNdbA/f+GilpYW678ZOjo6Og4cOHDq1GkpFU37tfu1ze0x/f/Qcfne6WxvTX74v4RbJyQlJc76nHFycmL5J2yFGwBob28/duzY8WPHeDAw01zXwUR7nKaiopQoN/R8Xag0WkMLiVBZl1xQ/iw5/2U2QVNd/eTp03Pnzv1aXSoqKvpjq+fjsEfSyup6VnPVTazk1EcLikni+Pi/Vpe4DBWdbS3NnyqrCrOK3ka9f/kUQ6V6eW3z8vLqcxyqD2icQCQSz5w5YzPFGtfP9F8uXwtJCfHFixeHhYV1d3dz9J4OEzk5OZ6enpra/c5z5/L9gsXhrKfY+Pj4EIlEjj4V7J7dMNHZ2ZmXl1dTU9PSws1b8jXh4eERFxdXV1dXV1cfASnaACASiXl5eQ0NDR0dHV+7L1wGi4iIiJycnL6+PtPaSzYZYLjhwoULF07h3snjwoXLCMENN1y4cBkhuOGGCxcuI8T/AdXKdTvcWMPZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.plot_decision_tree(clf, features[0:25], ['not', 'reassaulted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Random Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Random Forest model can typically be a high performing model.  We will investigate it here for posterity, though we are unlikely to utilize it in finality or production in this instance.  A sensitive human-based topic such as domestic abuse is highly prone to bias and utilizing a black box methodology such as this would likely be a poor choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_params = {'max_depth': [2, 3, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.709324\n",
      "2          4  0.711152\n",
      "1          3  0.716636\n",
      "Cross Validation Results: \n",
      "[0.70909091 0.68181818 0.75229358 0.70642202 0.75229358]\n",
      "--------------------------------------------------------\n",
      "Model based on top 5 features\n",
      "Accuracy of Random Forest classifier on training set: 0.74\n",
      "[[177  73]\n",
      " [ 70 227]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71       250\n",
      "           1       0.76      0.76      0.76       297\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       547\n",
      "   macro avg       0.74      0.74      0.74       547\n",
      "weighted avg       0.74      0.74      0.74       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "2          4  0.722121\n",
      "0          2  0.723949\n",
      "1          3  0.731261\n",
      "Cross Validation Results: \n",
      "[0.70909091 0.7        0.82568807 0.74311927 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 6 features\n",
      "Accuracy of Random Forest classifier on training set: 0.75\n",
      "[[182  68]\n",
      " [ 67 230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       250\n",
      "           1       0.77      0.77      0.77       297\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       547\n",
      "   macro avg       0.75      0.75      0.75       547\n",
      "weighted avg       0.75      0.75      0.75       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "2          4  0.745887\n",
      "0          2  0.751371\n",
      "1          3  0.751371\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.70909091 0.79816514 0.74311927 0.78899083]\n",
      "--------------------------------------------------------\n",
      "Model based on top 7 features\n",
      "Accuracy of Random Forest classifier on training set: 0.77\n",
      "[[182  68]\n",
      " [ 59 238]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74       250\n",
      "           1       0.78      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.76      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.749543\n",
      "2          4  0.751371\n",
      "1          3  0.753199\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.70909091 0.79816514 0.75229358 0.78899083]\n",
      "--------------------------------------------------------\n",
      "Model based on top 8 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[182  68]\n",
      " [ 55 242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       250\n",
      "           1       0.78      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.78      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.736746\n",
      "0          2  0.738574\n",
      "2          4  0.747715\n",
      "Cross Validation Results: \n",
      "[0.70909091 0.70909091 0.79816514 0.75229358 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 9 features\n",
      "Accuracy of Random Forest classifier on training set: 0.77\n",
      "[[179  71]\n",
      " [ 53 244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.74       250\n",
      "           1       0.77      0.82      0.80       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.736746\n",
      "1          3  0.740402\n",
      "2          4  0.740402\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.70909091 0.77981651 0.75229358 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 10 features\n",
      "Accuracy of Random Forest classifier on training set: 0.77\n",
      "[[182  68]\n",
      " [ 59 238]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74       250\n",
      "           1       0.78      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.76      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.736746\n",
      "2          4  0.738574\n",
      "1          3  0.742230\n",
      "Cross Validation Results: \n",
      "[0.70909091 0.72727273 0.7706422  0.74311927 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 11 features\n",
      "Accuracy of Random Forest classifier on training set: 0.77\n",
      "[[181  69]\n",
      " [ 59 238]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74       250\n",
      "           1       0.78      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.76      0.76      0.76       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.736746\n",
      "2          4  0.742230\n",
      "0          2  0.753199\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.71818182 0.77981651 0.74311927 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 12 features\n",
      "Accuracy of Random Forest classifier on training set: 0.77\n",
      "[[182  68]\n",
      " [ 60 237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       250\n",
      "           1       0.78      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.76      0.76      0.76       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.744059\n",
      "0          2  0.747715\n",
      "2          4  0.747715\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.73636364 0.83486239 0.73394495 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 13 features\n",
      "Accuracy of Random Forest classifier on training set: 0.77\n",
      "[[182  68]\n",
      " [ 57 240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74       250\n",
      "           1       0.78      0.81      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "2          4  0.729433\n",
      "0          2  0.734918\n",
      "1          3  0.742230\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.72727273 0.78899083 0.73394495 0.75229358]\n",
      "--------------------------------------------------------\n",
      "Model based on top 14 features\n",
      "Accuracy of Random Forest classifier on training set: 0.77\n",
      "[[180  70]\n",
      " [ 56 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74       250\n",
      "           1       0.77      0.81      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.736746\n",
      "2          4  0.742230\n",
      "1          3  0.749543\n",
      "Cross Validation Results: \n",
      "[0.72727273 0.72727273 0.78899083 0.73394495 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 15 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[184  66]\n",
      " [ 57 240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       250\n",
      "           1       0.78      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.78      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid cv results: \n",
      "   max_depth     score\n",
      "2          4  0.740402\n",
      "1          3  0.751371\n",
      "0          2  0.758684\n",
      "Cross Validation Results: \n",
      "[0.71818182 0.72727273 0.7706422  0.75229358 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 16 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[182  68]\n",
      " [ 51 246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75       250\n",
      "           1       0.78      0.83      0.81       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.742230\n",
      "0          2  0.745887\n",
      "2          4  0.751371\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.71818182 0.76146789 0.72477064 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 17 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[186  64]\n",
      " [ 56 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76       250\n",
      "           1       0.79      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.745887\n",
      "1          3  0.747715\n",
      "2          4  0.749543\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.69090909 0.7706422  0.72477064 0.7706422 ]\n",
      "--------------------------------------------------------\n",
      "Model based on top 18 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[183  67]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       250\n",
      "           1       0.78      0.82      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.742230\n",
      "1          3  0.744059\n",
      "2          4  0.749543\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.73636364 0.7706422  0.74311927 0.77981651]\n",
      "--------------------------------------------------------\n",
      "Model based on top 19 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[186  64]\n",
      " [ 59 238]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       250\n",
      "           1       0.79      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.78      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.736746\n",
      "0          2  0.740402\n",
      "2          4  0.742230\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.70909091 0.80733945 0.73394495 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 20 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[187  63]\n",
      " [ 57 240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       250\n",
      "           1       0.79      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.742230\n",
      "0          2  0.745887\n",
      "2          4  0.747715\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.69090909 0.78899083 0.74311927 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 21 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[186  64]\n",
      " [ 55 242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76       250\n",
      "           1       0.79      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.738574\n",
      "0          2  0.740402\n",
      "2          4  0.745887\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.72727273 0.81651376 0.75229358 0.73394495]\n",
      "--------------------------------------------------------\n",
      "Model based on top 22 features\n",
      "Accuracy of Random Forest classifier on training set: 0.79\n",
      "[[188  62]\n",
      " [ 55 242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       250\n",
      "           1       0.80      0.81      0.81       297\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.79      0.79      0.79       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.742230\n",
      "2          4  0.749543\n",
      "1          3  0.751371\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.70909091 0.7706422  0.74311927 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 23 features\n",
      "Accuracy of Random Forest classifier on training set: 0.77\n",
      "[[184  66]\n",
      " [ 60 237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74       250\n",
      "           1       0.78      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.738574\n",
      "2          4  0.744059\n",
      "1          3  0.745887\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.71818182 0.79816514 0.76146789 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 24 features\n",
      "Accuracy of Random Forest classifier on training set: 0.77\n",
      "[[186  64]\n",
      " [ 60 237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       250\n",
      "           1       0.79      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.733090\n",
      "1          3  0.744059\n",
      "2          4  0.747715\n",
      "Cross Validation Results: \n",
      "[0.76363636 0.70909091 0.80733945 0.73394495 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 25 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[183  67]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       250\n",
      "           1       0.78      0.82      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.745887\n",
      "0          2  0.751371\n",
      "2          4  0.751371\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.72727273 0.80733945 0.76146789 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 26 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[184  66]\n",
      " [ 56 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       250\n",
      "           1       0.79      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.77      0.77       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.738574\n",
      "2          4  0.744059\n",
      "1          3  0.753199\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.70909091 0.80733945 0.75229358 0.75229358]\n",
      "--------------------------------------------------------\n",
      "Model based on top 27 features\n",
      "Accuracy of Random Forest classifier on training set: 0.77\n",
      "[[185  65]\n",
      " [ 59 238]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75       250\n",
      "           1       0.79      0.80      0.79       297\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       547\n",
      "   macro avg       0.77      0.77      0.77       547\n",
      "weighted avg       0.77      0.77      0.77       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.740402\n",
      "1          3  0.740402\n",
      "2          4  0.740402\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.71818182 0.79816514 0.74311927 0.73394495]\n",
      "--------------------------------------------------------\n",
      "Model based on top 28 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[187  63]\n",
      " [ 58 239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76       250\n",
      "           1       0.79      0.80      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.736746\n",
      "2          4  0.744059\n",
      "1          3  0.751371\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.71818182 0.77981651 0.74311927 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 29 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[184  66]\n",
      " [ 53 244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       250\n",
      "           1       0.79      0.82      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.747715\n",
      "1          3  0.749543\n",
      "2          4  0.753199\n",
      "Cross Validation Results: \n",
      "[0.74545455 0.70909091 0.79816514 0.74311927 0.73394495]\n",
      "--------------------------------------------------------\n",
      "Model based on top 30 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[189  61]\n",
      " [ 60 237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76       250\n",
      "           1       0.80      0.80      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.745887\n",
      "1          3  0.745887\n",
      "2          4  0.745887\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.69090909 0.80733945 0.75229358 0.75229358]\n",
      "--------------------------------------------------------\n",
      "Model based on top 31 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[185  65]\n",
      " [ 56 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       250\n",
      "           1       0.79      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.736746\n",
      "0          2  0.742230\n",
      "2          4  0.744059\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.7        0.78899083 0.75229358 0.73394495]\n",
      "--------------------------------------------------------\n",
      "Model based on top 32 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[185  65]\n",
      " [ 55 242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76       250\n",
      "           1       0.79      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.736746\n",
      "1          3  0.740402\n",
      "2          4  0.755027\n",
      "Cross Validation Results: \n",
      "[0.76363636 0.70909091 0.78899083 0.76146789 0.73394495]\n",
      "--------------------------------------------------------\n",
      "Model based on top 33 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[188  62]\n",
      " [ 59 238]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76       250\n",
      "           1       0.79      0.80      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.745887\n",
      "2          4  0.749543\n",
      "0          2  0.753199\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.71818182 0.80733945 0.74311927 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 34 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[185  65]\n",
      " [ 55 242]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76       250\n",
      "           1       0.79      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.745887\n",
      "1          3  0.756856\n",
      "2          4  0.758684\n",
      "Cross Validation Results: \n",
      "[0.76363636 0.69090909 0.81651376 0.76146789 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 35 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[186  64]\n",
      " [ 56 241]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76       250\n",
      "           1       0.79      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.745887\n",
      "1          3  0.753199\n",
      "2          4  0.755027\n",
      "Cross Validation Results: \n",
      "[0.73636364 0.71818182 0.80733945 0.75229358 0.76146789]\n",
      "--------------------------------------------------------\n",
      "Model based on top 36 features\n",
      "Accuracy of Random Forest classifier on training set: 0.79\n",
      "[[189  61]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       250\n",
      "           1       0.80      0.82      0.81       297\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       547\n",
      "   macro avg       0.79      0.79      0.79       547\n",
      "weighted avg       0.79      0.79      0.79       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.745887\n",
      "0          2  0.753199\n",
      "2          4  0.758684\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.72727273 0.82568807 0.75229358 0.75229358]\n",
      "--------------------------------------------------------\n",
      "Model based on top 37 features\n",
      "Accuracy of Random Forest classifier on training set: 0.79\n",
      "[[183  67]\n",
      " [ 49 248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76       250\n",
      "           1       0.79      0.84      0.81       297\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       547\n",
      "   macro avg       0.79      0.78      0.78       547\n",
      "weighted avg       0.79      0.79      0.79       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid cv results: \n",
      "   max_depth     score\n",
      "0          2  0.751371\n",
      "2          4  0.755027\n",
      "1          3  0.760512\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.73636364 0.82568807 0.75229358 0.73394495]\n",
      "--------------------------------------------------------\n",
      "Model based on top 38 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[187  63]\n",
      " [ 57 240]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       250\n",
      "           1       0.79      0.81      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.742230\n",
      "2          4  0.749543\n",
      "0          2  0.751371\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.7        0.81651376 0.75229358 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[184  66]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       250\n",
      "           1       0.79      0.82      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.742230\n",
      "2          4  0.749543\n",
      "0          2  0.751371\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.7        0.81651376 0.75229358 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[184  66]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       250\n",
      "           1       0.79      0.82      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.742230\n",
      "2          4  0.749543\n",
      "0          2  0.751371\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.7        0.81651376 0.75229358 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[184  66]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       250\n",
      "           1       0.79      0.82      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n",
      "grid cv results: \n",
      "   max_depth     score\n",
      "1          3  0.742230\n",
      "2          4  0.749543\n",
      "0          2  0.751371\n",
      "Cross Validation Results: \n",
      "[0.75454545 0.7        0.81651376 0.75229358 0.74311927]\n",
      "--------------------------------------------------------\n",
      "Model based on top 39 features\n",
      "Accuracy of Random Forest classifier on training set: 0.78\n",
      "[[184  66]\n",
      " [ 54 243]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75       250\n",
      "           1       0.79      0.82      0.80       297\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       547\n",
      "   macro avg       0.78      0.78      0.78       547\n",
      "weighted avg       0.78      0.78      0.78       547\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for list_item in list_of_feature_lists[4:]:\n",
    "    clf, y_pred, y_pred_proba = model.random_forest(list_item, X_train, y_train)\n",
    "    print('--------------------------------------------------------')\n",
    "    print(f'Model based on top {len(list_item)} features')\n",
    "    print('Accuracy of Random Forest classifier on training set: {:.2f}'.format(clf.score(X_train[list_item], y_train)))\n",
    "    print(confusion_matrix(y_train, y_pred))\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results of liblinear Logistic Regression model using top 9 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Results: \n",
      "[0.72727273 0.7        0.79816514 0.75229358 0.77981651]\n"
     ]
    }
   ],
   "source": [
    "clf, y_pred, y_pred_proba = model.log_reg(features[:9], X_train, y_train, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logreg classifier on test set: 0.84\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_test[features[:9]], y_test)\n",
    "y_pred = clf.predict(X_test[features[:9]])\n",
    "y_pred_proba = clf.predict_proba(X_test[features[:9]])\n",
    "print('Accuracy of logreg classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test[features[:9]], y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81        44\n",
      "           1       0.84      0.87      0.85        53\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        97\n",
      "   macro avg       0.83      0.83      0.83        97\n",
      "weighted avg       0.83      0.84      0.83        97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
